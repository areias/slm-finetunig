{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/areias/slm-finetunig/blob/main/colab_axolotl_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKjdG7tbTb-n"
      },
      "source": [
        "# Finetuning with Axolotl on google colab\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGXGQ00u1cJ-",
        "outputId": "0a9ed976-e4b6-4c18-e6ef-5c53d749d8dd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## prepare data"
      ],
      "metadata": {
        "id": "lrdze25M2Ds7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "fTUD4NI13diW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ls drive/MyDrive/mistral-finetune/data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLviH6P14cZk",
        "outputId": "ad835ba7-7090-4022-985e-2c4b4cb1797f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nyt10m_finetuning-balanced.csv  nyt10m_test.csv             test_sample.json\n",
            "nyt10m_finetuning.csv           test_sample_basepreds.json  train_sample.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"drive/MyDrive/mistral-finetune/data/nyt10m_finetuning-balanced.csv\")"
      ],
      "metadata": {
        "id": "FEFGKtdzSt5q"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[df['relation'].isna(),'relation']=\"None\"\n"
      ],
      "metadata": {
        "id": "rRgTtQKjS6NZ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "qJrvuAs_SwxP",
        "outputId": "16acfce2-4b68-4174-b9f5-0ed5a77a0b4d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text         h_name  \\\n",
              "0  There were also performers who were born in Lo...  Johnny Rivers   \n",
              "1  Indeed , Mr. Chávez said Sunday that he wished...    Evo Morales   \n",
              "2  Indeed , Mr. Chávez said Sunday that he wished...    Evo Morales   \n",
              "3  Analysts contrast Mr. Chávez 's success at con...    Evo Morales   \n",
              "4  Ecuador 's new president , Rafael Correa , joi...    Evo Morales   \n",
              "\n",
              "      t_name                       relation  \n",
              "0  Louisiana  /people/person/place_of_birth  \n",
              "1    Bolivia     /people/person/nationality  \n",
              "2    Bolivia     /people/person/place_lived  \n",
              "3    Bolivia     /people/person/nationality  \n",
              "4    Bolivia     /people/person/nationality  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b3ddb963-f41d-450f-96c5-425db62b7204\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>h_name</th>\n",
              "      <th>t_name</th>\n",
              "      <th>relation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>There were also performers who were born in Lo...</td>\n",
              "      <td>Johnny Rivers</td>\n",
              "      <td>Louisiana</td>\n",
              "      <td>/people/person/place_of_birth</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Indeed , Mr. Chávez said Sunday that he wished...</td>\n",
              "      <td>Evo Morales</td>\n",
              "      <td>Bolivia</td>\n",
              "      <td>/people/person/nationality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Indeed , Mr. Chávez said Sunday that he wished...</td>\n",
              "      <td>Evo Morales</td>\n",
              "      <td>Bolivia</td>\n",
              "      <td>/people/person/place_lived</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Analysts contrast Mr. Chávez 's success at con...</td>\n",
              "      <td>Evo Morales</td>\n",
              "      <td>Bolivia</td>\n",
              "      <td>/people/person/nationality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ecuador 's new president , Rafael Correa , joi...</td>\n",
              "      <td>Evo Morales</td>\n",
              "      <td>Bolivia</td>\n",
              "      <td>/people/person/nationality</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b3ddb963-f41d-450f-96c5-425db62b7204')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b3ddb963-f41d-450f-96c5-425db62b7204 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b3ddb963-f41d-450f-96c5-425db62b7204');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-01329382-9c11-4837-a836-c86bc13b47f8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-01329382-9c11-4837-a836-c86bc13b47f8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-01329382-9c11-4837-a836-c86bc13b47f8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1452,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 974,\n        \"samples\": [\n          \"And in Mexico , rumors abound about development in a remote area of Baja California known as Scorpion Bay .\",\n          \"Hassan Dahir , the vice president of Puntland , a semiautonomous region of Somalia , said eight Islamist militants had been killed , including one who was an American citizen , according to documents found on his body .\",\n          \"PUNAK -- Randy M. , 53 of NYC died March 5 , 2007 in Paris , France .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"h_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 734,\n        \"samples\": [\n          \"Equinix\",\n          \"Havana\",\n          \"Oceanport\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"t_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 442,\n        \"samples\": [\n          \"PCCW\",\n          \"Troma Entertainment\",\n          \"Ontario\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"relation\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"/location/administrative_division/country\",\n          \"/people/person/nationality\",\n          \"/business/company/advisors\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.relation.value_counts() / len(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-SDv9QYS8Es",
        "outputId": "4391ee22-bc68-4617-9597-12a5db3b4c69"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "/people/person/place_lived                    0.176997\n",
              "/location/located_in                          0.153581\n",
              "/business/person/company                      0.125344\n",
              "/location/administrative_division/country     0.082645\n",
              "/people/person/nationality                    0.081956\n",
              "None                                          0.081956\n",
              "/business/location                            0.079890\n",
              "/location/country/administrative_divisions    0.066804\n",
              "/people/person/place_of_birth                 0.058540\n",
              "/business/company/advisors                    0.048898\n",
              "/people/deceasedperson/place_of_death         0.043388\n",
              "Name: relation, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbQPngoCSxi2",
        "outputId": "58d3d0f4-4eed-491a-a422-4919764df944"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1452"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(df):\n",
        "\n",
        "    data = []\n",
        "\n",
        "    for idx, sentence in enumerate(df['text'].unique()):\n",
        "        output=[]\n",
        "        for row in df[df['text']==sentence].iterrows():\n",
        "            if row[1]['relation']==\"None\":\n",
        "                output.append(\"None\")\n",
        "            else:\n",
        "                output.append(tuple([row[1]['h_name'],row[1]['relation'],row[1]['t_name']]))\n",
        "        data.append({\"input\": sentence,\n",
        "                    \"output\": \", \".join([str(x) for x in output])})\n",
        "    return data"
      ],
      "metadata": {
        "id": "jh61ah9tTcuk"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=preprocess(df)"
      ],
      "metadata": {
        "id": "Ymjg3KgaTcrU"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[0]['input']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "ucqo9OsxTcnI",
        "outputId": "9343ac9e-7838-464b-da5d-a23388e4ca8f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"There were also performers who were born in Louisiana , including Lucinda Williams , Jerry Lee Lewis and Johnny Rivers , whose '' Secret Agent Man '' had a touch of bayou-country swamp-pop .\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q jsonlines"
      ],
      "metadata": {
        "id": "YKMfrApAUDor"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import jsonlines\n",
        "\n",
        "# Replace 'output.jsonl' with the desired output file path\n",
        "output_file = 'drive/MyDrive/mistral-finetune/data/rel-ext-train.jsonl'\n",
        "\n",
        "# Iterate through each row of the DataFrame and save as JSONL\n",
        "with jsonlines.open(output_file, mode='w') as writer:\n",
        "    for x in data:\n",
        "        # Write dictionary to JSONL file\n",
        "        writer.write(x)"
      ],
      "metadata": {
        "id": "rtPTy5lDTca7"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head -n 3 drive/MyDrive/mistral-finetune/data/rel-ext-train.jsonl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvJrLDGpUObr",
        "outputId": "817d35c7-2e7f-4149-815d-6050df46acd1"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"input\": \"There were also performers who were born in Louisiana , including Lucinda Williams , Jerry Lee Lewis and Johnny Rivers , whose '' Secret Agent Man '' had a touch of bayou-country swamp-pop .\", \"output\": \"('Johnny Rivers', '/people/person/place_of_birth', 'Louisiana'), ('Jerry Lee Lewis', '/people/person/place_of_birth', 'Louisiana')\"}\n",
            "{\"input\": \"Indeed , Mr. Chávez said Sunday that he wished Mr. Correa the '' best of luck '' from Venezuela , where he appeared on television with President Evo Morales of Bolivia to commemorate the opening of a milk processing plant built in western Venezuela with financing from Iran .\", \"output\": \"('Evo Morales', '/people/person/nationality', 'Bolivia'), ('Evo Morales', '/people/person/place_lived', 'Bolivia')\"}\n",
            "{\"input\": \"Analysts contrast Mr. Chávez 's success at consolidating power in Venezuela with the troubles faced by President Evo Morales in Bolivia , where a constitution-writing assembly has been stalled by fractious delegates and regional power struggles .\", \"output\": \"('Evo Morales', '/people/person/nationality', 'Bolivia')\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rfip3lk5UOVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jWCDRL-zUOR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['text'].nunique()/2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VHmUBZkS0kb",
        "outputId": "a87e3f76-237d-4b7c-d265-dd0cc7635571"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "487.0"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open(\"drive/MyDrive/mistral-finetune/data/nyt10m_finetuning-balanced.csvz\",\"r\") as file:\n",
        "    data = json.load(file)"
      ],
      "metadata": {
        "id": "Hx3UXJaR3Zka"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mb-p6_AP3sQa",
        "outputId": "33f89264-60b8-4416-9e0c-a7ad5df4af69"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': '10476',\n",
              " 'tokens': ['CINCINNATI', 'AT', 'COLORADO'],\n",
              " 'pos_tags': [22, 22, 22],\n",
              " 'chunk_tags': [11, 12, 12],\n",
              " 'ner_tags': [3, 0, 5],\n",
              " 'labels': ['B-ORG', 'O', 'B-LOC'],\n",
              " 'sentence': 'CINCINNATI AT COLORADO',\n",
              " 'entities': {'PER': [],\n",
              "  'ORG': ['CINCINNATI'],\n",
              "  'LOC': ['COLORADO'],\n",
              "  'MISC': []}}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9ez9bktSXjH",
        "outputId": "1a73a2d7-86ec-476e-90e5-f3e055b5fba6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=data[0]\n",
        "print({\"input\": x['sentence'],\n",
        " \"output\": x['entities']})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VdsKxPO3o7i",
        "outputId": "97309042-f313-428f-886c-040b2f85ca99"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input': 'CINCINNATI AT COLORADO', 'output': {'PER': [], 'ORG': ['CINCINNATI'], 'LOC': ['COLORADO'], 'MISC': []}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jsonlines"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gWPD1ye4jjS",
        "outputId": "a27a928c-a757-4a41-ea6a-8fe9fa9e4c11"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jsonlines\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines) (23.2.0)\n",
            "Installing collected packages: jsonlines\n",
            "Successfully installed jsonlines-4.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jsonlines\n",
        "\n",
        "# Replace 'output.jsonl' with the desired output file path\n",
        "output_file = 'drive/MyDrive/mistral-finetune/data/train.jsonl'\n",
        "\n",
        "# Iterate through each row of the DataFrame and save as JSONL\n",
        "with jsonlines.open(output_file, mode='w') as writer:\n",
        "    for x in data:\n",
        "        # Convert row to dictionary\n",
        "        line = {\"input\": x['sentence'],\"output\": x['entities']}\n",
        "        # Write dictionary to JSONL file\n",
        "        writer.write(line)"
      ],
      "metadata": {
        "id": "to61XqD_4J9X"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! head -n 5 drive/MyDrive/mistral-finetune/data/train.jsonl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Do5j0O075ag-",
        "outputId": "7a876c66-18b5-4cd7-b7f6-d53b83e950d1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"input\": \"CINCINNATI AT COLORADO\", \"output\": {\"PER\": [], \"ORG\": [\"CINCINNATI\"], \"LOC\": [\"COLORADO\"], \"MISC\": []}}\n",
            "{\"input\": \"Relations with Russia , which is our main partner , have great importance , \\\" Kuchma said .\", \"output\": {\"PER\": [\"Kuchma\"], \"ORG\": [], \"LOC\": [\"Russia\"], \"MISC\": []}}\n",
            "{\"input\": \"He added : \\\" If no one asked , I never opened my mouth .\", \"output\": {\"PER\": [], \"ORG\": [], \"LOC\": [], \"MISC\": []}}\n",
            "{\"input\": \"-- Steve Weizman , Copenhagen newsroom +45 33969650\", \"output\": {\"PER\": [\"Steve Weizman\"], \"ORG\": [], \"LOC\": [\"Copenhagen\"], \"MISC\": []}}\n",
            "{\"input\": \"70 71 74\", \"output\": {\"PER\": [], \"ORG\": [], \"LOC\": [], \"MISC\": []}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RcbNpOgWRcii"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "# Check so there is a gpu available, a T4(free tier) is enough to run this notebook\n",
        "assert (torch.cuda.is_available()==True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3nLav8oTRA5"
      },
      "source": [
        "## Install Axolotl and dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3c3yGAwnOIdi",
        "outputId": "5c1b7288-e297-4b38-c2c8-664a6752db06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.1.2\n",
            "  Downloading torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.1.2)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.1.2)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.1.2)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m89.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.1.2)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.1.2)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.1.2)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.1.2)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.1.2)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.1.2)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.18.1 (from torch==2.1.2)\n",
            "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.1.2)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2) (2.1.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.2)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m89.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.2) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.2) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.0+cu121\n",
            "    Uninstalling torch-2.1.0+cu121:\n",
            "      Successfully uninstalled torch-2.1.0+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.1.0+cu121 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\n",
            "torchvision 0.16.0+cu121 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.3.101 nvidia-nvtx-cu12-12.1.105 torch-2.1.2\n",
            "Obtaining axolotl from git+https://github.com/OpenAccess-AI-Collective/axolotl#egg=axolotl\n",
            "  Cloning https://github.com/OpenAccess-AI-Collective/axolotl to ./src/axolotl\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/OpenAccess-AI-Collective/axolotl /content/src/axolotl\n",
            "  Resolved https://github.com/OpenAccess-AI-Collective/axolotl to commit b5b44925ec5732a390fee932039acc487f8741f6\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting peft@ git+https://github.com/huggingface/peft.git (from axolotl)\n",
            "  Cloning https://github.com/huggingface/peft.git to /tmp/pip-install-w13xzvpf/peft_e0bd5534fcf34d8d86a9a656efeaab72\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-install-w13xzvpf/peft_e0bd5534fcf34d8d86a9a656efeaab72\n",
            "  Resolved https://github.com/huggingface/peft.git to commit 34f3fba2b3f76d62a55491524301baca83dbc22b\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting transformers@ git+https://github.com/huggingface/transformers.git@ae49b218c3d718df90d8e4a109016450fb8f0632 (from axolotl)\n",
            "  Cloning https://github.com/huggingface/transformers.git (to revision ae49b218c3d718df90d8e4a109016450fb8f0632) to /tmp/pip-install-w13xzvpf/transformers_64283e2ef82a42a488f482164e212f36\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-install-w13xzvpf/transformers_64283e2ef82a42a488f482164e212f36\n",
            "  Running command git rev-parse -q --verify 'sha^ae49b218c3d718df90d8e4a109016450fb8f0632'\n",
            "  Running command git fetch -q https://github.com/huggingface/transformers.git ae49b218c3d718df90d8e4a109016450fb8f0632\n",
            "  Running command git checkout -q ae49b218c3d718df90d8e4a109016450fb8f0632\n",
            "  Resolved https://github.com/huggingface/transformers.git to commit ae49b218c3d718df90d8e4a109016450fb8f0632\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging==23.2 in /usr/local/lib/python3.10/dist-packages (from axolotl) (23.2)\n",
            "Collecting tokenizers==0.15.0 (from axolotl)\n",
            "  Downloading tokenizers-0.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitsandbytes>=0.41.1 (from axolotl)\n",
            "  Downloading bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate==0.26.1 (from axolotl)\n",
            "  Downloading accelerate-0.26.1-py3-none-any.whl (270 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.9/270.9 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic==2.6.3 in /usr/local/lib/python3.10/dist-packages (from axolotl) (2.6.3)\n",
            "Collecting addict (from axolotl)\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Collecting fire (from axolotl)\n",
            "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML>=6.0 in /usr/local/lib/python3.10/dist-packages (from axolotl) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from axolotl) (2.31.0)\n",
            "Collecting datasets>=2.15.0 (from axolotl)\n",
            "  Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from axolotl) (0.1.99)\n",
            "Collecting wandb (from axolotl)\n",
            "  Downloading wandb-0.16.3-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m82.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops (from axolotl)\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting optimum==1.16.2 (from axolotl)\n",
            "  Downloading optimum-1.16.2-py3-none-any.whl (402 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m402.5/402.5 kB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hf_transfer (from axolotl)\n",
            "  Downloading hf_transfer-0.1.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m89.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorama (from axolotl)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from axolotl) (0.58.1)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.10/dist-packages (from axolotl) (1.25.2)\n",
            "Collecting evaluate==0.4.1 (from axolotl)\n",
            "  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from axolotl) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn==1.2.2 in /usr/local/lib/python3.10/dist-packages (from axolotl) (1.2.2)\n",
            "Collecting pynvml (from axolotl)\n",
            "  Downloading pynvml-11.5.0-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting art (from axolotl)\n",
            "  Downloading art-6.1-py3-none-any.whl (599 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m599.8/599.8 kB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fschat==0.2.36 (from axolotl)\n",
            "  Downloading fschat-0.2.36-py3-none-any.whl (256 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.9/256.9 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gradio==3.50.2 (from axolotl)\n",
            "  Downloading gradio-3.50.2-py3-none-any.whl (20.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.3/20.3 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from axolotl) (2.15.2)\n",
            "Collecting s3fs (from axolotl)\n",
            "  Downloading s3fs-2024.2.0-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: gcsfs in /usr/local/lib/python3.10/dist-packages (from axolotl) (2023.6.0)\n",
            "Collecting trl>=0.7.9 (from axolotl)\n",
            "  Downloading trl-0.7.11-py3-none-any.whl (155 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch==2.1.2 in /usr/local/lib/python3.10/dist-packages (from axolotl) (2.1.2)\n",
            "Collecting xformers>=0.0.23 (from axolotl)\n",
            "  Downloading xformers-0.0.24-cp310-cp310-manylinux2014_x86_64.whl (218.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m218.2/218.2 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.26.1->axolotl) (5.9.5)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate==0.26.1->axolotl) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.26.1->axolotl) (0.4.2)\n",
            "Collecting dill (from evaluate==0.4.1->axolotl)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate==0.4.1->axolotl) (1.5.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate==0.4.1->axolotl) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate==0.4.1->axolotl) (3.4.1)\n",
            "Collecting multiprocess (from evaluate==0.4.1->axolotl)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate==0.4.1->axolotl) (2023.6.0)\n",
            "Collecting responses<0.19 (from evaluate==0.4.1->axolotl)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from fschat==0.2.36->axolotl) (3.9.3)\n",
            "Collecting fastapi (from fschat==0.2.36->axolotl)\n",
            "  Downloading fastapi-0.110.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx (from fschat==0.2.36->axolotl)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting markdown2[all] (from fschat==0.2.36->axolotl)\n",
            "  Downloading markdown2-2.4.13-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nh3 (from fschat==0.2.36->axolotl)\n",
            "  Downloading nh3-0.2.15-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m86.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: prompt-toolkit>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from fschat==0.2.36->axolotl) (3.0.43)\n",
            "Requirement already satisfied: rich>=10.0.0 in /usr/local/lib/python3.10/dist-packages (from fschat==0.2.36->axolotl) (13.7.0)\n",
            "Collecting shortuuid (from fschat==0.2.36->axolotl)\n",
            "  Downloading shortuuid-1.0.12-py3-none-any.whl (10 kB)\n",
            "Collecting tiktoken (from fschat==0.2.36->axolotl)\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m89.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn (from fschat==0.2.36->axolotl)\n",
            "  Downloading uvicorn-0.27.1-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio==3.50.2->axolotl)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.2->axolotl) (4.2.2)\n",
            "Collecting ffmpy (from gradio==3.50.2->axolotl)\n",
            "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.6.1 (from gradio==3.50.2->axolotl)\n",
            "  Downloading gradio_client-0.6.1-py3-none-any.whl (299 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.2->axolotl) (6.1.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.2->axolotl) (3.1.3)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.2->axolotl) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.2->axolotl) (3.7.1)\n",
            "Collecting orjson~=3.0 (from gradio==3.50.2->axolotl)\n",
            "  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.2->axolotl) (9.4.0)\n",
            "Collecting pydub (from gradio==3.50.2->axolotl)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart (from gradio==3.50.2->axolotl)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio==3.50.2->axolotl)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.2->axolotl) (4.10.0)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio==3.50.2->axolotl)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coloredlogs (from optimum==1.16.2->axolotl)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from optimum==1.16.2->axolotl) (1.12)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic==2.6.3->axolotl) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic==2.6.3->axolotl) (2.16.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.2->axolotl) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.2->axolotl) (3.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->axolotl) (3.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->axolotl) (3.2.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->axolotl) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->axolotl) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->axolotl) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->axolotl) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->axolotl) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->axolotl) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->axolotl) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->axolotl) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->axolotl) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->axolotl) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->axolotl) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->axolotl) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.2->axolotl) (12.3.101)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.15.0->axolotl) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.15.0->axolotl) (0.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->axolotl) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->axolotl) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->axolotl) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->axolotl) (2024.2.2)\n",
            "Collecting tyro>=0.5.11 (from trl>=0.7.9->axolotl)\n",
            "  Downloading tyro-0.7.3-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers@ git+https://github.com/huggingface/transformers.git@ae49b218c3d718df90d8e4a109016450fb8f0632->axolotl) (2023.12.25)\n",
            "INFO: pip is looking at multiple versions of xformers to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting xformers>=0.0.23 (from axolotl)\n",
            "  Downloading xformers-0.0.23.post1-cp310-cp310-manylinux2014_x86_64.whl (213.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire->axolotl) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->axolotl) (2.4.0)\n",
            "Requirement already satisfied: decorator>4.1.2 in /usr/local/lib/python3.10/dist-packages (from gcsfs->axolotl) (4.4.2)\n",
            "Requirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.10/dist-packages (from gcsfs->axolotl) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.10/dist-packages (from gcsfs->axolotl) (1.2.0)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.10/dist-packages (from gcsfs->axolotl) (2.8.0)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->axolotl) (0.41.1)\n",
            "Collecting aiobotocore<3.0.0,>=2.5.4 (from s3fs->axolotl)\n",
            "  Downloading aiobotocore-2.12.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of s3fs to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting s3fs (from axolotl)\n",
            "  Downloading s3fs-2023.12.2-py3-none-any.whl (28 kB)\n",
            "  Downloading s3fs-2023.12.1-py3-none-any.whl (28 kB)\n",
            "  Downloading s3fs-2023.10.0-py3-none-any.whl (28 kB)\n",
            "Collecting aiobotocore~=2.7.0 (from s3fs->axolotl)\n",
            "  Downloading aiobotocore-2.7.0-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting s3fs (from axolotl)\n",
            "  Downloading s3fs-2023.9.2-py3-none-any.whl (28 kB)\n",
            "Collecting aiobotocore~=2.5.4 (from s3fs->axolotl)\n",
            "  Downloading aiobotocore-2.5.4-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.4/73.4 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting s3fs (from axolotl)\n",
            "  Downloading s3fs-2023.9.1-py3-none-any.whl (28 kB)\n",
            "  Downloading s3fs-2023.9.0-py3-none-any.whl (28 kB)\n",
            "  Downloading s3fs-2023.6.0-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->axolotl) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->axolotl) (1.62.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->axolotl) (3.5.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->axolotl) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->axolotl) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->axolotl) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->axolotl) (3.0.1)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb->axolotl) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb->axolotl)\n",
            "  Downloading GitPython-3.1.42-py3-none-any.whl (195 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.4/195.4 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentry-sdk>=1.0.0 (from wandb->axolotl)\n",
            "  Downloading sentry_sdk-1.40.6-py2.py3-none-any.whl (258 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.5/258.5 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb->axolotl)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting setproctitle (from wandb->axolotl)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb->axolotl) (1.4.4)\n",
            "Collecting botocore<1.31.18,>=1.31.17 (from aiobotocore~=2.5.4->s3fs->axolotl)\n",
            "  Downloading botocore-1.31.17-py3-none-any.whl (11.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m96.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wrapt<2.0.0,>=1.10.10 in /usr/local/lib/python3.10/dist-packages (from aiobotocore~=2.5.4->s3fs->axolotl) (1.14.1)\n",
            "Collecting aioitertools<1.0.0,>=0.5.1 (from aiobotocore~=2.5.4->s3fs->axolotl)\n",
            "  Downloading aioitertools-0.11.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->fschat==0.2.36->axolotl) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->fschat==0.2.36->axolotl) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->fschat==0.2.36->axolotl) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->fschat==0.2.36->axolotl) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->fschat==0.2.36->axolotl) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->fschat==0.2.36->axolotl) (4.0.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.50.2->axolotl) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.50.2->axolotl) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.50.2->axolotl) (0.12.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb->axolotl)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.2->gcsfs->axolotl) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.2->gcsfs->axolotl) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.2->gcsfs->axolotl) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib->gcsfs->axolotl) (1.3.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.50.2->axolotl) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.50.2->axolotl) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.50.2->axolotl) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.50.2->axolotl) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.50.2->axolotl) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.50.2->axolotl) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate==0.4.1->axolotl) (2023.4)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit>=3.0.0->fschat==0.2.36->axolotl) (0.2.13)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.0.0->fschat==0.2.36->axolotl) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.0.0->fschat==0.2.36->axolotl) (2.16.1)\n",
            "Collecting docstring-parser>=0.14.1 (from tyro>=0.5.11->trl>=0.7.9->axolotl)\n",
            "  Downloading docstring_parser-0.15-py3-none-any.whl (36 kB)\n",
            "Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl>=0.7.9->axolotl)\n",
            "  Downloading shtab-1.7.0-py3-none-any.whl (14 kB)\n",
            "Collecting h11>=0.8 (from uvicorn->fschat==0.2.36->axolotl)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting humanfriendly>=9.1 (from coloredlogs->optimum==1.16.2->axolotl)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting starlette<0.37.0,>=0.36.3 (from fastapi->fschat==0.2.36->axolotl)\n",
            "  Downloading starlette-0.36.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->gcsfs->axolotl) (2.11.1)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->gcsfs->axolotl) (2.3.3)\n",
            "Requirement already satisfied: google-resumable-media>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->gcsfs->axolotl) (2.7.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->fschat==0.2.36->axolotl) (3.7.1)\n",
            "Collecting httpcore==1.* (from httpx->fschat==0.2.36->axolotl)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->fschat==0.2.36->axolotl) (1.3.1)\n",
            "Collecting wavedrom (from markdown2[all]->fschat==0.2.36->axolotl)\n",
            "  Downloading wavedrom-2.0.3.post3.tar.gz (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.7/137.7 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->optimum==1.16.2->axolotl) (1.3.0)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from botocore<1.31.18,>=1.31.17->aiobotocore~=2.5.4->s3fs->axolotl)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->axolotl)\n",
            "  Downloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->axolotl)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage->gcsfs->axolotl) (1.62.0)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media>=2.3.2->google-cloud-storage->gcsfs->axolotl) (1.5.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2->axolotl) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2->axolotl) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2->axolotl) (0.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.0.0->fschat==0.2.36->axolotl) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs->axolotl) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs->axolotl) (3.2.2)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->fschat==0.2.36->axolotl) (1.2.0)\n",
            "Collecting svgwrite (from wavedrom->markdown2[all]->fschat==0.2.36->axolotl)\n",
            "  Downloading svgwrite-1.4.3-py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.1/67.1 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: transformers, fire, peft, ffmpy, wavedrom\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.39.0.dev0-py3-none-any.whl size=8551480 sha256=8c8ee7d2c1f6b9d6f27727d7251b444b8a73ac22f4dc7a4512fcadde81ca6371\n",
            "  Stored in directory: /root/.cache/pip/wheels/66/a1/0f/b2970db5cd88e25a562f6cddb1bfe32dad96bec0582979fc79\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116934 sha256=d5cec0a79460889166c80129ec9d9ba732554efd61fca9bb572fd3a23617cd09\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/d4/f7/9404e5db0116bd4d43e5666eaa3e70ab53723e1e3ea40c9a95\n",
            "  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for peft: filename=peft-0.9.1.dev0-py3-none-any.whl size=191000 sha256=bc30b96f453aeef382bf719750a0605d7a247b4f3b4a3988d317d1d567948273\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-a9u_44v_/wheels/d7/c7/de/1368fac8590e1b103ddc2ec2a28ad51d83aded1a3830e8a087\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=5f0f20815e74f3f9a88693a78eb376f0d5dee53da01fd19cfdd7658835fd7aef\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n",
            "  Building wheel for wavedrom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wavedrom: filename=wavedrom-2.0.3.post3-py2.py3-none-any.whl size=30052 sha256=37966c2d6a5003d6cf20cdb1b8a9482236b95587a1efcc42033d7403871d4be8\n",
            "  Stored in directory: /root/.cache/pip/wheels/9c/52/8c/38b454b42f712f325e26f633287484c7dc1ad469e1580c5954\n",
            "Successfully built transformers fire peft ffmpy wavedrom\n",
            "Installing collected packages: pydub, nh3, ffmpy, addict, websockets, urllib3, svgwrite, smmap, shtab, shortuuid, setproctitle, semantic-version, python-multipart, pynvml, orjson, markdown2, jmespath, humanfriendly, hf_transfer, h11, fire, einops, docstring-parser, docker-pycreds, dill, colorama, art, aioitertools, aiofiles, wavedrom, uvicorn, starlette, sentry-sdk, multiprocess, httpcore, gitdb, coloredlogs, botocore, bitsandbytes, tyro, tiktoken, responses, httpx, GitPython, fastapi, aiobotocore, xformers, wandb, tokenizers, s3fs, gradio-client, fschat, datasets, accelerate, transformers, gradio, evaluate, trl, peft, optimum, axolotl\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.7\n",
            "    Uninstalling urllib3-2.0.7:\n",
            "      Successfully uninstalled urllib3-2.0.7\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.15.2\n",
            "    Uninstalling tokenizers-0.15.2:\n",
            "      Successfully uninstalled tokenizers-0.15.2\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.38.1\n",
            "    Uninstalling transformers-4.38.1:\n",
            "      Successfully uninstalled transformers-4.38.1\n",
            "  Running setup.py develop for axolotl\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\n",
            "torchvision 0.16.0+cu121 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed GitPython-3.1.42 accelerate-0.26.1 addict-2.4.0 aiobotocore-2.5.4 aiofiles-23.2.1 aioitertools-0.11.0 art-6.1 axolotl-0.4.0 bitsandbytes-0.42.0 botocore-1.31.17 colorama-0.4.6 coloredlogs-15.0.1 datasets-2.18.0 dill-0.3.8 docker-pycreds-0.4.0 docstring-parser-0.15 einops-0.7.0 evaluate-0.4.1 fastapi-0.110.0 ffmpy-0.3.2 fire-0.5.0 fschat-0.2.36 gitdb-4.0.11 gradio-3.50.2 gradio-client-0.6.1 h11-0.14.0 hf_transfer-0.1.6 httpcore-1.0.4 httpx-0.27.0 humanfriendly-10.0 jmespath-1.0.1 markdown2-2.4.13 multiprocess-0.70.16 nh3-0.2.15 optimum-1.16.2 orjson-3.9.15 peft-0.9.1.dev0 pydub-0.25.1 pynvml-11.5.0 python-multipart-0.0.9 responses-0.18.0 s3fs-2023.6.0 semantic-version-2.10.0 sentry-sdk-1.40.6 setproctitle-1.3.3 shortuuid-1.0.12 shtab-1.7.0 smmap-5.0.1 starlette-0.36.3 svgwrite-1.4.3 tiktoken-0.6.0 tokenizers-0.15.0 transformers-4.39.0.dev0 trl-0.7.11 tyro-0.7.3 urllib3-1.26.18 uvicorn-0.27.1 wandb-0.16.3 wavedrom-2.0.3.post3 websockets-11.0.3 xformers-0.0.23.post1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "urllib3"
                ]
              },
              "id": "156bf4d18ca848efb48a42c249ec2b21"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flash-attn==2.5.0\n",
            "  Downloading flash_attn-2.5.0.tar.gz (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from flash-attn==2.5.0) (2.1.2)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from flash-attn==2.5.0) (0.7.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from flash-attn==2.5.0) (23.2)\n",
            "Collecting ninja (from flash-attn==2.5.0)\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn==2.5.0) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn==2.5.0) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn==2.5.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn==2.5.0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn==2.5.0) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn==2.5.0) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn==2.5.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn==2.5.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn==2.5.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn==2.5.0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn==2.5.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn==2.5.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn==2.5.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn==2.5.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn==2.5.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn==2.5.0) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn==2.5.0) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn==2.5.0) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->flash-attn==2.5.0) (12.3.101)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->flash-attn==2.5.0) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->flash-attn==2.5.0) (1.3.0)\n",
            "Building wheels for collected packages: flash-attn\n",
            "  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flash-attn: filename=flash_attn-2.5.0-cp310-cp310-linux_x86_64.whl size=120823033 sha256=3335e74258645eb190597754d42c2fee391fbdeb772847f9e1de12da60450a33\n",
            "  Stored in directory: /root/.cache/pip/wheels/9e/c3/22/a576eb5627fb2c30dc4679a33d67d34d922d6dbeb24a9119b2\n",
            "Successfully built flash-attn\n",
            "Installing collected packages: ninja, flash-attn\n",
            "Successfully installed flash-attn-2.5.0 ninja-1.11.1.1\n",
            "Collecting deepspeed==0.13.1\n",
            "  Downloading deepspeed-0.13.1.tar.gz (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting hjson (from deepspeed==0.13.1)\n",
            "  Downloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.13.1) (1.11.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.13.1) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.13.1) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.13.1) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.13.1) (9.0.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.13.1) (2.6.3)\n",
            "Requirement already satisfied: pynvml in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.13.1) (11.5.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.13.1) (2.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.13.1) (4.66.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->deepspeed==0.13.1) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic->deepspeed==0.13.1) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic->deepspeed==0.13.1) (4.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.13.1) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.13.1) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.13.1) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.13.1) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.13.1) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.13.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.13.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.13.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.13.1) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.13.1) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.13.1) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.13.1) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.13.1) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.13.1) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.13.1) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.13.1) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.13.1) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->deepspeed==0.13.1) (12.3.101)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->deepspeed==0.13.1) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->deepspeed==0.13.1) (1.3.0)\n",
            "Building wheels for collected packages: deepspeed\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepspeed: filename=deepspeed-0.13.1-py3-none-any.whl size=1350299 sha256=4b67716a2fa393588c09ebd0a4511b5e38d4792b095f831c1330230ce933436a\n",
            "  Stored in directory: /root/.cache/pip/wheels/0f/fb/b5/b159b3500525eca167d8ca6e3a7e224b6075045cac90f47cf7\n",
            "Successfully built deepspeed\n",
            "Installing collected packages: hjson, deepspeed\n",
            "Successfully installed deepspeed-0.13.1 hjson-3.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==\"2.1.2\"\n",
        "!pip install -e git+https://github.com/OpenAccess-AI-Collective/axolotl#egg=axolotl\n",
        "!pip install flash-attn==\"2.5.0\"\n",
        "!pip install deepspeed==\"0.13.1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BW2MFr7HTjub"
      },
      "source": [
        "## Create an yaml config file"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/OpenAccess-AI-Collective/axolotl/tree/main?tab=readme-ov-file#config\n",
        "\n",
        "https://github.com/OpenAccess-AI-Collective/axolotl/blob/main/examples/mistral/Mistral-7b-example/config.yml"
      ],
      "metadata": {
        "id": "Q4S7LZdZb-4Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9pkF2dSoQEUN"
      },
      "outputs": [],
      "source": [
        "import yaml\n",
        "\n",
        "# Your YAML string\n",
        "yaml_string = \"\"\"\n",
        "base_model: mistralai/Mistral-7B-Instruct-v0.2\n",
        "model_type: MistralForCausalLM\n",
        "tokenizer_type: LlamaTokenizer\n",
        "is_mistral_derived_model: true # sets padding to 'left'\n",
        "\n",
        "# optional overrides to the bnb 4bit quantization configuration\n",
        "bnb_config_kwargs:\n",
        "  # These are default values\n",
        "  llm_int8_has_fp16_weight: false\n",
        "  bnb_4bit_quant_type: nf4\n",
        "  bnb_4bit_use_double_quant: true\n",
        "\n",
        "load_in_8bit: false\n",
        "# Use bitsandbytes 4 bit\n",
        "load_in_4bit: true\n",
        "strict: false\n",
        "\n",
        "datasets:\n",
        "  - path: drive/MyDrive/mistral-finetune/data/rel-ext-train.jsonl\n",
        "    type:\n",
        "      system_prompt: \"\"\n",
        "      field_system: system\n",
        "      field_instruction: input\n",
        "      field_output: output\n",
        "      format: >\n",
        "            [INST] You are an NLP expert tasked with entity and relation extraction. Here is a list of potential relation types: ['/business/company/advisors',\n",
        "            '/business/location', '/business/person/company', '/location/administrative_division/country',\n",
        "            '/location/country/administrative_divisions', '/location/located_in', '/people/deceasedperson/place_of_death',\n",
        "            '/people/person/nationality', '/people/person/place_lived','/people/person/place_of_birth']\n",
        "\n",
        "            What relations in the given list might be included in the given sentence? Make sure to use only relations from the list provided!\n",
        "\n",
        "            The given sentence is: '{input}'\n",
        "\n",
        "            If none present, answer: None.\n",
        "\n",
        "            Respond with relationship triples, e.g. (head entity 1, relation 1, tail entity 1), (head entity 2, relation 2, tail entity 2), (...)\n",
        "\n",
        "            Take care, your answer is only valid if it follows the correct format! [/INST]\n",
        "\n",
        "# How much of the dataset to set aside as evaluation. 1 = 100%, 0.50 = 50%, etc. 0 for no eval.\n",
        "val_set_size: 0.2\n",
        "\n",
        "# Where to save the full-finetuned model to\n",
        "output_dir: drive/MyDrive/mistral-finetune/rel-ext/r32alpha16\n",
        "\n",
        "adapter: qlora\n",
        "lora_model_dir:\n",
        "\n",
        "sequence_len: 512\n",
        "sample_packing: false\n",
        "pad_to_sequence_len: true\n",
        "\n",
        "lora_r: 32\n",
        "lora_alpha: 16\n",
        "lora_dropout: 0.05\n",
        "lora_target_modules:\n",
        "lora_target_linear: true # If true, will target all linear modules\n",
        "lora_fan_in_fan_out:\n",
        "\n",
        "\n",
        "# wandb configuration if you're using it\n",
        "# Make sure your `WANDB_API_KEY` environment variable is set (recommended) or you login to wandb with `wandb login`.\n",
        "wandb_mode: # \"offline\" to save run metadata locally and not sync to the server, \"disabled\" to turn off wandb\n",
        "wandb_project: mistral-rel-finetune\n",
        "wandb_entity: # A wandb Team name if using a Team\n",
        "wandb_watch:\n",
        "wandb_name: r32alpha16 # Set the name of your wandb run\n",
        "wandb_run_id: # Set the ID of your wandb run\n",
        "wandb_log_model: save_steps # \"checkpoint\" to log model to wandb Artifacts every `save_steps` or \"end\" to log only at the end of training\n",
        "\n",
        "\n",
        "gradient_accumulation_steps: 1\n",
        "# The number of samples to include in each batch. This is the number of samples sent to each GPU.\n",
        "micro_batch_size: 2\n",
        "num_epochs: 1\n",
        "max_steps: 500\n",
        "optimizer: paged_adamw_8bit\n",
        "lr_scheduler: cosine\n",
        "learning_rate: 0.000025\n",
        "\n",
        "train_on_inputs: false\n",
        "group_by_length: false\n",
        "bf16: false\n",
        "# Use CUDA fp16\n",
        "fp16: true\n",
        "tf32: false\n",
        "\n",
        "gradient_checkpointing: true\n",
        "early_stopping_patience:\n",
        "resume_from_checkpoint:\n",
        "local_rank:\n",
        "logging_steps: 25\n",
        "xformers_attention:\n",
        "flash_attention: false\n",
        "\n",
        "warmup_steps: 1\n",
        "evals_per_epoch:\n",
        "saves_per_epoch:\n",
        "debug:\n",
        "deepspeed:\n",
        "weight_decay: 0.0\n",
        "fsdp:\n",
        "fsdp_config:\n",
        "special_tokens:\n",
        "  bos_token: \"<s>\"\n",
        "  eos_token: \"</s>\"\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Convert the YAML string to a Python dictionary\n",
        "yaml_dict = yaml.safe_load(yaml_string)\n",
        "\n",
        "# Specify your file path\n",
        "file_path = 'drive/MyDrive/mistral-finetune/axolotl-mistral-relext-r32alpha16.yaml'\n",
        "\n",
        "# Write the YAML file\n",
        "with open(file_path, 'w') as file:\n",
        "    yaml.dump(yaml_dict, file)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bidoj8YLTusD"
      },
      "source": [
        "## Launch the training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydTI2Jk2RStU",
        "outputId": "ad17a0dc-e95d-4855-f983-46593e8f90d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "[2024-03-04 16:49:59,542] [INFO] [datasets.<module>:58] [PID:7864] PyTorch version 2.1.2 available.\n",
            "[2024-03-04 16:49:59,543] [INFO] [datasets.<module>:95] [PID:7864] TensorFlow version 2.15.0 available.\n",
            "[2024-03-04 16:49:59,544] [INFO] [datasets.<module>:108] [PID:7864] JAX version 0.4.23 available.\n",
            "2024-03-04 16:50:01.529642: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-04 16:50:01.529694: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-04 16:50:01.531056: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-04 16:50:03.211321: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "[2024-03-04 16:50:05,218] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2024-03-04 16:50:08,276] [INFO] [axolotl.normalize_config:178] [PID:7864] [RANK:0] GPU memory usage baseline: 0.000GB (+0.255GB misc)\u001b[39m\n",
            "                                 dP            dP   dP \n",
            "                                 88            88   88 \n",
            "      .d8888b. dP.  .dP .d8888b. 88 .d8888b. d8888P 88 \n",
            "      88'  `88  `8bd8'  88'  `88 88 88'  `88   88   88 \n",
            "      88.  .88  .d88b.  88.  .88 88 88.  .88   88   88 \n",
            "      `88888P8 dP'  `dP `88888P' dP `88888P'   dP   dP \n",
            "                                                       \n",
            "                                                       \n",
            "\n",
            "\u001b[33m[2024-03-04 16:50:08,279] [WARNING] [axolotl.scripts.check_user_token:449] [PID:7864] [RANK:0] Error verifying HuggingFace token. Remember to log in using `huggingface-cli login` and get your access token from https://huggingface.co/settings/tokens if you want to use gated models or datasets.\u001b[39m\n",
            "[2024-03-04 16:50:08,674] [DEBUG] [axolotl.load_tokenizer:245] [PID:7864] [RANK:0] EOS: 2 / </s>\u001b[39m\n",
            "[2024-03-04 16:50:08,674] [DEBUG] [axolotl.load_tokenizer:246] [PID:7864] [RANK:0] BOS: 1 / <s>\u001b[39m\n",
            "[2024-03-04 16:50:08,674] [DEBUG] [axolotl.load_tokenizer:247] [PID:7864] [RANK:0] PAD: 2 / </s>\u001b[39m\n",
            "[2024-03-04 16:50:08,675] [DEBUG] [axolotl.load_tokenizer:248] [PID:7864] [RANK:0] UNK: 0 / <unk>\u001b[39m\n",
            "[2024-03-04 16:50:08,675] [INFO] [axolotl.load_tokenizer:259] [PID:7864] [RANK:0] No Chat template selected. Consider adding a chat template for easier inference.\u001b[39m\n",
            "[2024-03-04 16:50:08,675] [INFO] [axolotl.load_tokenized_prepared_datasets:191] [PID:7864] [RANK:0] Unable to find prepared dataset in last_run_prepared/64aa487dea82bb5a0e5e12a7288e1b71\u001b[39m\n",
            "[2024-03-04 16:50:08,675] [INFO] [axolotl.load_tokenized_prepared_datasets:192] [PID:7864] [RANK:0] Loading raw datasets...\u001b[39m\n",
            "\u001b[33m[2024-03-04 16:50:08,675] [WARNING] [axolotl.load_tokenized_prepared_datasets:194] [PID:7864] [RANK:0] Processing datasets during training can lead to VRAM instability. Please pre-process your dataset.\u001b[39m\n",
            "[2024-03-04 16:50:08,675] [INFO] [axolotl.load_tokenized_prepared_datasets:201] [PID:7864] [RANK:0] No seed provided, using default seed of 42\u001b[39m\n",
            "Tokenizing Prompts (num_proc=2): 100% 974/974 [00:01<00:00, 510.70 examples/s]\n",
            "[2024-03-04 16:50:10,978] [INFO] [axolotl.load_tokenized_prepared_datasets:414] [PID:7864] [RANK:0] merging datasets\u001b[39m\n",
            "Dropping Long Sequences (num_proc=2): 100% 974/974 [00:00<00:00, 1795.84 examples/s]\n",
            "[2024-03-04 16:50:11,587] [INFO] [axolotl.load_tokenized_prepared_datasets:424] [PID:7864] [RANK:0] Saving merged prepared dataset to disk... last_run_prepared/64aa487dea82bb5a0e5e12a7288e1b71\u001b[39m\n",
            "Saving the dataset (1/1 shards): 100% 974/974 [00:00<00:00, 55380.48 examples/s]\n",
            "[2024-03-04 16:50:11,616] [DEBUG] [axolotl.log:61] [PID:7864] [RANK:0] total_num_tokens: 307650\u001b[39m\n",
            "[2024-03-04 16:50:11,626] [DEBUG] [axolotl.log:61] [PID:7864] [RANK:0] `total_supervised_tokens: 27991`\u001b[39m\n",
            "[2024-03-04 16:50:11,626] [DEBUG] [axolotl.log:61] [PID:7864] [RANK:0] total_num_steps: 390\u001b[39m\n",
            "[2024-03-04 16:50:11,626] [INFO] [axolotl.prepare_dataset:124] [PID:7864] [RANK:0] Maximum number of steps set at 390\u001b[39m\n",
            "[2024-03-04 16:50:11,626] [DEBUG] [axolotl.train.log:61] [PID:7864] [RANK:0] loading tokenizer... mistralai/Mistral-7B-Instruct-v0.2\u001b[39m\n",
            "[2024-03-04 16:50:11,961] [DEBUG] [axolotl.load_tokenizer:245] [PID:7864] [RANK:0] EOS: 2 / </s>\u001b[39m\n",
            "[2024-03-04 16:50:11,961] [DEBUG] [axolotl.load_tokenizer:246] [PID:7864] [RANK:0] BOS: 1 / <s>\u001b[39m\n",
            "[2024-03-04 16:50:11,961] [DEBUG] [axolotl.load_tokenizer:247] [PID:7864] [RANK:0] PAD: 2 / </s>\u001b[39m\n",
            "[2024-03-04 16:50:11,961] [DEBUG] [axolotl.load_tokenizer:248] [PID:7864] [RANK:0] UNK: 0 / <unk>\u001b[39m\n",
            "[2024-03-04 16:50:11,961] [INFO] [axolotl.load_tokenizer:259] [PID:7864] [RANK:0] No Chat template selected. Consider adding a chat template for easier inference.\u001b[39m\n",
            "[2024-03-04 16:50:11,961] [DEBUG] [axolotl.train.log:61] [PID:7864] [RANK:0] loading model and peft_config...\u001b[39m\n",
            "Loading checkpoint shards: 100% 3/3 [01:10<00:00, 23.43s/it]\n",
            "[2024-03-04 16:51:25,490] [INFO] [axolotl.load_model:660] [PID:7864] [RANK:0] GPU memory usage after model load: 4.343GB (+0.146GB cache, +0.368GB misc)\u001b[39m\n",
            "[2024-03-04 16:51:25,520] [INFO] [axolotl.load_model:701] [PID:7864] [RANK:0] converting PEFT model w/ prepare_model_for_kbit_training\u001b[39m\n",
            "[2024-03-04 16:51:25,524] [INFO] [axolotl.load_model:710] [PID:7864] [RANK:0] converting modules to torch.float16 for flash attention\u001b[39m\n",
            "[2024-03-04 16:51:25,529] [INFO] [axolotl.load_lora:825] [PID:7864] [RANK:0] found linear modules: ['gate_proj', 'down_proj', 'k_proj', 'o_proj', 'q_proj', 'v_proj', 'up_proj']\u001b[39m\n",
            "trainable params: 83,886,080 || all params: 7,325,618,176 || trainable%: 1.1451058188485088\n",
            "[2024-03-04 16:51:26,651] [INFO] [axolotl.load_model:750] [PID:7864] [RANK:0] GPU memory usage after adapters: 4.672GB (+0.942GB cache, +0.368GB misc)\u001b[39m\n",
            "[2024-03-04 16:51:26,667] [INFO] [axolotl.train.log:61] [PID:7864] [RANK:0] Pre-saving adapter config to drive/MyDrive/mistral-finetune/rel-ext/r32alpha16\u001b[39m\n",
            "[2024-03-04 16:51:26,745] [INFO] [axolotl.train.log:61] [PID:7864] [RANK:0] Starting trainer...\u001b[39m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maareias\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20240304_165128-ul4otteb\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mr32alpha16\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/aareias/mistral-rel-finetune\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/aareias/mistral-rel-finetune/runs/ul4otteb\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n",
            "[2024-03-04 16:51:28,881] [INFO] [axolotl.callbacks.on_train_begin:752] [PID:7864] [RANK:0] The Axolotl config has been saved to the WandB run under files.\u001b[39m\n",
            "[2024-03-04 16:51:28,884] [INFO] [axolotl.callbacks.on_train_begin:752] [PID:7864] [RANK:0] The Axolotl config has been saved to the WandB run under files.\u001b[39m\n",
            "  0% 1/390 [00:04<30:26,  4.70s/it][2024-03-04 16:51:36,813] [INFO] [axolotl.callbacks.on_step_end:123] [PID:7864] [RANK:0] GPU memory usage while training: 4.692GB (+1.086GB cache, +0.638GB misc)\u001b[39m\n",
            "{'loss': 1.337, 'grad_norm': 1.302741289138794, 'learning_rate': 2.4820659688248116e-05, 'epoch': 0.06}\n",
            "{'loss': 0.2311, 'grad_norm': 4.17349100112915, 'learning_rate': 2.414730119791611e-05, 'epoch': 0.13}\n",
            "{'loss': 0.1725, 'grad_norm': 1.2799317836761475, 'learning_rate': 2.3000758704679398e-05, 'epoch': 0.19}\n",
            "{'loss': 0.1649, 'grad_norm': 0.8382508754730225, 'learning_rate': 2.1427611717149564e-05, 'epoch': 0.26}\n",
            "{'loss': 0.1429, 'grad_norm': 0.7152303457260132, 'learning_rate': 1.9491771005389816e-05, 'epoch': 0.32}\n",
            "{'loss': 0.1266, 'grad_norm': 1.1014184951782227, 'learning_rate': 1.7271882157885502e-05, 'epoch': 0.38}\n",
            "{'loss': 0.1273, 'grad_norm': 0.8291930556297302, 'learning_rate': 1.485813052083971e-05, 'epoch': 0.45}\n",
            "{'loss': 0.1376, 'grad_norm': 0.9532898664474487, 'learning_rate': 1.2348577322534194e-05, 'epoch': 0.51}\n",
            "{'loss': 0.1957, 'grad_norm': 4.328305244445801, 'learning_rate': 9.84517583160159e-06, 'epoch': 0.58}\n",
            "{'loss': 0.1141, 'grad_norm': 1.570357322692871, 'learning_rate': 7.449629397017634e-06, 'epoch': 0.64}\n",
            "{'loss': 0.099, 'grad_norm': 0.415975958108902, 'learning_rate': 5.259259641345276e-06, 'epoch': 0.71}\n",
            "{'loss': 0.1048, 'grad_norm': 2.5756008625030518, 'learning_rate': 3.3630526662761104e-06, 'epoch': 0.77}\n",
            "{'loss': 0.0951, 'grad_norm': 0.7361948490142822, 'learning_rate': 1.8380438975755158e-06, 'epoch': 0.83}\n",
            "{'loss': 0.1121, 'grad_norm': 1.8112717866897583, 'learning_rate': 7.461884389517781e-07, 'epoch': 0.9}\n",
            "{'loss': 0.1224, 'grad_norm': 3.520622730255127, 'learning_rate': 1.31844080052973e-07, 'epoch': 0.96}\n",
            "100% 390/390 [21:53<00:00,  2.97s/it]\n",
            "  0% 0/98 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 2/98 [00:01<00:52,  1.82it/s]\u001b[A\n",
            "  3% 3/98 [00:02<01:14,  1.28it/s]\u001b[A\n",
            "  4% 4/98 [00:03<01:23,  1.12it/s]\u001b[A\n",
            "  5% 5/98 [00:04<01:29,  1.04it/s]\u001b[A\n",
            "  6% 6/98 [00:05<01:32,  1.00s/it]\u001b[A\n",
            "  7% 7/98 [00:06<01:33,  1.03s/it]\u001b[A\n",
            "  8% 8/98 [00:07<01:34,  1.05s/it]\u001b[A\n",
            "  9% 9/98 [00:08<01:34,  1.06s/it]\u001b[A\n",
            " 10% 10/98 [00:09<01:34,  1.07s/it]\u001b[A\n",
            " 11% 11/98 [00:10<01:33,  1.08s/it]\u001b[A\n",
            " 12% 12/98 [00:12<01:32,  1.08s/it]\u001b[A\n",
            " 13% 13/98 [00:13<01:31,  1.08s/it]\u001b[A\n",
            " 14% 14/98 [00:14<01:30,  1.08s/it]\u001b[A\n",
            " 15% 15/98 [00:15<01:29,  1.08s/it]\u001b[A\n",
            " 16% 16/98 [00:16<01:28,  1.08s/it]\u001b[A\n",
            " 17% 17/98 [00:17<01:28,  1.09s/it]\u001b[A\n",
            " 18% 18/98 [00:18<01:26,  1.09s/it]\u001b[A\n",
            " 19% 19/98 [00:19<01:25,  1.09s/it]\u001b[A\n",
            " 20% 20/98 [00:20<01:24,  1.09s/it]\u001b[A\n",
            " 21% 21/98 [00:21<01:23,  1.09s/it]\u001b[A\n",
            " 22% 22/98 [00:22<01:22,  1.09s/it]\u001b[A\n",
            " 23% 23/98 [00:23<01:21,  1.09s/it]\u001b[A\n",
            " 24% 24/98 [00:25<01:20,  1.09s/it]\u001b[A\n",
            " 26% 25/98 [00:26<01:19,  1.09s/it]\u001b[A\n",
            " 27% 26/98 [00:27<01:18,  1.09s/it]\u001b[A\n",
            " 28% 27/98 [00:28<01:17,  1.09s/it]\u001b[A\n",
            " 29% 28/98 [00:29<01:16,  1.09s/it]\u001b[A\n",
            " 30% 29/98 [00:30<01:15,  1.09s/it]\u001b[A\n",
            " 31% 30/98 [00:31<01:13,  1.09s/it]\u001b[A\n",
            " 32% 31/98 [00:32<01:12,  1.09s/it]\u001b[A\n",
            " 33% 32/98 [00:33<01:11,  1.09s/it]\u001b[A\n",
            " 34% 33/98 [00:34<01:10,  1.09s/it]\u001b[A\n",
            " 35% 34/98 [00:35<01:09,  1.09s/it]\u001b[A\n",
            " 36% 35/98 [00:37<01:08,  1.09s/it]\u001b[A\n",
            " 37% 36/98 [00:38<01:07,  1.09s/it]\u001b[A\n",
            " 38% 37/98 [00:39<01:06,  1.09s/it]\u001b[A\n",
            " 39% 38/98 [00:40<01:05,  1.09s/it]\u001b[A\n",
            " 40% 39/98 [00:41<01:04,  1.09s/it]\u001b[A\n",
            " 41% 40/98 [00:42<01:03,  1.09s/it]\u001b[A\n",
            " 42% 41/98 [00:43<01:01,  1.09s/it]\u001b[A\n",
            " 43% 42/98 [00:44<01:00,  1.09s/it]\u001b[A\n",
            " 44% 43/98 [00:45<00:59,  1.09s/it]\u001b[A\n",
            " 45% 44/98 [00:46<00:58,  1.09s/it]\u001b[A\n",
            " 46% 45/98 [00:47<00:57,  1.09s/it]\u001b[A\n",
            " 47% 46/98 [00:48<00:56,  1.09s/it]\u001b[A\n",
            " 48% 47/98 [00:50<00:55,  1.09s/it]\u001b[A\n",
            " 49% 48/98 [00:51<00:54,  1.09s/it]\u001b[A\n",
            " 50% 49/98 [00:52<00:53,  1.09s/it]\u001b[A\n",
            " 51% 50/98 [00:53<00:52,  1.09s/it]\u001b[A\n",
            " 52% 51/98 [00:54<00:51,  1.09s/it]\u001b[A\n",
            " 53% 52/98 [00:55<00:50,  1.09s/it]\u001b[A\n",
            " 54% 53/98 [00:56<00:49,  1.09s/it]\u001b[A\n",
            " 55% 54/98 [00:57<00:47,  1.09s/it]\u001b[A\n",
            " 56% 55/98 [00:58<00:46,  1.09s/it]\u001b[A\n",
            " 57% 56/98 [00:59<00:45,  1.09s/it]\u001b[A\n",
            " 58% 57/98 [01:00<00:44,  1.09s/it]\u001b[A\n",
            " 59% 58/98 [01:02<00:43,  1.09s/it]\u001b[A\n",
            " 60% 59/98 [01:03<00:42,  1.09s/it]\u001b[A\n",
            " 61% 60/98 [01:04<00:41,  1.09s/it]\u001b[A\n",
            " 62% 61/98 [01:05<00:40,  1.09s/it]\u001b[A\n",
            " 63% 62/98 [01:06<00:39,  1.09s/it]\u001b[A\n",
            " 64% 63/98 [01:07<00:38,  1.09s/it]\u001b[A\n",
            " 65% 64/98 [01:08<00:36,  1.09s/it]\u001b[A\n",
            " 66% 65/98 [01:09<00:35,  1.09s/it]\u001b[A\n",
            " 67% 66/98 [01:10<00:34,  1.09s/it]\u001b[A\n",
            " 68% 67/98 [01:11<00:33,  1.09s/it]\u001b[A\n",
            " 69% 68/98 [01:12<00:32,  1.09s/it]\u001b[A\n",
            " 70% 69/98 [01:14<00:31,  1.09s/it]\u001b[A\n",
            " 71% 70/98 [01:15<00:30,  1.09s/it]\u001b[A\n",
            " 72% 71/98 [01:16<00:29,  1.09s/it]\u001b[A\n",
            " 73% 72/98 [01:17<00:28,  1.09s/it]\u001b[A\n",
            " 74% 73/98 [01:18<00:27,  1.09s/it]\u001b[A\n",
            " 76% 74/98 [01:19<00:26,  1.09s/it]\u001b[A\n",
            " 77% 75/98 [01:20<00:25,  1.09s/it]\u001b[A\n",
            " 78% 76/98 [01:21<00:24,  1.09s/it]\u001b[A\n",
            " 79% 77/98 [01:22<00:22,  1.09s/it]\u001b[A\n",
            " 80% 78/98 [01:23<00:21,  1.09s/it]\u001b[A\n",
            " 81% 79/98 [01:24<00:20,  1.09s/it]\u001b[A\n",
            " 82% 80/98 [01:26<00:19,  1.09s/it]\u001b[A\n",
            " 83% 81/98 [01:27<00:18,  1.09s/it]\u001b[A\n",
            " 84% 82/98 [01:28<00:17,  1.09s/it]\u001b[A\n",
            " 85% 83/98 [01:29<00:16,  1.09s/it]\u001b[A\n",
            " 86% 84/98 [01:30<00:15,  1.09s/it]\u001b[A\n",
            " 87% 85/98 [01:31<00:14,  1.09s/it]\u001b[A\n",
            " 88% 86/98 [01:32<00:13,  1.09s/it]\u001b[A\n",
            " 89% 87/98 [01:33<00:11,  1.09s/it]\u001b[A\n",
            " 90% 88/98 [01:34<00:10,  1.09s/it]\u001b[A\n",
            " 91% 89/98 [01:35<00:09,  1.09s/it]\u001b[A\n",
            " 92% 90/98 [01:36<00:08,  1.09s/it]\u001b[A\n",
            " 93% 91/98 [01:38<00:07,  1.09s/it]\u001b[A\n",
            " 94% 92/98 [01:39<00:06,  1.09s/it]\u001b[A\n",
            " 95% 93/98 [01:40<00:05,  1.09s/it]\u001b[A\n",
            " 96% 94/98 [01:41<00:04,  1.09s/it]\u001b[A\n",
            " 97% 95/98 [01:42<00:03,  1.09s/it]\u001b[A\n",
            " 98% 96/98 [01:43<00:02,  1.09s/it]\u001b[A\n",
            " 99% 97/98 [01:44<00:01,  1.09s/it]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.2268979251384735, 'eval_runtime': 106.2148, 'eval_samples_per_second': 1.836, 'eval_steps_per_second': 0.923, 'epoch': 1.0}\n",
            "100% 390/390 [23:40<00:00,  2.97s/it]\n",
            "100% 98/98 [01:45<00:00,  1.02it/s]\u001b[A\n",
            "{'train_runtime': 1427.2129, 'train_samples_per_second': 0.547, 'train_steps_per_second': 0.273, 'train_loss': 0.21479830589049903, 'epoch': 1.0}\n",
            "100% 390/390 [23:45<00:00,  3.66s/it]\n",
            "[2024-03-04 17:15:14,372] [INFO] [axolotl.train.log:61] [PID:7864] [RANK:0] Training Completed!!! Saving pre-trained model to drive/MyDrive/mistral-finetune/rel-ext/r32alpha16\u001b[39m\n",
            "(PeftModelForCausalLM(   (base_model): LoraModel(     (model): MistralForCausalLM(       (model): MistralModel(         (embed_tokens): Embedding(32000, 4096)         (layers): ModuleList(           (0-31): 32 x MistralDecoderLayer(             (self_attn): MistralSdpaAttention(               (q_proj): lora.Linear4bit(                 (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)                 (lora_dropout): ModuleDict(                   (default): Dropout(p=0.05, inplace=False)                 )                 (lora_A): ModuleDict(                   (default): Linear(in_features=4096, out_features=32, bias=False)                 )                 (lora_B): ModuleDict(                   (default): Linear(in_features=32, out_features=4096, bias=False)                 )                 (lora_embedding_A): ParameterDict()                 (lora_embedding_B): ParameterDict()               )               (k_proj): lora.Linear4bit(                 (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)                 (lora_dropout): ModuleDict(                   (default): Dropout(p=0.05, inplace=False)                 )                 (lora_A): ModuleDict(                   (default): Linear(in_features=4096, out_features=32, bias=False)                 )                 (lora_B): ModuleDict(                   (default): Linear(in_features=32, out_features=1024, bias=False)                 )                 (lora_embedding_A): ParameterDict()                 (lora_embedding_B): ParameterDict()               )               (v_proj): lora.Linear4bit(                 (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)                 (lora_dropout): ModuleDict(                   (default): Dropout(p=0.05, inplace=False)                 )                 (lora_A): ModuleDict(                   (default): Linear(in_features=4096, out_features=32, bias=False)                 )                 (lora_B): ModuleDict(                   (default): Linear(in_features=32, out_features=1024, bias=False)                 )                 (lora_embedding_A): ParameterDict()                 (lora_embedding_B): ParameterDict()               )               (o_proj): lora.Linear4bit(                 (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)                 (lora_dropout): ModuleDict(                   (default): Dropout(p=0.05, inplace=False)                 )                 (lora_A): ModuleDict(                   (default): Linear(in_features=4096, out_features=32, bias=False)                 )                 (lora_B): ModuleDict(                   (default): Linear(in_features=32, out_features=4096, bias=False)                 )                 (lora_embedding_A): ParameterDict()                 (lora_embedding_B): ParameterDict()               )               (rotary_emb): MistralRotaryEmbedding()             )             (mlp): MistralMLP(               (gate_proj): lora.Linear4bit(                 (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)                 (lora_dropout): ModuleDict(                   (default): Dropout(p=0.05, inplace=False)                 )                 (lora_A): ModuleDict(                   (default): Linear(in_features=4096, out_features=32, bias=False)                 )                 (lora_B): ModuleDict(                   (default): Linear(in_features=32, out_features=14336, bias=False)                 )                 (lora_embedding_A): ParameterDict()                 (lora_embedding_B): ParameterDict()               )               (up_proj): lora.Linear4bit(                 (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)                 (lora_dropout): ModuleDict(                   (default): Dropout(p=0.05, inplace=False)                 )                 (lora_A): ModuleDict(                   (default): Linear(in_features=4096, out_features=32, bias=False)                 )                 (lora_B): ModuleDict(                   (default): Linear(in_features=32, out_features=14336, bias=False)                 )                 (lora_embedding_A): ParameterDict()                 (lora_embedding_B): ParameterDict()               )               (down_proj): lora.Linear4bit(                 (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)                 (lora_dropout): ModuleDict(                   (default): Dropout(p=0.05, inplace=False)                 )                 (lora_A): ModuleDict(                   (default): Linear(in_features=14336, out_features=32, bias=False)                 )                 (lora_B): ModuleDict(                   (default): Linear(in_features=32, out_features=4096, bias=False)                 )                 (lora_embedding_A): ParameterDict()                 (lora_embedding_B): ParameterDict()               )               (act_fn): SiLU()             )             (input_layernorm): MistralRMSNorm()             (post_attention_layernorm): MistralRMSNorm()           )         )         (norm): MistralRMSNorm()       )       (lm_head): Linear(in_features=4096, out_features=32000, bias=False)     )   ) ), LlamaTokenizer(name_or_path='mistralai/Mistral-7B-Instruct-v0.2', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '</s>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={ \t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True), \t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True), \t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True), })\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch ▁▂▂▂▃▃▄▄▅▅▆▆▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step ▁▁▂▂▃▃▄▄▅▅▆▆▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                train/grad_norm ▃█▃▂▂▂▂▂█▃▁▅▂▃▇\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate ██▇▇▆▆▅▄▄▃▂▂▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss █▂▁▁▁▁▁▁▂▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss 0.2269\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime 106.2148\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second 1.836\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second 0.923\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch 1.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step 390\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                train/grad_norm 3.52062\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss 0.1224\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos 1.7217182119231488e+16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss 0.2148\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime 1427.2129\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second 0.547\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second 0.273\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mr32alpha16\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/aareias/mistral-rel-finetune/runs/ul4otteb\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240304_165128-ul4otteb/logs\u001b[0m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Buy using the ! the comand will be executed as a bash command\n",
        "import os\n",
        "os.environ[\"WANDB_API_KEY\"] = \"20475519ff6c5ed5b99e2432a603c688e3084404\"\n",
        "!accelerate launch -m axolotl.cli.train drive/MyDrive/mistral-finetune/axolotl-mistral-relext-r32alpha16.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4_lLURhZXpu"
      },
      "source": [
        "## Play with inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBfrls6IZXpu"
      },
      "outputs": [],
      "source": [
        "# Buy using the ! the comand will be executed as a bash command\n",
        "!accelerate launch -m axolotl.cli.inference /content/test_axolotl.yaml \\\n",
        "    --qlora_model_dir=\"./qlora-out\" --gradio"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}