{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4788ad5243474cc58733fd97d86140ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fd82d55ad2f94805b37cdf7a076d2f7e",
              "IPY_MODEL_957304ebfce2401280010c4324cb3ea8",
              "IPY_MODEL_b6f75848e4454185821775784bcd866b"
            ],
            "layout": "IPY_MODEL_b3d1b04d9b4643aa9b06072e8e76e843"
          }
        },
        "fd82d55ad2f94805b37cdf7a076d2f7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a75c112da2714e12b2996b5084fd27f6",
            "placeholder": "​",
            "style": "IPY_MODEL_bdafdfb92209478d9f6611783abdb407",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "957304ebfce2401280010c4324cb3ea8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc65fc2695e34006a922580b78bdb03b",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_62fc2127f1ee465d9bae6c06aa457e75",
            "value": 3
          }
        },
        "b6f75848e4454185821775784bcd866b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2a4e4e9694548dd974e211d966e8e03",
            "placeholder": "​",
            "style": "IPY_MODEL_f169dc9690c64720a14455b25ab2e05c",
            "value": " 3/3 [01:32&lt;00:00, 29.86s/it]"
          }
        },
        "b3d1b04d9b4643aa9b06072e8e76e843": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a75c112da2714e12b2996b5084fd27f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdafdfb92209478d9f6611783abdb407": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc65fc2695e34006a922580b78bdb03b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62fc2127f1ee465d9bae6c06aa457e75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d2a4e4e9694548dd974e211d966e8e03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f169dc9690c64720a14455b25ab2e05c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f56dce779a764a81abc0e0aaf9386f77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f4a32547663e483aa9bca9326eccc715",
              "IPY_MODEL_802a4457a44747e3a060bb53e8822ab9",
              "IPY_MODEL_1138a97c19b24b3ab5092ffb08dde21f"
            ],
            "layout": "IPY_MODEL_f74b9f969a014444887b754977e84d20"
          }
        },
        "f4a32547663e483aa9bca9326eccc715": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ee6decb4f9049e5a3a897dc1553aa08",
            "placeholder": "​",
            "style": "IPY_MODEL_01d7b3f521bb457597eab87d82a6454b",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "802a4457a44747e3a060bb53e8822ab9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b71f65d00cb7476582a122e5883abe37",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8aaa15bed8e9488fa2577ed3b80f6135",
            "value": 3
          }
        },
        "1138a97c19b24b3ab5092ffb08dde21f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7ddca4c3e7f4ce9a4a9bac5d63cf7f4",
            "placeholder": "​",
            "style": "IPY_MODEL_b3a21ecb7ee246bc9b42c3f7ed016cc1",
            "value": " 3/3 [00:08&lt;00:00,  2.70s/it]"
          }
        },
        "f74b9f969a014444887b754977e84d20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ee6decb4f9049e5a3a897dc1553aa08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01d7b3f521bb457597eab87d82a6454b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b71f65d00cb7476582a122e5883abe37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8aaa15bed8e9488fa2577ed3b80f6135": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e7ddca4c3e7f4ce9a4a9bac5d63cf7f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3a21ecb7ee246bc9b42c3f7ed016cc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b101b9d9fa5345aeae0e7af9a2ff3038": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8f16176b384b4d5582771006ba05bc40",
              "IPY_MODEL_4bda7e8506d3458386c7580541dfded8",
              "IPY_MODEL_0a85486f046e48559643aaf228b4387b"
            ],
            "layout": "IPY_MODEL_47151bc6595a4167a0a38f79ad518b46"
          }
        },
        "8f16176b384b4d5582771006ba05bc40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7adafe111cff43d5802a40612634a2dd",
            "placeholder": "​",
            "style": "IPY_MODEL_ce4336f171f14d5fb0cfff0c7fa4fa4f",
            "value": "Map: 100%"
          }
        },
        "4bda7e8506d3458386c7580541dfded8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39adc73b3eb847e9ae44844df190ec44",
            "max": 779,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bf61d07eeb5740da85ea2045b4e7a44d",
            "value": 779
          }
        },
        "0a85486f046e48559643aaf228b4387b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30003789868a4694b9a01340d528061f",
            "placeholder": "​",
            "style": "IPY_MODEL_a901d07beb2648dab6c12c65bd677819",
            "value": " 779/779 [00:00&lt;00:00, 1261.60 examples/s]"
          }
        },
        "47151bc6595a4167a0a38f79ad518b46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7adafe111cff43d5802a40612634a2dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce4336f171f14d5fb0cfff0c7fa4fa4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39adc73b3eb847e9ae44844df190ec44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf61d07eeb5740da85ea2045b4e7a44d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "30003789868a4694b9a01340d528061f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a901d07beb2648dab6c12c65bd677819": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a8ccda2a0d7e429a87627c237b9bcdfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1f1d718ca66b4902ae04a8651b85a630",
              "IPY_MODEL_9aec5f5f6ec648b5b6e75026c526c9e9",
              "IPY_MODEL_048b6ded7f8044f5905309ecc4063008"
            ],
            "layout": "IPY_MODEL_648026667ad8455c80cb19ee75ab8af2"
          }
        },
        "1f1d718ca66b4902ae04a8651b85a630": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db6ff2f03ff74ff0ae03af655918d279",
            "placeholder": "​",
            "style": "IPY_MODEL_ec2e5caf5e29487ba0b06519900f9f95",
            "value": "Map: 100%"
          }
        },
        "9aec5f5f6ec648b5b6e75026c526c9e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc28a936303c400e9a855fe8b1c41eaa",
            "max": 195,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b4ddd230fec743939ed742f10761c2e9",
            "value": 195
          }
        },
        "048b6ded7f8044f5905309ecc4063008": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5502b8fc205c4202b7128cf2f4b4cc3b",
            "placeholder": "​",
            "style": "IPY_MODEL_e5e0e8a796c14e41a8b9f23625eb045a",
            "value": " 195/195 [00:00&lt;00:00, 1055.67 examples/s]"
          }
        },
        "648026667ad8455c80cb19ee75ab8af2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db6ff2f03ff74ff0ae03af655918d279": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec2e5caf5e29487ba0b06519900f9f95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc28a936303c400e9a855fe8b1c41eaa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4ddd230fec743939ed742f10761c2e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5502b8fc205c4202b7128cf2f4b4cc3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5e0e8a796c14e41a8b9f23625eb045a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9631b08289924f68aab5f2b0384ba972": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7ae0f92ba8df4056b07c4d65509dd284",
              "IPY_MODEL_aafa74b60b5d440bb2eadbcefcd899db",
              "IPY_MODEL_5156fd3b5c0b4c0d9a9260c2d383a453"
            ],
            "layout": "IPY_MODEL_a6d630b3451446f5bd245d5bcff4b703"
          }
        },
        "7ae0f92ba8df4056b07c4d65509dd284": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2fdbfd7d02b43ea9ecddd514b02e6ca",
            "placeholder": "​",
            "style": "IPY_MODEL_a972cc11e2c54ec5869223ed80f16846",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "aafa74b60b5d440bb2eadbcefcd899db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c0dea4fabf04d2da21adb174fcc29cf",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c8c7f68aa6b7480893f103856e9cb7f6",
            "value": 3
          }
        },
        "5156fd3b5c0b4c0d9a9260c2d383a453": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21759245e6c0489db0fa5ca2f24a7f95",
            "placeholder": "​",
            "style": "IPY_MODEL_18eae89a759b4e08b2f3252f9d0a1c33",
            "value": " 3/3 [00:08&lt;00:00,  2.68s/it]"
          }
        },
        "a6d630b3451446f5bd245d5bcff4b703": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2fdbfd7d02b43ea9ecddd514b02e6ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a972cc11e2c54ec5869223ed80f16846": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c0dea4fabf04d2da21adb174fcc29cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8c7f68aa6b7480893f103856e9cb7f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "21759245e6c0489db0fa5ca2f24a7f95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18eae89a759b4e08b2f3252f9d0a1c33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/areias/slm-finetunig/blob/main/finetune_mistral.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Fine-tuning Mistral-7b for relationship extraction\n",
        "\n",
        "See how mistral-7b performs at relationship extraction task before and after fine-tuning on 1000 examples."
      ],
      "metadata": {
        "id": "MSds52ZvCWLz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "based on\n",
        "\n",
        "[Fine-tune large models using 🤗 peft adapters, transformers & bitsandbytes](https://colab.research.google.com/drive/1jCkpikz0J2o20FBQmYmAGdiKmJGOMo-o?usp=sharing#scrollTo=WE5GJ6s7y0Xo)\n",
        "\n",
        "\n",
        "[transformers meets bitsandbytes for democratzing Large Language Models (LLMs) through 4bit quantization](https://colab.research.google.com/drive/1VoYNfYDKcKRQRor98Zbf2-9VQTtGJ24k#scrollTo=jq0nX33BmfaC)\n",
        "\n",
        "[Fine-tuning Mistral on your own data](https://github.com/brevdev/notebooks/blob/main/mistral-finetune-own-data.ipynb)\n",
        "\n",
        "[Fine-tuning Large Language Models](https://learn.deeplearning.ai/finetuning-large-language-models/lesson/1/introduction)\n",
        "\n",
        "\n",
        "[Ollama: Running GGUF Models from Hugging Face](https://www.markhneedham.com/blog/2023/10/18/ollama-hugging-face-gguf-models/)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KYy-QW1jstyf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load our fine-tuning data"
      ],
      "metadata": {
        "id": "ol6dhVSPDN8M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q peft\n",
        "! pip install -q git+https://github.com/huggingface/accelerate.git\n",
        "! pip install -q bitsandbytes\n",
        "! pip install -q transformers datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCSw2a-Uc6-2",
        "outputId": "ea846335-bb80-471a-c785-43f4e2cc9b4a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/183.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m174.1/183.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.4/183.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/280.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for accelerate (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.7/536.7 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('drive/My Drive/mistral-finetune/')"
      ],
      "metadata": {
        "id": "xX7DSX6Tf5U6"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Q6OPzWAkdQuM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CImq57GrNSpk",
        "outputId": "45c94263-bb5d-4dd3-93df-255513888bb9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"drive/MyDrive/mistral-finetune/data/nyt10m_finetuning-balanced.csv\")"
      ],
      "metadata": {
        "id": "0ROtsw5ENSk0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df['text'].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiCQF6lbu9Yj",
        "outputId": "89391126-9070-4b52-c684-0e096eebecab"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "974"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBDbTBVKeDdc",
        "outputId": "6561dfec-0ccd-4e3a-c142-6c9b63907b37"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1452"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "aypHxSxKNSek",
        "outputId": "c59238d9-5a5b-4b4c-c9be-a52f1e6be42c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text         h_name  \\\n",
              "0  There were also performers who were born in Lo...  Johnny Rivers   \n",
              "1  Indeed , Mr. Chávez said Sunday that he wished...    Evo Morales   \n",
              "2  Indeed , Mr. Chávez said Sunday that he wished...    Evo Morales   \n",
              "3  Analysts contrast Mr. Chávez 's success at con...    Evo Morales   \n",
              "4  Ecuador 's new president , Rafael Correa , joi...    Evo Morales   \n",
              "\n",
              "      t_name                       relation  \n",
              "0  Louisiana  /people/person/place_of_birth  \n",
              "1    Bolivia     /people/person/nationality  \n",
              "2    Bolivia     /people/person/place_lived  \n",
              "3    Bolivia     /people/person/nationality  \n",
              "4    Bolivia     /people/person/nationality  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fde020d3-65d6-4d0b-a0ec-9892ceed441c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>h_name</th>\n",
              "      <th>t_name</th>\n",
              "      <th>relation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>There were also performers who were born in Lo...</td>\n",
              "      <td>Johnny Rivers</td>\n",
              "      <td>Louisiana</td>\n",
              "      <td>/people/person/place_of_birth</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Indeed , Mr. Chávez said Sunday that he wished...</td>\n",
              "      <td>Evo Morales</td>\n",
              "      <td>Bolivia</td>\n",
              "      <td>/people/person/nationality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Indeed , Mr. Chávez said Sunday that he wished...</td>\n",
              "      <td>Evo Morales</td>\n",
              "      <td>Bolivia</td>\n",
              "      <td>/people/person/place_lived</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Analysts contrast Mr. Chávez 's success at con...</td>\n",
              "      <td>Evo Morales</td>\n",
              "      <td>Bolivia</td>\n",
              "      <td>/people/person/nationality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ecuador 's new president , Rafael Correa , joi...</td>\n",
              "      <td>Evo Morales</td>\n",
              "      <td>Bolivia</td>\n",
              "      <td>/people/person/nationality</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fde020d3-65d6-4d0b-a0ec-9892ceed441c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fde020d3-65d6-4d0b-a0ec-9892ceed441c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fde020d3-65d6-4d0b-a0ec-9892ceed441c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0b56a51f-8823-4f35-94f0-2c8008961628\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0b56a51f-8823-4f35-94f0-2c8008961628')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0b56a51f-8823-4f35-94f0-2c8008961628 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1452,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 974,\n        \"samples\": [\n          \"And in Mexico , rumors abound about development in a remote area of Baja California known as Scorpion Bay .\",\n          \"Hassan Dahir , the vice president of Puntland , a semiautonomous region of Somalia , said eight Islamist militants had been killed , including one who was an American citizen , according to documents found on his body .\",\n          \"PUNAK -- Randy M. , 53 of NYC died March 5 , 2007 in Paris , France .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"h_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 734,\n        \"samples\": [\n          \"Equinix\",\n          \"Havana\",\n          \"Oceanport\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"t_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 442,\n        \"samples\": [\n          \"PCCW\",\n          \"Troma Entertainment\",\n          \"Ontario\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"relation\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"/location/administrative_division/country\",\n          \"/people/person/nationality\",\n          \"/business/company/advisors\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[df['relation'].isna(),'relation']=\"None\"\n",
        "#df = df.loc[~df['relation'].isna()] #remove Nones\n"
      ],
      "metadata": {
        "id": "agWiWweV1KSF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence=df['text'].unique()[31]\n",
        "sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "HOEsvRNrvEAL",
        "outputId": "50519704-0d49-4b3e-b33d-f8b886e99f1b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Among the mourners were Queen Sofía of Spain and Bernadette Chirac , the wife of President Jacques Chirac of France , President Ilham Aliyev of Azerbaijan and young cellists , bearing witness to Mr. Rostropovich 's reputation as a man of the world whose appeal cut across class lines .\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.relation.value_counts() / len(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGQDXpcSbV40",
        "outputId": "455cbf1b-0dc8-44ff-9c18-17586f792d2a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "/people/person/place_lived                    0.176997\n",
              "/location/located_in                          0.153581\n",
              "/business/person/company                      0.125344\n",
              "/location/administrative_division/country     0.082645\n",
              "/people/person/nationality                    0.081956\n",
              "None                                          0.081956\n",
              "/business/location                            0.079890\n",
              "/location/country/administrative_divisions    0.066804\n",
              "/people/person/place_of_birth                 0.058540\n",
              "/business/company/advisors                    0.048898\n",
              "/people/deceasedperson/place_of_death         0.043388\n",
              "Name: relation, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['text']==sentence]"
      ],
      "metadata": {
        "id": "IoJvU-u6yJnw",
        "outputId": "f5576256-a039-4e74-a2be-7ecb0a31f5d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  text             h_name  \\\n",
              "45   Among the mourners were Queen Sofía of Spain a...     Jacques Chirac   \n",
              "46   Among the mourners were Queen Sofía of Spain a...     Jacques Chirac   \n",
              "798  Among the mourners were Queen Sofía of Spain a...  Bernadette Chirac   \n",
              "799  Among the mourners were Queen Sofía of Spain a...  Bernadette Chirac   \n",
              "\n",
              "     t_name                    relation  \n",
              "45   France  /people/person/nationality  \n",
              "46   France  /people/person/place_lived  \n",
              "798  France  /people/person/nationality  \n",
              "799  France  /people/person/place_lived  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c18e7f7c-4eb9-4ea7-87ee-3533b066722d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>h_name</th>\n",
              "      <th>t_name</th>\n",
              "      <th>relation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>Among the mourners were Queen Sofía of Spain a...</td>\n",
              "      <td>Jacques Chirac</td>\n",
              "      <td>France</td>\n",
              "      <td>/people/person/nationality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>Among the mourners were Queen Sofía of Spain a...</td>\n",
              "      <td>Jacques Chirac</td>\n",
              "      <td>France</td>\n",
              "      <td>/people/person/place_lived</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>798</th>\n",
              "      <td>Among the mourners were Queen Sofía of Spain a...</td>\n",
              "      <td>Bernadette Chirac</td>\n",
              "      <td>France</td>\n",
              "      <td>/people/person/nationality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799</th>\n",
              "      <td>Among the mourners were Queen Sofía of Spain a...</td>\n",
              "      <td>Bernadette Chirac</td>\n",
              "      <td>France</td>\n",
              "      <td>/people/person/place_lived</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c18e7f7c-4eb9-4ea7-87ee-3533b066722d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c18e7f7c-4eb9-4ea7-87ee-3533b066722d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c18e7f7c-4eb9-4ea7-87ee-3533b066722d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1bf059d3-3276-4802-87b7-928b833c0ea8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1bf059d3-3276-4802-87b7-928b833c0ea8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1bf059d3-3276-4802-87b7-928b833c0ea8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df[df['text']==sentence]\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Among the mourners were Queen Sof\\u00eda of Spain and Bernadette Chirac , the wife of President Jacques Chirac of France , President Ilham Aliyev of Azerbaijan and young cellists , bearing witness to Mr. Rostropovich 's reputation as a man of the world whose appeal cut across class lines .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"h_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Bernadette Chirac\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"t_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"France\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"relation\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"/people/person/place_lived\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FgaZrFWoccn",
        "outputId": "d585f001-43c0-4356-ef2a-1baf698445ae"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1452"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.text.nunique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zfqs6a1odL0",
        "outputId": "880f9ef2-0267-4dda-80b8-a4901d0d1713"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "974"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from helper_functions import preprocess"
      ],
      "metadata": {
        "id": "kS-7Srfjvs6H"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make sure works for example with no relations\n",
        "data = preprocess(df)\n",
        "data[400]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRV-deeM3yoe",
        "outputId": "87e07368-813f-4294-db9c-f36ff40a977b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'Yesterday , Mr. Sulzberger received support when Donald E. Graham , the chairman and chief executive of the Washington Post Company , urged investors to support the Times Company .',\n",
              " 'output': \"('Washington Post Company', '/business/company/advisors', 'Donald E. Graham'), ('Donald E. Graham', '/business/person/company', 'Washington Post Company')\"}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# and exapmle with multiple relations\n",
        "data[230]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9P6cQoG2_SW",
        "outputId": "7f626ada-ac8f-4bef-b7a0-4f49e142cfc7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'The Real Estate Market Though prices have risen sharply in recent years , real estate agents and developers still talk up Port St. Lucie as a Florida bargain .',\n",
              " 'output': \"('St. Lucie', '/location/located_in', 'Florida')\"}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# as well as your single relation\n",
        "data[:4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxqA50iDxOXc",
        "outputId": "50fbf49c-0345-416b-cebd-e9318c9c6770"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'input': \"There were also performers who were born in Louisiana , including Lucinda Williams , Jerry Lee Lewis and Johnny Rivers , whose '' Secret Agent Man '' had a touch of bayou-country swamp-pop .\",\n",
              "  'output': \"('Johnny Rivers', '/people/person/place_of_birth', 'Louisiana'), ('Jerry Lee Lewis', '/people/person/place_of_birth', 'Louisiana')\"},\n",
              " {'input': \"Indeed , Mr. Chávez said Sunday that he wished Mr. Correa the '' best of luck '' from Venezuela , where he appeared on television with President Evo Morales of Bolivia to commemorate the opening of a milk processing plant built in western Venezuela with financing from Iran .\",\n",
              "  'output': \"('Evo Morales', '/people/person/nationality', 'Bolivia'), ('Evo Morales', '/people/person/place_lived', 'Bolivia')\"},\n",
              " {'input': \"Analysts contrast Mr. Chávez 's success at consolidating power in Venezuela with the troubles faced by President Evo Morales in Bolivia , where a constitution-writing assembly has been stalled by fractious delegates and regional power struggles .\",\n",
              "  'output': \"('Evo Morales', '/people/person/nationality', 'Bolivia')\"},\n",
              " {'input': \"Ecuador 's new president , Rafael Correa , joins not only Chávez but also Evo Morales of Bolivia and Daniel Ortega in Nicaragua .\",\n",
              "  'output': \"('Evo Morales', '/people/person/nationality', 'Bolivia')\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.relation.value_counts(dropna=False)"
      ],
      "metadata": {
        "id": "EihweA1iVuWC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "806ce570-a739-4cd6-b5fa-0c717905dc0c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "/people/person/place_lived                    257\n",
              "/location/located_in                          223\n",
              "/business/person/company                      182\n",
              "/location/administrative_division/country     120\n",
              "/people/person/nationality                    119\n",
              "None                                          119\n",
              "/business/location                            116\n",
              "/location/country/administrative_divisions     97\n",
              "/people/person/place_of_birth                  85\n",
              "/business/company/advisors                     71\n",
              "/people/deceasedperson/place_of_death          63\n",
              "Name: relation, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "relations = np.sort(list(df.relation.unique()))\n",
        "relations = list(relations[:len(relations)-1])\n",
        "relations\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPam1FbUbrJ9",
        "outputId": "49a17099-fe13-4e87-cc19-e6e66b3039ed"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/business/company/advisors',\n",
              " '/business/location',\n",
              " '/business/person/company',\n",
              " '/location/administrative_division/country',\n",
              " '/location/country/administrative_divisions',\n",
              " '/location/located_in',\n",
              " '/people/deceasedperson/place_of_death',\n",
              " '/people/person/nationality',\n",
              " '/people/person/place_lived',\n",
              " '/people/person/place_of_birth']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import formatting_func"
      ],
      "metadata": {
        "id": "6bzq7NFj7U4r"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatting_func(data[0]))"
      ],
      "metadata": {
        "id": "MCT6ILZ7VuMO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2341882-5edf-4cb5-da98-cf40a83041c3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INST] You are an NLP expert tasked with entity and relation extraction. Here is a list of potential relation types: ['/business/company/advisors', '/business/location', '/business/person/company', '/location/administrative_division/country', '/location/country/administrative_divisions', '/location/located_in', '/people/deceasedperson/place_of_death', '/people/person/nationality', '/people/person/place_lived', '/people/person/place_of_birth'] \n",
            "What relations in the given list might be included in the given sentence? Make sure to use only relations from the list provided!\n",
            "The given sentence is: 'There were also performers who were born in Louisiana , including Lucinda Williams , Jerry Lee Lewis and Johnny Rivers , whose '' Secret Agent Man '' had a touch of bayou-country swamp-pop .'\n",
            "If none present, answer: None.\n",
            "Respond with relationship triples, e.g. (head entity 1, relation 1, tail entity 1), (head entity 2, relation 2, tail entity 2), (...) \n",
            "Take care, your answer is only valid if it follows the correct format! [\\INST]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load a quantized Mistral:instruct model"
      ],
      "metadata": {
        "id": "kuWZqB3JRUS9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://huggingface.co/docs/peft/main/en/developer_guides/quantization\n",
        "\n",
        "\n",
        "...since PEFT methods only add extra trainable parameters, this allows you to train a quantized model with a PEFT adapter on top! Combining quantization with PEFT can be a good strategy for training even the largest models on a single GPU. For example, QLoRA is a method that quantizes a model to 4-bits and then trains it with LoRA.\n",
        "\n",
        "\n",
        "bitsandbytes is a quantization library with a Transformers integration. With this integration, you can quantize a model to 8 or 4-bits and enable many other options by configuring the BitsAndBytesConfig class. For example, you can:"
      ],
      "metadata": {
        "id": "wmmB-bubPSDf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "import torch"
      ],
      "metadata": {
        "id": "5h83krKnsKG-"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " https://huggingface.co/docs/peft/main/en/developer_guides/quantization\n",
        "\n",
        "...For example, you can:\n",
        "\n",
        "* set load_in_4bit=True to quantize the model to 4-bits when you load it\n",
        "* set bnb_4bit_quant_type=\"nf4\" to use a special 4-bit data type for weights initialized from a normal distribution\n",
        "* set bnb_4bit_use_double_quant=True to use a nested quantization scheme to quantize the already quantized weights\n",
        "* set bnb_4bit_compute_dtype=torch.bfloat16 to use bfloat16 for faster computation"
      ],
      "metadata": {
        "id": "nummh5EBQwX1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n"
      ],
      "metadata": {
        "id": "bBGal5Uz0Dpi"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pass the config to the from_pretrained method."
      ],
      "metadata": {
        "id": "pqjzb8TkQ7rZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map=\"auto\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "f56dce779a764a81abc0e0aaf9386f77",
            "f4a32547663e483aa9bca9326eccc715",
            "802a4457a44747e3a060bb53e8822ab9",
            "1138a97c19b24b3ab5092ffb08dde21f",
            "f74b9f969a014444887b754977e84d20",
            "6ee6decb4f9049e5a3a897dc1553aa08",
            "01d7b3f521bb457597eab87d82a6454b",
            "b71f65d00cb7476582a122e5883abe37",
            "8aaa15bed8e9488fa2577ed3b80f6135",
            "e7ddca4c3e7f4ce9a4a9bac5d63cf7f4",
            "b3a21ecb7ee246bc9b42c3f7ed016cc1"
          ]
        },
        "id": "K2iMaEKB5N7C",
        "outputId": "c06bd70d-4d6b-42e0-8ae3-13355803d4f5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f56dce779a764a81abc0e0aaf9386f77"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load tokenizer"
      ],
      "metadata": {
        "id": "G_mjxEvYRcLI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://huggingface.co/docs/transformers/en/llm_tutorial#wrong-padding-side\n",
        "\n",
        "LLMs are decoder-only architectures, meaning they continue to iterate on your input prompt. If your inputs do not have the same length, they need to be padded. Since LLMs are not trained to continue from pad tokens, your input needs to be left-padded. Make sure you also don’t forget to pass the attention mask to generate!\n",
        "\n",
        "tokenizer.pad_token = tokenizer.eos_token  # Most LLMs don't have a pad token by default\n"
      ],
      "metadata": {
        "id": "Gb3knHaXjgx7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_id,\n",
        "                                        padding_side=\"left\") # padding on left from brewdev notebook\n",
        "tokenizer.pad_token = tokenizer.eos_token\n"
      ],
      "metadata": {
        "id": "oGD3jrkqsWUe"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Now let's tokenize again with padding and truncation, and set up the tokenize function to make labels and input_ids the same. This is basically what self-supervised fine-tuning is.\n"
      ],
      "metadata": {
        "id": "bXwxRdlBgVe5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 512 # This was an appropriate max length for my dataset\n",
        "\n",
        "def generate_and_tokenize_prompt(prompt):\n",
        "    result = tokenizer(\n",
        "        formatting_func(prompt),\n",
        "        truncation=True,\n",
        "        max_length=max_length,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
        "    return result"
      ],
      "metadata": {
        "id": "y6yXX_RafK-M"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_and_tokenize_prompt(prompt):\n",
        "    return tokenizer(formatting_func(prompt))"
      ],
      "metadata": {
        "id": "I0_ZtZoBfK2D"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate model out of the box\n",
        "\n"
      ],
      "metadata": {
        "id": "eUbYapyPbHJG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import get_relations, get_tuples, get_scores"
      ],
      "metadata": {
        "id": "r8s88sMcT20R"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"eval_prompt = formatting_func(data[230])\n",
        "print(eval_prompt)\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JRCuFLzPb4DK",
        "outputId": "79149bbd-a6ba-4f84-dd47-0e9a7e65e909"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'eval_prompt = formatting_func(data[230])\\nprint(eval_prompt)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Init an eval tokenizer that doesn't add padding or eos token\n",
        "eval_tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model_id,\n",
        "    add_bos_token=True,\n",
        ")\n"
      ],
      "metadata": {
        "id": "6T3tB41lcGjT"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://huggingface.co/docs/transformers/en/generation_strategies\n",
        "\n"
      ],
      "metadata": {
        "id": "SK21Hxe0k5uV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    response  = eval_tokenizer.decode(model.generate(**model_input,\n",
        "                    max_new_tokens=256, repetition_penalty=1.15,\n",
        "                    pad_token_id=eval_tokenizer.eos_token_id)[0], skip_special_tokens=True)\n",
        "    response = response.replace(eval_prompt, \"\")\n",
        "    print(response)\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "Vq8CtOhQcMEU",
        "outputId": "b70ba3f0-f94a-47ce-c3e9-75649abe9245"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\\n\\nmodel.eval()\\nwith torch.no_grad():\\n    response  = eval_tokenizer.decode(model.generate(**model_input,\\n                    max_new_tokens=256, repetition_penalty=1.15,\\n                    pad_token_id=eval_tokenizer.eos_token_id)[0], skip_special_tokens=True)\\n    response = response.replace(eval_prompt, \"\")\\n    print(response)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"response\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_XcYI1pO068C",
        "outputId": "69d2146a-7aea-4bd8-8b9d-8970dacbc0ba"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'response'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"predicted_relations = get_tuples(response.replace(eval_prompt, \"\"))\n",
        "predicted_relations\"\"\""
      ],
      "metadata": {
        "id": "rMEy0M8X8kQW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dd78bd99-bf6b-455f-8de6-4691b5aa86c1"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'predicted_relations = get_tuples(response.replace(eval_prompt, \"\"))\\npredicted_relations'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#predicted_relations.append(('Evo Morales', '/people/person/nationality', 'Bolivia'))"
      ],
      "metadata": {
        "id": "VxBQ0tmQ8cLX"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#predicted_relations"
      ],
      "metadata": {
        "id": "85hTg1a8Ig10"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"import helper_functions\n",
        "from importlib import reload\n",
        "reload(helper_functions)\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8U6ZVf47I6bf",
        "outputId": "d44c289d-b25c-4f6f-da6b-a5a5ce158bd7"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'import helper_functions\\nfrom importlib import reload\\nreload(helper_functions)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"expected_relations = get_relations(data[230])\n",
        "expected_relations\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ZanLDyNxS42r",
        "outputId": "ad34aa86-3a27-4e9c-8e45-3b3ad68a8dda"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'expected_relations = get_relations(data[230])\\nexpected_relations'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"get_scores(expected_relations, [\"None\"])\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "XxJfWFEm8Ti9",
        "outputId": "e0c35b60-5508-461a-d64f-32865f88b495"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'get_scores(expected_relations, [\"None\"])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding\"\"\""
      ],
      "metadata": {
        "id": "ehFFvcJwDA03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "77dbe734-5fa6-4fd8-e5b7-c59e6b317be9"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'import locale\\ndef getpreferredencoding(do_setlocale = True):\\n    return \"UTF-8\"\\nlocale.getpreferredencoding = getpreferredencoding'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"pip install pyarrow==11.0.0\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0zRs-43KC6jW",
        "outputId": "c1c8b2c1-2b1a-4b3d-e943-b386e9fc24b9"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'pip install pyarrow==11.0.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import Dataset\n",
        "\n",
        "# Convert list of dictionaries to DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Split DataFrame into train and test\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert back to datasets\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "\n"
      ],
      "metadata": {
        "id": "tD_mBzpgg7rY"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optionally, you can remove the pandas index column\n",
        "train_dataset = train_dataset.remove_columns('__index_level_0__')\n",
        "test_dataset = test_dataset.remove_columns('__index_level_0__')\n",
        "\n"
      ],
      "metadata": {
        "id": "M5M1JkSahu5v"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAeevXzRhBn4",
        "outputId": "159ab293-dca7-4bd7-8b25-ce69404ae5b3"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input', 'output'],\n",
              "    num_rows: 779\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt)\n",
        "tokenized_test_dataset = test_dataset.map(generate_and_tokenize_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "b101b9d9fa5345aeae0e7af9a2ff3038",
            "8f16176b384b4d5582771006ba05bc40",
            "4bda7e8506d3458386c7580541dfded8",
            "0a85486f046e48559643aaf228b4387b",
            "47151bc6595a4167a0a38f79ad518b46",
            "7adafe111cff43d5802a40612634a2dd",
            "ce4336f171f14d5fb0cfff0c7fa4fa4f",
            "39adc73b3eb847e9ae44844df190ec44",
            "bf61d07eeb5740da85ea2045b4e7a44d",
            "30003789868a4694b9a01340d528061f",
            "a901d07beb2648dab6c12c65bd677819",
            "a8ccda2a0d7e429a87627c237b9bcdfb",
            "1f1d718ca66b4902ae04a8651b85a630",
            "9aec5f5f6ec648b5b6e75026c526c9e9",
            "048b6ded7f8044f5905309ecc4063008",
            "648026667ad8455c80cb19ee75ab8af2",
            "db6ff2f03ff74ff0ae03af655918d279",
            "ec2e5caf5e29487ba0b06519900f9f95",
            "dc28a936303c400e9a855fe8b1c41eaa",
            "b4ddd230fec743939ed742f10761c2e9",
            "5502b8fc205c4202b7128cf2f4b4cc3b",
            "e5e0e8a796c14e41a8b9f23625eb045a"
          ]
        },
        "id": "q4ccG3Rrh0Y9",
        "outputId": "0a9b38f7-2dec-46b2-e352-1cbae6e3d1e0"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/779 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b101b9d9fa5345aeae0e7af9a2ff3038"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/195 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a8ccda2a0d7e429a87627c237b9bcdfb"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"tokenizer.decode(tokenized_train_dataset[1]['input_ids'])\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zQQeuH6iiG1Y",
        "outputId": "5f9412f9-b05c-49e4-9692-5bde19a0cb46"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"tokenizer.decode(tokenized_train_dataset[1]['input_ids'])\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"len(tokenized_train_dataset[1]['input_ids'])\"\"\""
      ],
      "metadata": {
        "id": "LRQ4KG-QE29y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "eb300974-a1f4-49ad-d988-e65477fbb43c"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"len(tokenized_train_dataset[1]['input_ids'])\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"print(tokenized_train_dataset[1]['input_ids'])\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "sme20yTfjVTA",
        "outputId": "614a4190-d9f3-4029-a1ad-1fa528ef1dde"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"print(tokenized_train_dataset[1]['input_ids'])\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_data_lengths(tokenized_train_dataset, tokenized_test_dataset):\n",
        "    lengths = [len(x['input_ids']) for x in tokenized_train_dataset]\n",
        "    lengths += [len(x['input_ids']) for x in tokenized_test_dataset]\n",
        "    print(len(lengths))\n",
        "\n",
        "    # Plotting the histogram\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.hist(lengths, bins=20, alpha=0.7, color='blue')\n",
        "    plt.xlabel('Length of input_ids')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.title('Distribution of Lengths of input_ids')\n",
        "    plt.show()\n",
        "\n",
        "plot_data_lengths(tokenized_train_dataset, tokenized_test_dataset)\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "A1SZhKDvFIOO",
        "outputId": "6b05c60c-e1c1-4789-8e58-c02a7e8a8fff"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"import matplotlib.pyplot as plt\\n\\ndef plot_data_lengths(tokenized_train_dataset, tokenized_test_dataset):\\n    lengths = [len(x['input_ids']) for x in tokenized_train_dataset]\\n    lengths += [len(x['input_ids']) for x in tokenized_test_dataset]\\n    print(len(lengths))\\n\\n    # Plotting the histogram\\n    plt.figure(figsize=(10, 6))\\n    plt.hist(lengths, bins=20, alpha=0.7, color='blue')\\n    plt.xlabel('Length of input_ids')\\n    plt.ylabel('Frequency')\\n    plt.title('Distribution of Lengths of input_ids')\\n    plt.show()\\n\\nplot_data_lengths(tokenized_train_dataset, tokenized_test_dataset)\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up LoRA"
      ],
      "metadata": {
        "id": "mL2nzAnfdTMy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.datacamp.com/tutorial/mastering-low-rank-adaptation-lora-enhancing-large-language-models-for-efficient-adaptation\n",
        "\n",
        "LoRA is built on the understanding that large models inherently possess a low-dimensional structure. By leveraging low-rank matrices, LoRA adapts these models effectively. This method focuses on the core concept that significant model changes can be represented with fewer parameters, thus making the adaptation process more efficient.\n",
        "\n",
        "First, we decompose the large weight matrices into smaller matrices using the lower-rank matrix technique, as explained above. This drastically reduces the number of trainable parameters. For a model like GPT-3, trainable parameters are reduced by 10000 times. This means instead of training 175 billion parameters, if you apply LoRA, you only have 17.5 million trainable parameters.\n",
        "\n",
        "We do not change any parameters for a pre-trained model. Instead, only train lower-rank matrices, which happen relatively very quickly because of fewer parameters.\n",
        "\n",
        "The weights are additive. This means for inference, we just add the weights of lower-rank matrices to pre-trained weights without any additional latency. The lower-rank matrices are very small in size as well so it is very easy to load and unload them for different tasks and different users\n",
        "\n",
        "LoRA does not introduce any additional latency during inference. While low-rank matrices are used during training, they are merged with the original parameters for inference, ensuring no slowdown\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "l4mgobltgSMx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, you should call the prepare_model_for_kbit_training() function to preprocess the quantized model for traininng."
      ],
      "metadata": {
        "id": "HRfpTV95K_G0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import prepare_model_for_kbit_training\n",
        "\n",
        "#model.gradient_checkpointing_enable()\n",
        "model = prepare_model_for_kbit_training(model)"
      ],
      "metadata": {
        "id": "WEmyEUeJrzZc"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://huggingface.co/docs/peft/main/en/developer_guides/lora#qlora-style-training\n",
        "\n",
        "However, in QLoRA, it was found that adding trainable weights to all the linear layers of a transformer model is beneficial to match full-finetuning performance. Since the list of modules to add will vary depending on the architecture, we provided a convenient shorthand : simple specify target_modules='all-linear' and let 🤗PEFT handle the rest:"
      ],
      "metadata": {
        "id": "3EhoQo1FPb41"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://huggingface.co/blog/4bit-transformers-bitsandbytes\n"
      ],
      "metadata": {
        "id": "VOkw-eBMnm7p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9S_20KTJmX6W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## opinions on LoRA params\n",
        "\n",
        "https://medium.com/@fartypantsham/what-rank-r-and-alpha-to-use-in-lora-in-llm-1b4f025fd133\n",
        "\n",
        "Generally ranks bellow 32 are more like a smudges on a glass with a dirty rag. Very low values like 8 or 4 are basically just telling the model a style of how you want the output to be formatted to but not care about the details as there isn’t enough parameters to distinguish much more.\n",
        "\n",
        "Alpha is a scaling parameter.\n",
        "\n",
        "alpha = rank is scaling weights at 1.0\n",
        "\n",
        "What you train in LORA weights will be then merged with the main weights of model at x 1.0\n",
        "\n",
        "Previously people were suggesting alpha = (2 x rank), which is like yelling at your model really loud — all in order to make the newly learned weights “louder” than the model’s own. That requires a really good and large dataset, otherwise you are just amplifying nonsense.\n",
        "\n",
        "The model knows how to speak well already, while your dataset is too small to teach (or scream at) the model any language fundamentals. Increasing alpha amplifies everything, not just the stuff you wish the model learns from it.\n",
        "\n",
        "I would suggest rank = alpha, most of the time as your base — because it is very easily to attenuate the LORA data after the training is done if it appears to be too “loud”, overtaking the entire model.\n",
        "\n",
        "\n",
        "\n",
        "https://www.anyscale.com/blog/fine-tuning-llms-lora-or-full-parameter-an-in-depth-analysis-with-llama-2\n",
        "\n",
        "* Rank: 8 Choosing a higher rank for our decomposition matrices would counteract LoRA's efficiency gains. Our preliminary tests suggested minimal performance boosts when increasing the rank to, for instance, 16. As a result, we settled on a rank of 8 to maintain smaller checkpoint sizes and to avoid artificially inflating our checkpoint files.\n",
        "* Alpha: 16 Alpha scales the learned weights. Existing literature, including the original LoRA paper, generally advises fixing Alpha—often at 16—rather than treating it as a tunable hyperparameter.\n",
        "* Base learning rate: 1e-4\n",
        "A learning rate of 1e-4 has become the standard when fine-tuning LLMs with LoRA. Although we occasionally encountered training loss instabilities, reducing the learning rate to lower values like 3e-5 proved effective in stabilizing the process—more on this will follow."
      ],
      "metadata": {
        "id": "wxdkvd6Op4EG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "math.sqrt(32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJhp3A4dLEPq",
        "outputId": "b75d4b14-54d7-47a3-9846-4d4c4b710ae6"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.656854249492381"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "config = LoraConfig(\n",
        "    r=128,\n",
        "    lora_alpha=64,\n",
        "    target_modules=\"all-linear\",\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "ScHXgXNU1emg"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_trainable_parameters(model):\n",
        "    \"\"\"\n",
        "    Prints the number of trainable parameters in the model.\n",
        "    \"\"\"\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(\n",
        "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
        "    )"
      ],
      "metadata": {
        "id": "IsKDeTi61GeM"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Let's print the model to examine its layers, as we will apply QLoRA to all the linear layers of the model. Those layers are q_proj, k_proj, v_proj, o_proj, gate_proj, up_proj, down_proj, and lm_head.\n"
      ],
      "metadata": {
        "id": "2mhQAL_DaoPR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_peft_model(model, config)"
      ],
      "metadata": {
        "id": "iyhMZl1V1iwk"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/huggingface/transformers/blob/main/src/transformers/models/mistral/modeling_mistral.py"
      ],
      "metadata": {
        "id": "WDGAhJSY2nu6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print_trainable_parameters(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLtmZtxw1noF",
        "outputId": "c7e198ab-db1e-45c5-f3fe-09518f887ac5"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 335544320 || all params: 4087615488 || trainable%: 8.208803420601972\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YM2kDYOjLv_4",
        "outputId": "6e6640c0-ae38-411b-b403-21c3c73d8db2"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PeftModelForCausalLM(\n",
            "  (base_model): LoraModel(\n",
            "    (model): MistralForCausalLM(\n",
            "      (model): MistralModel(\n",
            "        (embed_tokens): Embedding(32000, 4096)\n",
            "        (layers): ModuleList(\n",
            "          (0-31): 32 x MistralDecoderLayer(\n",
            "            (self_attn): MistralAttention(\n",
            "              (q_proj): lora.Linear4bit(\n",
            "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Dropout(p=0.05, inplace=False)\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=4096, out_features=128, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=128, out_features=4096, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "              )\n",
            "              (k_proj): lora.Linear4bit(\n",
            "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Dropout(p=0.05, inplace=False)\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=4096, out_features=128, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=128, out_features=1024, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "              )\n",
            "              (v_proj): lora.Linear4bit(\n",
            "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Dropout(p=0.05, inplace=False)\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=4096, out_features=128, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=128, out_features=1024, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "              )\n",
            "              (o_proj): lora.Linear4bit(\n",
            "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Dropout(p=0.05, inplace=False)\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=4096, out_features=128, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=128, out_features=4096, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "              )\n",
            "              (rotary_emb): MistralRotaryEmbedding()\n",
            "            )\n",
            "            (mlp): MistralMLP(\n",
            "              (gate_proj): lora.Linear4bit(\n",
            "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Dropout(p=0.05, inplace=False)\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=4096, out_features=128, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=128, out_features=14336, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "              )\n",
            "              (up_proj): lora.Linear4bit(\n",
            "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Dropout(p=0.05, inplace=False)\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=4096, out_features=128, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=128, out_features=14336, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "              )\n",
            "              (down_proj): lora.Linear4bit(\n",
            "                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Dropout(p=0.05, inplace=False)\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=14336, out_features=128, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=128, out_features=4096, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "              )\n",
            "              (act_fn): SiLU()\n",
            "            )\n",
            "            (input_layernorm): MistralRMSNorm()\n",
            "            (post_attention_layernorm): MistralRMSNorm()\n",
            "          )\n",
            "        )\n",
            "        (norm): MistralRMSNorm()\n",
            "      )\n",
            "      (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://huggingface.co/docs/transformers/peft"
      ],
      "metadata": {
        "id": "QW_Azaqb38Mi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q wandb -U\n",
        "\n",
        "import wandb, os\n",
        "wandb.login()\n",
        "\n",
        "wandb_project = \"mistral-finetune\"\n",
        "if len(wandb_project) > 0:\n",
        "    os.environ[\"WANDB_PROJECT\"] = wandb_project"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQO_NaAvF8QH",
        "outputId": "60adc225-bf07-4e74-fbde-768e2eb8f176"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maareias\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! ls drive/MyDrive/mistral-finetune/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjkYxg_WHCIa",
        "outputId": "f39a388f-e9e2-4a3d-8e6a-42d4431e7d3f"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "checkpoint-500\t\t\t       mistral-finetuning-data-loweralpha.json\n",
            "data\t\t\t\t       mistral-finetuning-data-nonegative.json\n",
            "helper_functions.py\t\t       mistral-finetuning-data-r32alpha16.json\n",
            "mistral-finetuning-data2.json\t       mistral-finetuning-data-r8alpha16.json\n",
            "mistral-finetuning-data3.json\t       __pycache__\n",
            "mistral-finetuning-data-balanced.json  runs\n",
            "mistral-finetuning-data.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#mkdir drive/MyDrive/mistral-finetune/runs"
      ],
      "metadata": {
        "id": "Q61w65e6HOqq"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mkdir drive/MyDrive/mistral-finetune/runs/logs"
      ],
      "metadata": {
        "id": "5pdDpUXUHyXE"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "project = \"relation-extraction-finetune\"\n",
        "base_model_name = \"mistral7b\"\n",
        "run_name = base_model_name + \"-\" + project + \"_10\" # rank 128 alpha 64 scale factor 0.5 and batch size 8\n",
        "output_dir = \"drive/MyDrive/mistral-finetune/runs/\" + run_name\n"
      ],
      "metadata": {
        "id": "Xwnxw2lPGKxX"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://huggingface.co/docs/peft/main/en/conceptual_guides/lora#common-lora-parameters-in-peft\n",
        "\n"
      ],
      "metadata": {
        "id": "3Z9BHtfRK9_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dnbC8NLAK9sm",
        "outputId": "8e517735-7c66-4db1-d01b-0e33a375bcac"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'drive/MyDrive/mistral-finetune/runs/mistral7b-relation-extraction-finetune_10'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "bf16 gives error ValueError: Your setup doesn't support bf16/gpu. You need torch>=1.10, using Ampere GPU with cuda>=11.0"
      ],
      "metadata": {
        "id": "j7Bw0NJVRCbU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://ai.google.dev/gemma/docs/lora_tuning#lora_fine-tuning\n",
        "\n",
        "The LoRA rank determines the dimensionality of the trainable matrices that are added to the original weights of the LLM. It controls the expressiveness and precision of the fine-tuning adjustments.\n",
        "\n",
        "A higher rank means more detailed changes are possible, but also means more trainable parameters. A lower rank means less computational overhead, but potentially less precise adaptation.\n",
        "\n",
        "This tutorial uses a LoRA rank of 4. In practice, begin with a relatively small rank (such as 4, 8, 16). This is computationally efficient for experimentation. Train your model with this rank and evaluate the performance improvement on your task. Gradually increase the rank in subsequent trials and see if that further boosts performance."
      ],
      "metadata": {
        "id": "YipIp6repJKH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://huggingface.co/transformers/v3.0.2/main_classes/trainer.html\n",
        "\n",
        "*  train_batch_size, per_device_train_batch_size (int, optional, defaults to 8) – The batch size per PU/TPU core/CPU for training.\n",
        "* learning_rate (float, optional, defaults to 5e-5) – The initial learning rate for Adam.\n",
        "* warmup_steps (int, optional, defaults to 0) – Number of steps used for a linear warmup from 0 to learning_rate.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lHoZpT0mt7Bb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GiZJolNYuyJ5"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "import transformers\n",
        "\n",
        "trainer = transformers.Trainer(\n",
        "    model=model,\n",
        "    train_dataset=tokenized_train_dataset,\n",
        "    eval_dataset=tokenized_test_dataset,\n",
        "    args=transformers.TrainingArguments(\n",
        "        output_dir=output_dir,\n",
        "        warmup_steps=1,\n",
        "        per_device_train_batch_size=8,\n",
        "        gradient_accumulation_steps=1,\n",
        "        gradient_checkpointing=True,\n",
        "        max_steps=500,\n",
        "        learning_rate=2.5e-5, # Want a small lr for finetuning\n",
        "        fp16=True,\n",
        "        logging_steps=25,\n",
        "        optim=\"paged_adamw_8bit\",\n",
        "        logging_dir=\"drive/MyDrive/mistral-finetune/runs/logs\",        # Directory for storing logs\n",
        "        save_strategy=\"steps\",       # Save the model checkpoint every logging step\n",
        "        save_steps=25,                # Save checkpoints every 50 steps\n",
        "        evaluation_strategy=\"steps\", # Evaluate the model every logging step\n",
        "        eval_steps=25,               # Evaluate and save checkpoints every 50 steps\n",
        "        do_eval=True,                # Perform evaluation at the end of training\n",
        "        report_to=\"wandb\",           # Comment this out if you don't want to use weights & baises\n",
        "        run_name=f\"{run_name}-{datetime.now().strftime('%Y-%m-%d-%H-%M')}\"          # Name of the W&B run (optional)\n",
        "    ),\n",
        "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
        ")\n",
        "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
        "trainer.train()\n",
        "\n"
      ],
      "metadata": {
        "id": "OJfu-NDg3Oy8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "012ff5a3-f7a5-410d-86bc-8541eb23e909"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:437: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240224_135348-a6zika6e</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/aareias/mistral-finetune/runs/a6zika6e' target=\"_blank\">mistral7b-relation-extraction-finetune_10-2024-02-24-13-53</a></strong> to <a href='https://wandb.ai/aareias/mistral-finetune' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/aareias/mistral-finetune' target=\"_blank\">https://wandb.ai/aareias/mistral-finetune</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/aareias/mistral-finetune/runs/a6zika6e' target=\"_blank\">https://wandb.ai/aareias/mistral-finetune/runs/a6zika6e</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='226' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [226/500 08:27 < 10:20, 0.44 it/s, Epoch 2.30/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.906500</td>\n",
              "      <td>0.420110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.431500</td>\n",
              "      <td>0.399194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>0.402500</td>\n",
              "      <td>0.383935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.365200</td>\n",
              "      <td>0.372237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>0.334900</td>\n",
              "      <td>0.373792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.333900</td>\n",
              "      <td>0.373710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>0.327500</td>\n",
              "      <td>0.373564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.331400</td>\n",
              "      <td>0.378221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>0.272600</td>\n",
              "      <td>0.392320</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-e3850c3ccc05>\u001b[0m in \u001b[0;36m<cell line: 31>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m )\n\u001b[1;32m     30\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# silence the warnings. Please re-enable for inference!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1537\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1538\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1539\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1540\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1541\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1927\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1929\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_log_save_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1930\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1931\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_substep_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2301\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_save\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2302\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2303\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_save_checkpoint\u001b[0;34m(self, model, trial, metrics)\u001b[0m\n\u001b[1;32m   2376\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2377\u001b[0m             \u001b[0mstaging_output_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"tmp-{checkpoint_folder}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2378\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstaging_output_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_internal_call\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_only_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(self, output_dir, _internal_call)\u001b[0m\n\u001b[1;32m   2884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2885\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_save\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2886\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2888\u001b[0m         \u001b[0;31m# Push to the Hub when `save_model` is called by the user.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(self, output_dir, state_dict)\u001b[0m\n\u001b[1;32m   2956\u001b[0m                     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWEIGHTS_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2957\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2958\u001b[0;31m             self.model.save_pretrained(\n\u001b[0m\u001b[1;32m   2959\u001b[0m                 \u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe_serialization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_safetensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2960\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36msave_pretrained\u001b[0;34m(self, save_directory, safe_serialization, selected_adapters, save_embedding_layers, is_main_process, **kwargs)\u001b[0m\n\u001b[1;32m    246\u001b[0m                         \u001b[0moutput_state_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mshared_tensor_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_state_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mshared_tensor_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m                 safe_save_file(\n\u001b[0m\u001b[1;32m    249\u001b[0m                     \u001b[0moutput_state_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m                     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSAFETENSORS_WEIGHTS_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/safetensors/torch.py\u001b[0m in \u001b[0;36msave_file\u001b[0;34m(tensors, filename, metadata)\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \"\"\"\n\u001b[0;32m--> 281\u001b[0;31m     \u001b[0mserialize_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://magazine.sebastianraschka.com/p/practical-tips-for-finetuning-llms"
      ],
      "metadata": {
        "id": "8A93t3xtR3XO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "aXCzmpXCRUjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "restart session!"
      ],
      "metadata": {
        "id": "zBXAJC1MYV54"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating"
      ],
      "metadata": {
        "id": "Di3sNhyhXWeU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xp3iswxoiTHe",
        "outputId": "94ce8f65-4a10-493e-88c3-ac55022b2d7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('drive/My Drive/mistral-finetune/')"
      ],
      "metadata": {
        "id": "MRLRwHrqWnuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import preprocess"
      ],
      "metadata": {
        "id": "A9gw5kEsWc-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load test data\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"./drive/MyDrive/mistral-finetune/data/nyt10m_test.csv\")\n"
      ],
      "metadata": {
        "id": "wwyfZnqw9V3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[df['relation'].isna(),'relation']=\"None\""
      ],
      "metadata": {
        "id": "YQjD1L3zYZv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.relation.value_counts()/len(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Rp3uv0mhvj6",
        "outputId": "60cdb127-ed83-47d0-b28a-6aca4ece22ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "/people/person/place_lived                    0.229008\n",
              "/location/located_in                          0.213740\n",
              "None                                          0.190840\n",
              "/business/person/company                      0.114504\n",
              "/location/country/administrative_divisions    0.061069\n",
              "/people/person/nationality                    0.061069\n",
              "/location/administrative_division/country     0.053435\n",
              "/business/location                            0.038168\n",
              "/business/company/advisors                    0.015267\n",
              "/people/deceasedperson/place_of_death         0.015267\n",
              "/people/person/place_of_birth                 0.007634\n",
              "Name: relation, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = preprocess(df)"
      ],
      "metadata": {
        "id": "XfO-C3oKZ64n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzrcU5jiaAND",
        "outputId": "dafe7475-e23c-4210-c446-108adcc46ad0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOwukI0waBDW",
        "outputId": "71b0dbb2-fac9-4fe9-b89a-cfb05ea3cc43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'A1 OBITUARIES A15 Mstislav Rostropovich A cellist and conductor who was renowned as one of the great instrumentalists of the 20th century and an outspoken champion of artistic freedom in the Soviet Union during the last decades of the cold war , he was 80 and lived in Paris .',\n",
              " 'output': \"('Mstislav Rostropovich', '/people/person/place_lived', 'Paris')\"}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "relations = np.sort(list(df.relation.unique()))\n",
        "relations = list(relations[:len(relations)-1])\n",
        "relations"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4ZXfbyEaQDi",
        "outputId": "97d6f05c-2094-44ab-eb7d-479d02fdb508"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/business/company/advisors',\n",
              " '/business/location',\n",
              " '/business/person/company',\n",
              " '/location/administrative_division/country',\n",
              " '/location/country/administrative_divisions',\n",
              " '/location/located_in',\n",
              " '/people/deceasedperson/place_of_death',\n",
              " '/people/person/nationality',\n",
              " '/people/person/place_lived',\n",
              " '/people/person/place_of_birth']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" double checking that fits training data same categories\n",
        "['/business/company/advisors',\n",
        " '/business/location',\n",
        " '/business/person/company',\n",
        " '/location/administrative_division/country',\n",
        " '/location/country/administrative_divisions',\n",
        " '/location/located_in',\n",
        " '/people/deceasedperson/place_of_death',\n",
        " '/people/person/nationality',\n",
        " '/people/person/place_lived',\n",
        " '/people/person/place_of_birth']\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "e1-HUzbBaP_5",
        "outputId": "f24621a3-0f1a-4a75-a6cd-876deae2d1e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" double checking that fits training data same categories\\n['/business/company/advisors',\\n '/business/location',\\n '/business/person/company',\\n '/location/administrative_division/country',\\n '/location/country/administrative_divisions',\\n '/location/located_in',\\n '/people/deceasedperson/place_of_death',\\n '/people/person/nationality',\\n '/people/person/place_lived',\\n '/people/person/place_of_birth']\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "66GX_SwVaP89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Baq6nbAIaP5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "import torch"
      ],
      "metadata": {
        "id": "eWvmg8OqYcoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")"
      ],
      "metadata": {
        "id": "zfEKgdPHY7Kx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Init an eval tokenizer that doesn't add padding or eos token\n",
        "eval_tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model_id,\n",
        "    add_bos_token=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHx6xiRyYqzV",
        "outputId": "ca3400ab-00fe-442a-c46a-335bc2aa0c31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"pip install accelerate\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoITykgknheJ",
        "outputId": "9698a352-28ab-4256-a83d-dcaa4347b6ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.28.0.dev0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map=\"auto\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "4788ad5243474cc58733fd97d86140ca",
            "fd82d55ad2f94805b37cdf7a076d2f7e",
            "957304ebfce2401280010c4324cb3ea8",
            "b6f75848e4454185821775784bcd866b",
            "b3d1b04d9b4643aa9b06072e8e76e843",
            "a75c112da2714e12b2996b5084fd27f6",
            "bdafdfb92209478d9f6611783abdb407",
            "bc65fc2695e34006a922580b78bdb03b",
            "62fc2127f1ee465d9bae6c06aa457e75",
            "d2a4e4e9694548dd974e211d966e8e03",
            "f169dc9690c64720a14455b25ab2e05c"
          ]
        },
        "id": "WDdGT_8VYzbc",
        "outputId": "c14bc398-d761-4d4a-ee70-a98878bb06ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4788ad5243474cc58733fd97d86140ca"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_prompt = formatting_func(data[2])\n"
      ],
      "metadata": {
        "id": "d7FtAP9jZyBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "_ZAogIsGaIvY",
        "outputId": "fcf2e98d-222a-42a5-93be-7bea29748a7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"[INST] You are an NLP expert tasked with entity and relation extraction. Here is a list of potential relation types: ['/business/company/advisors', '/business/location', '/business/person/company', '/location/administrative_division/country', '/location/country/administrative_divisions', '/location/located_in', '/people/deceasedperson/place_of_death', '/people/person/nationality', '/people/person/place_lived', '/people/person/place_of_birth'] \\nWhat relations in the given list might be included in the given sentence? Make sure to use only relations from the list provided!\\nThe given sentence is: 'A1 OBITUARIES A15 Mstislav Rostropovich A cellist and conductor who was renowned as one of the great instrumentalists of the 20th century and an outspoken champion of artistic freedom in the Soviet Union during the last decades of the cold war , he was 80 and lived in Paris .'\\nIf none present, answer: None.\\nRespond with relationship triples, e.g. (head entity 1, relation 1, tail entity 1), (head entity 2, relation 2, tail entity 2), (...) \\nTake care, your answer is only valid if it follows the correct format! [\\\\INST]\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    response  = eval_tokenizer.decode(model.generate(**model_input, max_new_tokens=256, repetition_penalty=1.15)[0], skip_special_tokens=True)\n",
        "    response = response.replace(eval_prompt, \"\")\n",
        "    print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXKZaeaVah2Q",
        "outputId": "3b2b35e9-80f0-4abe-cc2e-20df1b4329de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Based on the given sentence, the following relation triple can be extracted:\n",
            "(Mstislav Rostropovich, /people/person/place_lived, Paris)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_relations = get_tuples(response)\n",
        "predicted_relations"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gmVETQBa_am",
        "outputId": "eb64fe65-b5d3-4af1-ec99-68e1d66d65b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Mstislav Rostropovich', '/people/person/place_lived', 'Paris')]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "expected_relations = get_relations(data[10])\n",
        "expected_relations"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRUuEMzsbLbF",
        "outputId": "f095fef4-ef39-4c56-8eca-f81272a1d5cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['None']"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "expected_set = set(expected_relations)\n",
        "expected_set"
      ],
      "metadata": {
        "id": "ryRown3XfP8i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ef4c97e-0d67-464e-c8e0-8116e59d3f08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'None'}"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "09K_v_40fP3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LuX4rpr7fPsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision, recall,f1 = get_scores(expected_relations, predicted_relations)"
      ],
      "metadata": {
        "id": "DZm2J8P5bXr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision,recall,f1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyMXIgFibaVx",
        "outputId": "fac4908f-8cd4-422a-b7db-2af8edf58101"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.0, 1.0, 1.0)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[0].update({'base_model' : {'predicted_relations':predicted_relations,\n",
        "                                'precision': precision,\n",
        "                                'recall': recall,\n",
        "                                'f1': f1}})"
      ],
      "metadata": {
        "id": "L8w5yhXZbgJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[1:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-R9O-Pcxbm6w",
        "outputId": "fd2f17ff-53c8-4710-fed9-14230b777160"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'input': \"9:30 P.M. (13) THE WILD PARROTS OF TELEGRAPH HILL -- '' Independent Lens '' follows Mark Bittner , a homeless street musician in San Francisco , as he literally goes to the birds -- and finds meaning in his life -- by taking up with a flock of wild red and green parrots .\",\n",
              "  'output': \"('Mark Bittner', '/people/person/place_lived', 'San Francisco')\"},\n",
              " {'input': 'A1 OBITUARIES A15 Mstislav Rostropovich A cellist and conductor who was renowned as one of the great instrumentalists of the 20th century and an outspoken champion of artistic freedom in the Soviet Union during the last decades of the cold war , he was 80 and lived in Paris .',\n",
              "  'output': \"('Mstislav Rostropovich', '/people/person/place_lived', 'Paris')\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(range(1,3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9rpInOndVCy",
        "outputId": "7d14b511-9a90-44a7-cf52-e4a6a247fec6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "progress_bar = tqdm(total=len(data), desc='Progress')\n",
        "\n",
        "for idx, example in zip(list(range(len(data))), data):\n",
        "\n",
        "    eval_prompt = formatting_func(example)\n",
        "\n",
        "    model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        response  = eval_tokenizer.decode(model.generate(**model_input, max_new_tokens=256,\n",
        "                                                         repetition_penalty=1.15,\n",
        "                                                         pad_token_id=eval_tokenizer.eos_token_id)[0],\n",
        "                                          skip_special_tokens=True)\n",
        "        response = response.replace(eval_prompt, \"\")\n",
        "\n",
        "    predicted_relations = get_tuples(response)\n",
        "\n",
        "    expected_relations = get_relations(example)\n",
        "\n",
        "    precision, recall,f1 = get_scores(expected_relations, predicted_relations)\n",
        "\n",
        "    data[idx].update({'base_model':\n",
        "                        {'response': response,\n",
        "                         'predicted_relations':predicted_relations,\n",
        "                        'precision': precision,\n",
        "                        'recall': recall,\n",
        "                        'f1': f1}\n",
        "                    })\n",
        "    progress_bar.update(1)\n",
        "\n",
        "progress_bar.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzAeMdk_b0Kk",
        "outputId": "1ac14b31-da29-4874-a393-e7e122596278"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Progress: 100%|██████████| 100/100 [22:17<00:00, 13.38s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[:4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oNWgsOZxger",
        "outputId": "1e460f91-063e-4886-a521-377c151aab7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'input': '-LRB- AP -RRB- WEST VIRGINIA 67 , VILLANOVA 56 -- Frank Young scored a career-high 25 points , including eight 3-pointers , for No. 25 West Virginia -LRB- 12-1 , 2-0 -RRB- in a Big East game .',\n",
              "  'output': \"('Frank Young', '/people/person/place_lived', 'West Virginia')\",\n",
              "  'base_model': {'response': \" Based on the given sentence, there do not seem to be any explicit relations mentioned that can be directly extracted using the provided list. The sentence primarily describes an event (a basketball game) involving entities 'West Virginia' and 'Villanova'. However, no specific relations between these entities or other mentioned entities ('Frank Young') are explicitly stated in the sentence. Therefore, the answer would be: None.\",\n",
              "   'predicted_relations': 'None',\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': \"9:30 P.M. (13) THE WILD PARROTS OF TELEGRAPH HILL -- '' Independent Lens '' follows Mark Bittner , a homeless street musician in San Francisco , as he literally goes to the birds -- and finds meaning in his life -- by taking up with a flock of wild red and green parrots .\",\n",
              "  'output': \"('Mark Bittner', '/people/person/place_lived', 'San Francisco')\",\n",
              "  'base_model': {'response': \" Based on the given sentence, there don't seem to be any explicit relations mentioned that can be directly extracted using the provided list. The sentence describes Mark Bittner being a homeless street musician in San Francisco who connects with a flock of wild parrots, but it does not explicitly state any location or company relationships between these entities. Therefore, none.\",\n",
              "   'predicted_relations': 'None',\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': 'A1 OBITUARIES A15 Mstislav Rostropovich A cellist and conductor who was renowned as one of the great instrumentalists of the 20th century and an outspoken champion of artistic freedom in the Soviet Union during the last decades of the cold war , he was 80 and lived in Paris .',\n",
              "  'output': \"('Mstislav Rostropovich', '/people/person/place_lived', 'Paris')\",\n",
              "  'base_model': {'response': ' Based on the given sentence, the following relation triple can be extracted:\\n(Mstislav Rostropovich, /people/person/place_lived, Paris)',\n",
              "   'predicted_relations': [('Mstislav Rostropovich',\n",
              "     '/people/person/place_lived',\n",
              "     'Paris')],\n",
              "   'precision': 1.0,\n",
              "   'recall': 1.0,\n",
              "   'f1': 1.0}},\n",
              " {'input': 'About 2.4 million people live within a 10-mile radius of the Westfield Garden State Plaza in Paramus , which is the largest shopping mall in the state and draws 20 million visitors a year .',\n",
              "  'output': 'None',\n",
              "  'base_model': {'response': \" Based on the given sentence, the following relation triple can be extracted: ('Westfield Garden State Plaza', '/location/located_in', 'Paramus')\",\n",
              "   'predicted_relations': [('Westfield Garden State Plaza',\n",
              "     '/location/located_in',\n",
              "     'Paramus')],\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}}]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "# Define the file path\n",
        "file_path = \"./mistral-finetuning-data.json\"\n",
        "\n",
        "# Save the data to a JSON file\n",
        "with open(file_path, \"w\") as json_file:\n",
        "    json.dump(data, json_file)\n",
        "\n",
        "print(f\"Data saved to {file_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfNwgMzvcczB",
        "outputId": "ccfe495c-b1b8-48c7-8aef-7abc2b3bc0ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data saved to ./mistral-finetuning-data.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate average metrics\n",
        "avg_precision, avg_recall, avg_f1 = calculate_average_metrics(data)\n",
        "\n",
        "print(\"Average Precision:\", avg_precision)\n",
        "print(\"Average Recall:\", avg_recall)\n",
        "print(\"Average F1-score:\", avg_f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "sUmpdYgGyJn6",
        "outputId": "945b9124-f11a-45f8-a38d-bc0266020974"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'base_model'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-92-37c36adb265b>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Calculate average metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mavg_precision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_recall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_average_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Average Precision:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_precision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-92-37c36adb265b>\u001b[0m in \u001b[0;36mcalculate_average_metrics\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mtotal_precision\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'base_model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'precision'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mtotal_recall\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'base_model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'recall'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mtotal_f1\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'base_model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'f1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'base_model'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## load finetuned model"
      ],
      "metadata": {
        "id": "phWDBZmlx8EK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! ls drive/MyDrive/mistral-finetune/runs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0jW3AfvzZjO",
        "outputId": "4e188755-1bbb-43ef-dc00-4b779327d338"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "checkpoint-500\t\t\t       mistral-finetuning-data.json\n",
            "data\t\t\t\t       mistral-finetuning-data-loweralpha.json\n",
            "helper_functions.py\t\t       mistral-finetuning-data-nonegative.json\n",
            "mistral-finetuning-data2.json\t       __pycache__\n",
            "mistral-finetuning-data3.json\t       runs\n",
            "mistral-finetuning-data-balanced.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "\n",
        "model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,  # Mistral, same as before\n",
        "    quantization_config=bnb_config,  # Same quantization config as before\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "9631b08289924f68aab5f2b0384ba972",
            "7ae0f92ba8df4056b07c4d65509dd284",
            "aafa74b60b5d440bb2eadbcefcd899db",
            "5156fd3b5c0b4c0d9a9260c2d383a453",
            "a6d630b3451446f5bd245d5bcff4b703",
            "f2fdbfd7d02b43ea9ecddd514b02e6ca",
            "a972cc11e2c54ec5869223ed80f16846",
            "9c0dea4fabf04d2da21adb174fcc29cf",
            "c8c7f68aa6b7480893f103856e9cb7f6",
            "21759245e6c0489db0fa5ca2f24a7f95",
            "18eae89a759b4e08b2f3252f9d0a1c33"
          ]
        },
        "id": "mZauCEiyznw_",
        "outputId": "b440a5bd-dea7-4c8f-d8d7-27954e953fef"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9631b08289924f68aab5f2b0384ba972"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_tokenizer = AutoTokenizer.from_pretrained(model_id, add_bos_token=True, trust_remote_code=True)\n"
      ],
      "metadata": {
        "id": "lRDZONbC2-zT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ls drive/MyDrive/mistral-finetune/runs/mistral7b-relation-extraction-finetune_10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93vW05-t74vK",
        "outputId": "6e839aef-0ae7-4e43-fb94-02f5fa02255a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "checkpoint-100\tcheckpoint-150\tcheckpoint-200\tcheckpoint-50  tmp-checkpoint-225\n",
            "checkpoint-125\tcheckpoint-175\tcheckpoint-25\tcheckpoint-75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import PeftModel\n",
        "\n",
        "ft_model = PeftModel.from_pretrained(model, \"drive/MyDrive/mistral-finetune/runs/mistral7b-relation-extraction-finetune_10/checkpoint-175\")\n"
      ],
      "metadata": {
        "id": "690eVjXyy_nx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open(\"drive/MyDrive/mistral-finetune/mistral-finetuning-data.json\", \"r\") as json_file:\n",
        "    data = json.load(json_file)"
      ],
      "metadata": {
        "id": "RVD-Ay2H5Y6D"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U58uUXs25nd7",
        "outputId": "bb153724-641e-4efc-cc11-356b8dc5301f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'input': '-LRB- AP -RRB- WEST VIRGINIA 67 , VILLANOVA 56 -- Frank Young scored a career-high 25 points , including eight 3-pointers , for No. 25 West Virginia -LRB- 12-1 , 2-0 -RRB- in a Big East game .',\n",
              "  'output': \"('Frank Young', '/people/person/place_lived', 'West Virginia')\",\n",
              "  'base_model': {'response': \" Based on the given sentence, there do not seem to be any explicit relations mentioned that can be directly extracted using the provided list. The sentence primarily describes an event (a basketball game) involving entities 'West Virginia' and 'Villanova'. However, no specific relations between these entities or other mentioned entities ('Frank Young') are explicitly stated in the sentence. Therefore, the answer would be: None.\",\n",
              "   'predicted_relations': 'None',\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': \"9:30 P.M. (13) THE WILD PARROTS OF TELEGRAPH HILL -- '' Independent Lens '' follows Mark Bittner , a homeless street musician in San Francisco , as he literally goes to the birds -- and finds meaning in his life -- by taking up with a flock of wild red and green parrots .\",\n",
              "  'output': \"('Mark Bittner', '/people/person/place_lived', 'San Francisco')\",\n",
              "  'base_model': {'response': \" Based on the given sentence, there don't seem to be any explicit relations mentioned that can be directly extracted using the provided list. The sentence describes Mark Bittner being a homeless street musician in San Francisco who connects with a flock of wild parrots, but it does not explicitly state any location or company relationships between these entities. Therefore, none.\",\n",
              "   'predicted_relations': 'None',\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': 'A1 OBITUARIES A15 Mstislav Rostropovich A cellist and conductor who was renowned as one of the great instrumentalists of the 20th century and an outspoken champion of artistic freedom in the Soviet Union during the last decades of the cold war , he was 80 and lived in Paris .',\n",
              "  'output': \"('Mstislav Rostropovich', '/people/person/place_lived', 'Paris')\",\n",
              "  'base_model': {'response': ' Based on the given sentence, the following relation triple can be extracted:\\n(Mstislav Rostropovich, /people/person/place_lived, Paris)',\n",
              "   'predicted_relations': [['Mstislav Rostropovich',\n",
              "     '/people/person/place_lived',\n",
              "     'Paris']],\n",
              "   'precision': 1.0,\n",
              "   'recall': 1.0,\n",
              "   'f1': 1.0}},\n",
              " {'input': 'About 2.4 million people live within a 10-mile radius of the Westfield Garden State Plaza in Paramus , which is the largest shopping mall in the state and draws 20 million visitors a year .',\n",
              "  'output': 'None',\n",
              "  'base_model': {'response': \" Based on the given sentence, the following relation triple can be extracted: ('Westfield Garden State Plaza', '/location/located_in', 'Paramus')\",\n",
              "   'predicted_relations': [['Westfield Garden State Plaza',\n",
              "     '/location/located_in',\n",
              "     'Paramus']],\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': \"According to Glazer , Philadelphia 's Brian Dawkins and Jacksonville 's Donovin Darius have trained at a mixed martial arts gym .\",\n",
              "  'output': 'None',\n",
              "  'base_model': {'response': \" Based on the given sentence, there isn't a clear head entity or tail entity for any relation type in the list provided. However, we can infer that 'Philadelphia's Brian Dawkins' and 'Jacksonville's Donovin Darius' are people who have lived or reside in certain locations ('Philadelphia' and 'Jacksonville' respectively). We could potentially consider the relation '/people/person/place_lived'. But since this information is not explicitly stated in the sentence, it would be speculative to include it as a relation triple. Therefore, based on the given sentence alone, no relation triples can be definitively extracted using the provided list.\",\n",
              "   'predicted_relations': [],\n",
              "   'precision': 0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': 'American officials said it was possible that he is the same man who they acknowledged last week was in custody at Guantánamo Bay , Cuba .',\n",
              "  'output': \"('Guantánamo Bay', '/location/located_in', 'Cuba')\",\n",
              "  'base_model': {'response': ' Based on the given sentence, there aren\\'t any explicit entities or relations mentioned from the list provided. However, we can infer some implicit relations as follows:\\n\\n(people/person/nationality, /, American)\\n(people/person/place_lived, /, Cuba)\\n\\nThese relations are implied by the mention of \"American officials\" and \"Cuba\" in the sentence. But please note that these relations don\\'t directly relate to the entities mentioned in the sentence itself.',\n",
              "   'predicted_relations': [['people/person/nationality', '/', 'American'],\n",
              "    ['people/person/place_lived', '/', 'Cuba']],\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': \"Among the industry players who have contributed are Peter A. Chernin , chairman and chief executive of News Corporation 's Fox Group ; Ron Meyer , the president of Universal Studios ; Richard Cook , chairman of Walt Disney Studios ; and Brad Grey , chairman of Paramount Pictures .\",\n",
              "  'output': \"('Brad Grey', '/business/person/company', 'Paramount Pictures')\",\n",
              "  'base_model': {'response': \" Based on the given sentence, the following relation triples can be extracted:\\n(Peter A. Chernin, /business/person/company, News Corporation's Fox Group)\\n(Ron Meyer, /business/person/company, Universal Studios)\\n(Richard Cook, /business/person/company, Walt Disney Studios)\\n(Brad Grey, /business/person/company, Paramount Pictures)\\nEach person is associated with their respective company.\",\n",
              "   'predicted_relations': [['Peter A. Chernin',\n",
              "     '/business/person/company',\n",
              "     \"News Corporation's Fox Group\"],\n",
              "    ['Ron Meyer', '/business/person/company', 'Universal Studios'],\n",
              "    ['Richard Cook', '/business/person/company', 'Walt Disney Studios'],\n",
              "    ['Brad Grey', '/business/person/company', 'Paramount Pictures']],\n",
              "   'precision': 0.25,\n",
              "   'recall': 1.0,\n",
              "   'f1': 0.4}},\n",
              " {'input': 'An Albert telecast has snarky notes in the key of the old David Letterman show on NBC , where Albert and his sports bloopers were frequent guests .',\n",
              "  'output': \"('David Letterman', '/business/person/company', 'NBC')\",\n",
              "  'base_model': {'response': \" Based on the given sentence, there do not seem to be any explicit entities or relationships that can be extracted using the provided relation types. The sentence mentions 'Albert', 'NBC', and 'old David Letterman show', but no clear relation between them can be determined based on the information provided alone. Therefore, the answer would be: None.\",\n",
              "   'predicted_relations': 'None',\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': 'Another winner was Terra Industries , an agricultural and industrial chemical company in Sioux City , Iowa .',\n",
              "  'output': \"('Sioux City', '/location/located_in', 'Iowa')\",\n",
              "  'base_model': {'response': \" Based on the given sentence, the following relation triples can be extracted:\\n(Terra Industries, /business/company, None) - This triple represents Terra Industries being identified as a company.\\n(Terra Industries, /business/industry/sector, 'agricultural and industrial chemical') - This triple represents Terra Industries being an agricultural and industrial chemical company.\\n(Sioux City, /location, None) - This triple represents Sioux City being identified as a location.\\n(Sioux City, /location/city, None) - This triple represents Sioux City being identified as a city.\\n(Sioux City, /location/addressable_location/city, None) - This triple represents Sioux City being identified as a city in this context.\\n(Sioux City, /location/located_in, Iowa) - This triple represents Sioux City located in Iowa.\\n(Iowa, /location/country, None) - This triple represents Iowa being identified as a country.\\nTherefore, the final set of relation triples would look like:\\n[(Terra Industries, /business/company, None), (Terra Industries, /business/indust\",\n",
              "   'predicted_relations': 'None',\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': 'As Ms. Qin spoke on the eve of the holiday at the Jade Buddha Temple in central Shanghai , scores of worshipers strolled through the temple complex .',\n",
              "  'output': \"('Jade Buddha Temple', '/location/located_in', 'Shanghai')\",\n",
              "  'base_model': {'response': ' Based on the given sentence, the following relation might be extracted:\\n(/location/location_name/temple, /location/located_in, /location/city/shanghai)\\n(Ms. Qin, /people/person/place_lived, /location/city/shanghai)\\n(Jade Buddha Temple, /business/location, /location/location_name/temple)\\nNote that there seems to be no clear head entity for the relation \"/location/country\" or any other country-related relation as the sentence does not provide enough context about the location being in a specific country. Therefore, I would not include such relations in my answer.',\n",
              "   'predicted_relations': [['/location/location_name/temple',\n",
              "     '/location/located_in',\n",
              "     '/location/city/shanghai'],\n",
              "    ['Ms. Qin', '/people/person/place_lived', '/location/city/shanghai'],\n",
              "    ['Jade Buddha Temple',\n",
              "     '/business/location',\n",
              "     '/location/location_name/temple']],\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': 'As the new face of the L.P.G.A. Tour , and as a star in Mexico and elsewhere , Ochoa seems to have taken to the job of being a role model .',\n",
              "  'output': 'None',\n",
              "  'base_model': {'response': ' Based on the given sentence, there do not seem to be any explicit relations mentioned that can be extracted using the provided list. Therefore, the answer would be: None.',\n",
              "   'predicted_relations': 'None',\n",
              "   'precision': 1.0,\n",
              "   'recall': 1.0,\n",
              "   'f1': 1.0}},\n",
              " {'input': \"At this point , he added , '' all the information we have is that it is a localized situation to Seoul , South Korea . ''\",\n",
              "  'output': \"('Seoul', '/location/located_in', 'South Korea'), ('South Korea', '/location/country/administrative_divisions', 'Seoul'), ('Seoul', '/location/administrative_division/country', 'South Korea')\",\n",
              "  'base_model': {'response': \" Based on the given sentence, the following relation might be extracted:\\n('/location/located_in', 'it', 'Seoul')\\n('/location/country/administrative_divisions', 'Seoul', 'South Korea')\\nTherefore, the relation triples would look like:\\n(it, '/location/located_in', Seoul)\\n(Seoul, '/location/country/administrative_divisions', South Korea)\",\n",
              "   'predicted_relations': [['/location/located_in', 'it', 'Seoul'],\n",
              "    ['/location/country/administrative_divisions', 'Seoul', 'South Korea'],\n",
              "    ['it', '/location/located_in', 'Seoul'],\n",
              "    ['Seoul', '/location/country/administrative_divisions', 'South Korea']],\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': \"Avi Dichter , a former Shin Bet director and now public security minister , said that Khaled Meshal , the political director of Hamas who is in exile in Damascus , Syria , would not be immune from Israeli attack . ''\",\n",
              "  'output': \"('Syria', '/location/country/administrative_divisions', 'Damascus'), ('Damascus', '/location/located_in', 'Syria'), ('Damascus', '/location/administrative_division/country', 'Syria')\",\n",
              "  'base_model': {'response': ' Based on the given sentence, the following relation triples can be extracted:\\n(Avi Dichter, /people/person/nationality, Israeli)\\n(Avi Dichter, /business/person/role, former Shin Bet director)\\n(Avi Dichter, /business/person/role, public security minister)\\n(Khaled Meshal, /people/person/nationality, Palestinian)\\n(Khaled Meshal, /organization/political_entity/position, political director of Hamas)\\n(Hamas, /business/location, Damascus, Syria)\\n(Khaled Meshal, /people/deceasedperson/place_of_death, Unknown)\\n(Khaled Meshal, /location/country/administrative_divisions, Syria)\\n(Khaled Meshal, /location/located_in, Damascus, Syria)',\n",
              "   'predicted_relations': [['Avi Dichter',\n",
              "     '/people/person/nationality',\n",
              "     'Israeli'],\n",
              "    ['Avi Dichter', '/business/person/role', 'former Shin Bet director'],\n",
              "    ['Avi Dichter', '/business/person/role', 'public security minister'],\n",
              "    ['Khaled Meshal', '/people/person/nationality', 'Palestinian'],\n",
              "    ['Khaled Meshal',\n",
              "     '/organization/political_entity/position',\n",
              "     'political director of Hamas'],\n",
              "    ['Hamas', '/business/location', 'Damascus, Syria'],\n",
              "    ['Khaled Meshal', '/people/deceasedperson/place_of_death', 'Unknown'],\n",
              "    ['Khaled Meshal', '/location/country/administrative_divisions', 'Syria'],\n",
              "    ['Khaled Meshal', '/location/located_in', 'Damascus, Syria']],\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': 'Beth Lee , President Rabbi David J. Gelfand $ -LRB- 6 $ -RRB- RESNICK -- Mildred Rothstein , of Ellenville , New York and Aventura , Florida passed away on January 8 , 2007 at age 90 .',\n",
              "  'output': \"('Aventura', '/location/located_in', 'Florida')\",\n",
              "  'base_model': {'response': ' Based on the given sentence, the following relation triple can be extracted:\\n(Mildred Rothstein, /people/person/place_lived, \"Ellenville\")\\n(Mildred Rothstein, /people/person/place_lived, \"Aventura\")\\nThere are no other relations that can be directly extracted from this sentence using the given list.',\n",
              "   'predicted_relations': [['Mildred Rothstein',\n",
              "     '/people/person/place_lived',\n",
              "     'Ellenville'],\n",
              "    ['Mildred Rothstein', '/people/person/place_lived', 'Aventura']],\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': \"Billy Donovan , who coached the Florida men 's team to its second consecutive N.C.A.A. title last month , and Pat Summitt , who coached the Tennessee women to their seventh title in her 33 years on the job , received the annual Winged Foot Awards last night at a dinner at the New York Athletic Club .\",\n",
              "  'output': \"('Billy Donovan', '/people/person/place_lived', 'Florida')\",\n",
              "  'base_model': {'response': \" Based on the given sentence, there are no explicit location or company entities mentioned. Therefore, the following relations cannot be extracted directly from the text: ['/business/company/advisors', '/business/location', '/business/person/company', '/location/administrative_division/country', '/location/country/administrative_divisions', '/location/located_in', '/people/deceasedperson/place_of_death', '/people/person/nationality', '/people/person/place_lived', '/people/person/place_of_birth']. However, we can infer that the New York Athletic Club is a location where the event took place. So, one possible relation would be: ('New York Athletic Club', '/location/venue', None)\",\n",
              "   'predicted_relations': 'None',\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': 'Born in California in 1969 , Kara Walker seems young for a full-scale museum survey .',\n",
              "  'output': \"('Kara Walker', '/people/person/place_of_birth', 'California')\",\n",
              "  'base_model': {'response': ' Based on the given sentence, the following relation can be extracted:\\n(head entity: \"Kara Walker\", relation: \"/people/person/place_of_birth\", tail entity: \"California\")',\n",
              "   'predicted_relations': [['head entity: \"Kara Walker',\n",
              "     'relation: \"/people/person/place_of_birth',\n",
              "     'tail entity: \"California']],\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': \"But when Frederick Ashton did this in his 1955 production for the Royal Danish Ballet -LRB- presumably the version the Danish-born Mr. Martins grew up with -RRB- , he made the men 's mysterious arrival fateful , like that of the three characters who come masked to the ball in Mozart 's '' Don Giovanni . ''\",\n",
              "  'output': \"('Frederick Ashton', '/business/person/company', 'Royal Danish Ballet')\",\n",
              "  'base_model': {'response': ' None.\\nIn the given sentence, there are no explicit mentions of companies, locations, or people with specified relationships using the provided relation types. The sentence primarily discusses the actions and productions of individuals (Frederick Ashton) and their associations with ballets and countries (Royal Danish Ballet, Denmark). However, there is no clear indication of advisory roles, nationalities, places lived, or places of birth mentioned explicitly in the text.',\n",
              "   'predicted_relations': 'None',\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': \"By noon , Byron York , a correspondent for the conservative National Review , had written in an online analysis that it had been '' a disastrous morning '' for Mr. Gonzales .\",\n",
              "  'output': \"('Byron York', '/business/person/company', 'National Review')\",\n",
              "  'base_model': {'response': \" None.\\nIn this sentence, there are no explicit mentions of locations, companies or countries associated with the entities 'Byron York' or 'Mr. Gonzales'. Therefore, no relation from the given list can be extracted from this sentence.\",\n",
              "   'predicted_relations': 'None',\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': \"Cleveland 's quarterback -- Frank Ryan , who was studying for a doctorate in math from Rice University during his playing days -- threw three touchdown passes , all to Gary Collins .\",\n",
              "  'output': \"('Frank Ryan', '/business/person/company', 'Cleveland')\",\n",
              "  'base_model': {'response': \" Based on the given sentence, there aren't any explicit relations mentioned that can be directly extracted using the provided list. However, we can infer some implicit relations as follows:\\n\\n(Frank Ryan, /people/person/place_lived, Cleveland)\\n(Frank Ryan, /business/person/company, Rice University)\\n(Rice University, /location/country/administrative_divisions, United States)\\n\\nThese relations represent that Frank Ryan lived in Cleveland, studied at Rice University which is located in the United States. Note that these relations are derived from the information given in the sentence and not explicitly stated.\",\n",
              "   'predicted_relations': [['Frank Ryan',\n",
              "     '/people/person/place_lived',\n",
              "     'Cleveland'],\n",
              "    ['Frank Ryan', '/business/person/company', 'Rice University'],\n",
              "    ['Rice University',\n",
              "     '/location/country/administrative_divisions',\n",
              "     'United States']],\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': \"Coincidentally , the movie Mr. Starkweather inspired , Terrence Malick 's '' Badlands , '' involves a flight to Saskatchewan .\",\n",
              "  'output': 'None',\n",
              "  'base_model': {'response': \" Based on the given sentence, there doesn't seem to be any clear-cut relation that can be extracted using the entities and relation types provided in the list. Therefore, the answer would be: None.\",\n",
              "   'predicted_relations': 'None',\n",
              "   'precision': 1.0,\n",
              "   'recall': 1.0,\n",
              "   'f1': 1.0}},\n",
              " {'input': \"Correction : June 9 , 2007 , Saturday An article in Business Day on May 29 about Russia 's strategy to gain a monopoly in natural gas exports to Asia through Gazprom misstated the percentage of ownership in the Kovykta gas field by TNK-BP , which is being accused by the Kremlin of having failed to meet license requirements .\",\n",
              "  'output': 'None',\n",
              "  'base_model': {'response': \" None.\\nThe given sentence does not provide sufficient information for any relation from the list to be extracted. It mentions entities such as 'Business Day', 'Russia', 'Gazprom', 'Kovykta gas field', 'TNK-BP', and 'May 29'. However, no explicit relationships between these entities are stated in the sentence.\",\n",
              "   'predicted_relations': 'None',\n",
              "   'precision': 1.0,\n",
              "   'recall': 1.0,\n",
              "   'f1': 1.0}},\n",
              " {'input': \"Correction : March 7 , 2007 , Wednesday An article on Sunday about an antigovernment protest in Russia referred incorrectly to Garry Kasparov , a former world chess champion , who is also a member of Russia 's liberal political opposition and who spoke to the crowd .\",\n",
              "  'output': \"('Garry Kasparov', '/people/person/nationality', 'Russia')\",\n",
              "  'base_model': {'response': \" None.\\nThe sentence mentions entities 'March 7, 2007', 'Sunday', 'Russia', 'Garry Kasparov', 'world chess champion', 'former world chess champion', 'antigovernment protest', 'Russia's liberal political opposition', 'crowd'. However, there are no explicit relationships mentioned between these entities in the sentence that can be extracted using the provided relation types.\",\n",
              "   'predicted_relations': 'None',\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': \"Dr. Hawking announced on his 65th birthday , in January , that he hoped to take a longer , higher flight in 2009 on a space plane being developed by Richard Branson 's company Virgin Galactic , which seeks to take six passengers to an altitude of 70 miles .\",\n",
              "  'output': \"('Virgin Galactic', '/business/company/advisors', 'Richard Branson'), ('Richard Branson', '/business/person/company', 'Virgin Galactic')\",\n",
              "  'base_model': {'response': ' Based on the given sentence, the following relation triples can be extracted:\\n(Dr. Hawking, /people/person/place_lived, January)\\n(Dr. Hawking, /people/person/place_lived, \"his 65th birthday\")\\n(Virgin Galactic, /business/company/advisors, Dr. Hawking)\\n(Virgin Galactic, /business/location/located_in, \"space\")\\n(Richard Branson, /people/person/nationality, British)\\n(Virgin Galactic, /business/person/company, Richard Branson)',\n",
              "   'predicted_relations': [['Dr. Hawking',\n",
              "     '/people/person/place_lived',\n",
              "     'January'],\n",
              "    ['Dr. Hawking', '/people/person/place_lived', 'his 65th birthday'],\n",
              "    ['Virgin Galactic', '/business/company/advisors', 'Dr. Hawking'],\n",
              "    ['Virgin Galactic', '/business/location/located_in', 'space'],\n",
              "    ['Richard Branson', '/people/person/nationality', 'British'],\n",
              "    ['Virgin Galactic', '/business/person/company', 'Richard Branson']],\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': 'Evan Almighty Hilarity ensues when God -LRB- Morgan Freeman -RRB- commands a newly elected congressman -LRB- Steve Carell -RRB- to start building an ark in his Virginia backyard .',\n",
              "  'output': \"('Morgan Freeman', '/people/person/place_lived', 'Virginia'), ('Steve Carell', '/people/person/place_lived', 'Virginia')\",\n",
              "  'base_model': {'response': \" Based on the given sentence, there aren't any explicit relations mentioned that can be directly extracted using the provided list. Therefore, the answer would be: None.\",\n",
              "   'predicted_relations': 'None',\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': 'Even with the $ 7.6 billion in donations and pledges , Mr. Siniora will still return to Lebanon with a battle on his hands as he tries to establish an international tribunal that could eventually implicate Syria in the assassination of Rafik Hariri , a former Lebanese prime minister who was an outspoken critic of Syria .',\n",
              "  'output': \"('Rafik Hariri', '/people/person/place_lived', 'Lebanon'), ('Rafik Hariri', '/people/person/nationality', 'Lebanon')\",\n",
              "  'base_model': {'response': ' None.\\nIn this sentence, there are no explicit mentions of companies, locations, or people with specified relationships using the provided relation types. The sentence primarily discusses monetary amounts, political actions, and geographical references without specifying entities in a relational context according to the given relation types.',\n",
              "   'predicted_relations': 'None',\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': \"For the powers at the Creative Artists Agency , Hollywood 's pre-eminent talent representative , the coming blockbuster '' Transformers '' has already brought a lesson in the cold-hearted ways of corporate entertainment .\",\n",
              "  'output': \"('Creative Artists Agency', '/business/location', 'Hollywood')\",\n",
              "  'base_model': {'response': \" None.\\nIn this sentence, there are no explicit mentions of entities or their relationships that can be extracted using the provided relation types. The sentence discusses the Creative Artists Agency being Hollywood's pre-eminent talent representative and the impact of the Transformers blockbuster on them, but it does not provide enough information for extracting specific entities and their relationships based on the given relation types.\",\n",
              "   'predicted_relations': 'None',\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': 'From 1981 to 1983 , Mr. Kline was a Fulbright scholar in Cracow , Poland , doing research on Stanislaw Wyspianski , the Polish painter and poet , and teaching English as a second language at Jagiellonian University .',\n",
              "  'output': \"('Cracow', '/location/located_in', 'Poland'), ('Poland', '/location/country/administrative_divisions', 'Cracow')\",\n",
              "  'base_model': {'response': ' Based on the given sentence, the following relation triples can be extracted:\\n(Mr. Kline, /people/person/place_lived, Cracow)\\n(Mr. Kline, /business/location, Jagiellonian University)\\n(Cracow, /location/country/administrative_divisions, Poland)\\n(Poland, /location/country, None)\\n(Mr. Kline, /business/company/advisors, Fulbright Scholarship)\\n(Fulbright Scholarship, /people/person, Mr. Kline)\\n(Stanislaw Wyspianski, /people/person, None)\\n(Stanislaw Wyspianski, /business/artist, None)\\n(Jagiellonian University, /business/educational_institution, None)\\n\\nThese relation triples represent that Mr. Kline lived in Cracow, he worked at Jagiellonian University, Cracow is located in Poland, and Mr. Kline was a Fulbright scholar. Note that some entities in the sentence do not have clear relationships with others based on the given',\n",
              "   'predicted_relations': 'None',\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': \"George Zoritch , in his youth an Adonis the Ballets Russes alumnae still rhapsodize about , ended his career on the dance faculty at the University of Arizona in Tucson . ''\",\n",
              "  'output': \"('University of Arizona', '/location/located_in', 'Tucson')\",\n",
              "  'base_model': {'response': ' Based on the given sentence, the following relation triple may be extracted:\\n(George Zoritch, /people/person/place_lived, University of Arizona in Tucson)',\n",
              "   'predicted_relations': [['George Zoritch',\n",
              "     '/people/person/place_lived',\n",
              "     'University of Arizona in Tucson']],\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': 'He had tested positive for a banned substance three months earlier at a tournament in Acapulco , Mexico .',\n",
              "  'output': \"('Acapulco', '/location/located_in', 'Mexico')\",\n",
              "  'base_model': {'response': \" Based on the given sentence, there isn't a clear head entity or tail entity identified directly from the text that can be associated with any relation type from the list provided. However, we can infer some implicit entities and their relationships as follows:\\n\\n(Location 'Acapulco', relation '/location/located_in', Country 'Mexico')\\n\\nThis relation indicates that 'Acapulco' is located in 'Mexico'. While this information is not explicitly stated in the sentence, it is implied by mentioning 'Acapulco, Mexico' together. This relation does not involve any named person mentioned in the sentence. Therefore, no direct relation between people or companies can be determined based on the given sentence alone.\\n\\nSo, the final answer would be:\\n[(Location 'Acapulco'), ('/location/located_in', Country 'Mexico')]\",\n",
              "   'predicted_relations': [[\"Location 'Acapulco\",\n",
              "     \"relation '/location/located_in\",\n",
              "     \"Country 'Mexico\"],\n",
              "    [\"Location 'Acapulco')\", \"('/location/located_in\", \"Country 'Mexico\"]],\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': \"He plans to name the Connecticut attorney general , Richard Blumenthal , as his state campaign chairman , and Representative Rosa DeLauro of Connecticut , who was once Mr. Dodd 's chief of staff , as a national chairwoman .\",\n",
              "  'output': \"('Rosa DeLauro', '/people/person/place_lived', 'Connecticut')\",\n",
              "  'base_model': {'response': \" Based on the given sentence, the following relation triples can be extracted:\\n(Richard Blumenthal, /business/person/company, State campaign chairman)\\n(Richard Blumenthal, /business/person/company, He)\\n(Rosa DeLauro, /business/person/company, National chairwoman)\\n(Rosa DeLauro, /business/person/company, He)\\n(Rosa DeLauro, /location/located_in, Connecticut)\\nTherefore, the relations that might be included in the given sentence are: ['/business/person/company'].\",\n",
              "   'predicted_relations': [['Richard Blumenthal',\n",
              "     '/business/person/company',\n",
              "     'State campaign chairman'],\n",
              "    ['Richard Blumenthal', '/business/person/company', 'He'],\n",
              "    ['Rosa DeLauro', '/business/person/company', 'National chairwoman'],\n",
              "    ['Rosa DeLauro', '/business/person/company', 'He'],\n",
              "    ['Rosa DeLauro', '/location/located_in', 'Connecticut']],\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': 'He was referring to coverage in the mainstream newspaper Hurriyet that said Mr. Asgari arrived at the Istanbul airport on Feb. 7 after moving his family to safety in Damascus , Syria .',\n",
              "  'output': \"('Damascus', '/location/located_in', 'Syria'), ('Syria', '/location/country/administrative_divisions', 'Damascus'), ('Damascus', '/location/administrative_division/country', 'Syria')\",\n",
              "  'base_model': {'response': ' Based on the given sentence, the following relation triple can be extracted:\\n(Mr. Asgari, /people/person/place_lived, Damascus)\\n(Damascus, /location/country/administrative_divisions, Syria)\\n(Hurriyet, /business/media/newspaper, None)\\n(Istanbul airport, /location/airport, None)\\n(Mr. Asgari, /people/person/place_arrived, Istanbul airport)\\n(Date \"Feb. 7\", /time/date, None)\\n\\nThese triples represent that Mr. Asgari lived in Damascus, which is located in Syria, and he arrived at the Istanbul airport on February 7th. The newspaper Hurriyet is represented as a media organization without any specific location or relation mentioned in the sentence.',\n",
              "   'predicted_relations': 'None',\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': \"Her mother , Sarah Edwards , grew up in a town house a few doors down , where Virginia 's grandmother still lives .\",\n",
              "  'output': \"('Sarah Edwards', '/people/person/place_lived', 'Virginia')\",\n",
              "  'base_model': {'response': ' Based on the given sentence, the following relation triple can be extracted:\\n(person \"Sarah Edwards\", relation \"/location/person/place_lived\", location \"a town house\")\\n(location \"a town house\", relation \"/location/located_in\", location \"where Virginia \\'s grandmother still lives\")',\n",
              "   'predicted_relations': [['person \"Sarah Edwards',\n",
              "     'relation \"/location/person/place_lived',\n",
              "     'location \"a town house'],\n",
              "    ['location \"a town house',\n",
              "     'relation \"/location/located_in',\n",
              "     'location \"where Virginia \\'s grandmother still lives']],\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': 'Her mother is an assistant treasurer of the NewAlliance Bank based in New Haven and is the manager of branches in Storrs and Hebron , Conn. .',\n",
              "  'output': \"('NewAlliance Bank', '/business/location', 'New Haven')\",\n",
              "  'base_model': {'response': ' Based on the given sentence, the following relation triples can be extracted:\\n(person \"mother\", /business/person/employee/position, newalliance_bank)\\n(newalliance_bank, /business/company/location, new_haven)\\n(newalliance_bank, /business/company/location, storrss)\\n(newalliance_bank, /business/company/location, hebron_conn)\\nTherefore, the mother is an employee of NewAlliance Bank, which has locations in New Haven, Storrs, and Hebron, Connecticut.',\n",
              "   'predicted_relations': [['person \"mother',\n",
              "     '/business/person/employee/position',\n",
              "     'newalliance_bank'],\n",
              "    ['newalliance_bank', '/business/company/location', 'new_haven'],\n",
              "    ['newalliance_bank', '/business/company/location', 'storrss'],\n",
              "    ['newalliance_bank', '/business/company/location', 'hebron_conn']],\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': 'However the legal case turns out , the Yellowstone Club is likely to leave a lasting impression across the mountains of southern Montana , with its massive , stylish and , some say , excessive version of good living .',\n",
              "  'output': 'None',\n",
              "  'base_model': {'response': \" Based on the given sentence, the following relation might be applicable:\\n['/business/location': 'Yellowstone Club', '/location/located_in': {'Montana', 'southern Montana'} ]\\nThis relation indicates that the 'Yellowstone Club' is located in 'Montana' or more specifically, 'southern Montana'.\",\n",
              "   'predicted_relations': [],\n",
              "   'precision': 0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': 'INDIAN EXCHANGES DIVERSIFY -- The Bombay Stock Exchange sold a 5 percent stake to the Singapore Stock Exchange for 1.89 billion India rupees , or $ 42.6 million , and the exchange in Calcutta said it planned to sell 51 percent of its shares to partners and strategic investors .',\n",
              "  'output': \"('Calcutta', '/location/located_in', 'India')\",\n",
              "  'base_model': {'response': ' Based on the given sentence, the following relation triples can be extracted:\\n(Bombay Stock Exchange, /business/company/sold_stake, Singapore Stock Exchange)\\n(Calcutta Exchange, /business/company/planned_to_sell, Partners and strategic investors)\\n(Singapore Stock Exchange, /location/country/from, India)\\n(Bombay Stock Exchange, /location/country/from, India)\\n(Calcutta Exchange, /location/country/from, India)\\nTherefore, the answer is: [(Bombay Stock Exchange, /business/company/sold_stake, Singapore Stock Exchange), (Calcutta Exchange, /business/company/planned_to_sell, Partners and strategic investors), (Singapore Stock Exchange, /location/country/from, India), (Bombay Stock Exchange, /location/country/from, India), (Calcutta Exchange, /location/country/from, India)]',\n",
              "   'predicted_relations': [['Bombay Stock Exchange',\n",
              "     '/business/company/sold_stake',\n",
              "     'Singapore Stock Exchange'],\n",
              "    ['Calcutta Exchange',\n",
              "     '/business/company/planned_to_sell',\n",
              "     'Partners and strategic investors'],\n",
              "    ['Singapore Stock Exchange', '/location/country/from', 'India'],\n",
              "    ['Bombay Stock Exchange', '/location/country/from', 'India'],\n",
              "    ['Calcutta Exchange', '/location/country/from', 'India'],\n",
              "    ['Bombay Stock Exchange',\n",
              "     '/business/company/sold_stake',\n",
              "     'Singapore Stock Exchange'],\n",
              "    ['Calcutta Exchange',\n",
              "     '/business/company/planned_to_sell',\n",
              "     'Partners and strategic investors'],\n",
              "    ['Singapore Stock Exchange', '/location/country/from', 'India'],\n",
              "    ['Bombay Stock Exchange', '/location/country/from', 'India'],\n",
              "    ['Calcutta Exchange', '/location/country/from', 'India']],\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': \"In Amman , Mr. Ban 's plane left him at Queen Alia International Airport while his welcoming party awaited him 20 miles away at Amman Airport .\",\n",
              "  'output': \"('Queen Alia International Airport', '/location/located_in', 'Amman')\",\n",
              "  'base_model': {'response': ' Based on the given sentence, the following relation triples can be extracted:\\n(Queen Alia International Airport, /location/located_in, Amman)\\n(Amman, /location/administrative_division/country, Jordan)\\n(Mr. Ban, /people/person/place_of_birth, Unknown) % This information is not explicitly stated in the sentence but assumed based on the mention of his name\\n(Mr. Ban, /people/person/place_lived, Unknown) % Same as above\\n(Mr. Ban, /business/person/place_of_death, Unknown) % Same as above\\n(Queen Alia International Airport, /business/location, Amman Airport) % Assuming \"Airport\" refers to a specific location named \"Amman Airport\"\\n(Mr. Ban, /people/person, Mr. Ban\\'s welcoming party) % Implicit relation between Mr. Ban and his welcoming party\\n(Mr. Ban\\'s welcoming party, /business/person/company, Unknown) % We don\\'t have enough information to determine the company affiliation of Mr. Ban\\'s welcoming party.',\n",
              "   'predicted_relations': [['Queen Alia International Airport',\n",
              "     '/location/located_in',\n",
              "     'Amman'],\n",
              "    ['Amman', '/location/administrative_division/country', 'Jordan'],\n",
              "    ['Mr. Ban', '/people/person/place_of_birth', 'Unknown'],\n",
              "    ['Mr. Ban', '/people/person/place_lived', 'Unknown'],\n",
              "    ['Mr. Ban', '/business/person/place_of_death', 'Unknown'],\n",
              "    ['Queen Alia International Airport',\n",
              "     '/business/location',\n",
              "     'Amman Airport'],\n",
              "    ['Mr. Ban', '/people/person', \"Mr. Ban's welcoming party\"],\n",
              "    [\"Mr. Ban's welcoming party\", '/business/person/company', 'Unknown']],\n",
              "   'precision': 0.125,\n",
              "   'recall': 1.0,\n",
              "   'f1': 0.2222222222222222}},\n",
              " {'input': \"In a telephone interview from Khartoum on Tuesday , as she and a three-member camera crew prepared for a two-hour flight on a small plane into Darfur , Ms. Curry was asked why she had felt compelled to return to Sudan twice since her first visit . ''\",\n",
              "  'output': 'None',\n",
              "  'base_model': {'response': \" Based on the given sentence, there do not seem to be any explicit entities or relationships that can be extracted using the provided relation types. The sentence mentions 'Ms. Curry' who is a person, 'Khartoum' which is a location, and 'Darfur' which is also a location. However, the relation types provided do not include simple 'person-location' or 'location-location' relationships like 'person/place_lived' or 'location/located_in'. Therefore, no relationship triples can be extracted directly from this sentence using the given relation types.\\n\\nNone.\",\n",
              "   'predicted_relations': 'None',\n",
              "   'precision': 1.0,\n",
              "   'recall': 1.0,\n",
              "   'f1': 1.0}},\n",
              " {'input': \"In another development , Mr. Olmert has asked security officials to examine the possibility of re-routing part of Israel 's West Bank separation barrier to bring two additional Jewish settlements inside its walls , his office said Wednesday .\",\n",
              "  'output': \"('West Bank', '/location/located_in', 'Israel')\",\n",
              "  'base_model': {'response': \" Based on the given sentence, there do not seem to be any explicit entities or relationships mentioned that can be directly extracted using the provided relation types. The sentence primarily discusses actions taken by Mr. Olmert and mentions locations (Israel's West Bank separation barrier) but does not provide enough information for extracting specific entities or their relationships according to the given relation types. Therefore, the answer would be: None.\",\n",
              "   'predicted_relations': 'None',\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': 'In the 1960s the town of Jindabyne was intentionally flooded by the damming of a river and left at the bottom of a newly created lake in the middle of the Snowy Mountains in southeastern Australia .',\n",
              "  'output': \"('Jindabyne', '/location/located_in', 'Australia')\",\n",
              "  'base_model': {'response': \" Based on the given sentence, the following relation triples can be extracted:\\n(entity: 'Jindabyne', relation: '/location/located_in', entity: 'a newly created lake')\\n(entity: 'Jindabyne', relation: '/location/is_part_of', entity: 'the Snowy Mountains')\\n(entity: 'Snowy Mountains', relation: '/location/is_part_of', entity: 'southeastern Australia')\\n(entity: 'Australia', relation: '/location/country', entity: 'southeastern Australia')\",\n",
              "   'predicted_relations': [[\"entity: 'Jindabyne\",\n",
              "     \"relation: '/location/located_in\",\n",
              "     \"entity: 'a newly created lake\"],\n",
              "    [\"entity: 'Jindabyne\",\n",
              "     \"relation: '/location/is_part_of\",\n",
              "     \"entity: 'the Snowy Mountains\"],\n",
              "    [\"entity: 'Snowy Mountains\",\n",
              "     \"relation: '/location/is_part_of\",\n",
              "     \"entity: 'southeastern Australia\"],\n",
              "    [\"entity: 'Australia\",\n",
              "     \"relation: '/location/country\",\n",
              "     \"entity: 'southeastern Australia\"]],\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': 'In the next several years , dams on the Elwha and White Salmon Rivers in Washington and the Sandy River in Oregon are scheduled to be removed .',\n",
              "  'output': \"('Elwha', '/location/located_in', 'Washington')\",\n",
              "  'base_model': {'response': ' None.\\nThe given sentence does not provide enough information for any relation from the list to be extracted. It mentions rivers and states but there are no specific entities or people mentioned that could be related by these relations.',\n",
              "   'predicted_relations': 'None',\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': \"Israel 's head of military intelligence , Amos Yadlin , told cabinet officials on Sunday that Israeli intelligence had seen signs of defensive planning by Syria , Iran and the Lebanese militant group Hezbollah , all seemingly bracing for a possible attack by the United States in the coming months .\",\n",
              "  'output': \"('Amos Yadlin', '/people/person/nationality', 'Israel')\",\n",
              "  'base_model': {'response': \" Based on the given sentence, there are no explicit relations mentioned between entities in the provided list. However, we can infer some implicit relations as follows:\\n(Israel, /location/country/administrative_divisions, 'Israel')\\n(Amos Yadlin, /people/person/nationality, 'Israel')\\n(Syria, /business/location, 'Syria')\\n(Iran, /business/location, 'Iran')\\n(Lebanon, /business/location, 'Lebanon')\\n(Hezbollah, /organization/militant_group/name, 'Hezbollah')\\n(Hezbollah, /business/location, 'Lebanon')\\n(United States, /business/country, 'United States')\\nThese relations are inferred based on the context of the sentence and do not directly appear in the sentence itself.\",\n",
              "   'predicted_relations': [['Israel',\n",
              "     '/location/country/administrative_divisions',\n",
              "     'Israel'],\n",
              "    ['Amos Yadlin', '/people/person/nationality', 'Israel'],\n",
              "    ['Syria', '/business/location', 'Syria'],\n",
              "    ['Iran', '/business/location', 'Iran'],\n",
              "    ['Lebanon', '/business/location', 'Lebanon'],\n",
              "    ['Hezbollah', '/organization/militant_group/name', 'Hezbollah'],\n",
              "    ['Hezbollah', '/business/location', 'Lebanon'],\n",
              "    ['United States', '/business/country', 'United States']],\n",
              "   'precision': 0.125,\n",
              "   'recall': 1.0,\n",
              "   'f1': 0.2222222222222222}},\n",
              " {'input': \"Israel annexed Jerusalem in 1967 and offered full citizenship at the time to all of Jerusalem 's residents .\",\n",
              "  'output': \"('Jerusalem', '/location/located_in', 'Israel')\",\n",
              "  'base_model': {'response': \" Based on the given sentence, there isn't any direct relation that can be extracted using the provided list. The sentence mentions 'Israel' and 'Jerusalem', but it doesn't explicitly state that Jerusalem is a location 'administered by' or 'located in' Israel, nor does it mention any specific person or company. Therefore, no relation triples can be derived from this sentence based on the given list.\\n\\nNone.\",\n",
              "   'predicted_relations': 'None',\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': \"It 's a pain , '' said Eli Gold , 17 , a high school student from Piedmont , Calif. , who was staying in New York with 16 other students for a conference and was told early yesterday morning that his 8 p.m. flight had been canceled . ''\",\n",
              "  'output': \"('Eli Gold', '/people/person/place_lived', 'Piedmont')\",\n",
              "  'base_model': {'response': ' Based on the given sentence, there are no explicit entities or relations mentioned from the provided list. Therefore, the answer would be: None.',\n",
              "   'predicted_relations': 'None',\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': \"It is in the interest of Europe , its member states and its citizens to bring this process to a successful conclusion , '' she told Parliament 's assembly in Strasbourg , France , referring to the stalemate over the constitution , which was rejected in referendums in the Netherlands and France in 2005 . ''\",\n",
              "  'output': \"('France', '/location/country/administrative_divisions', 'Strasbourg'), ('Strasbourg', '/location/located_in', 'France')\",\n",
              "  'base_model': {'response': ' Based on the given sentence, the following relation triple can be extracted:\\n(Europe, /location/country/administrative_divisions, France)\\nExplanation: In the sentence, \"Parliament\\'s assembly in Strasbourg, France\" implies that Strasbourg is located in France, making France an administrative division of Europe according to the given relation type \"/location/country/administrative_divisions\".',\n",
              "   'predicted_relations': [['Europe',\n",
              "     '/location/country/administrative_divisions',\n",
              "     'France']],\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': \"Its parent , DaimlerChrysler of Germany , said in February that it would consider selling Chrysler , and board members are expected to receive a barrage of questions from shareholders about a sale at the company 's annual meeting in Berlin today .\",\n",
              "  'output': \"('Berlin', '/location/administrative_division/country', 'Germany'), ('Berlin', '/location/located_in', 'Germany'), ('Germany', '/location/country/administrative_divisions', 'Berlin')\",\n",
              "  'base_model': {'response': ' Based on the given sentence, the following relation triple can be extracted:\\n(DaimlerChrysler, /business/person/company/parent_company, Its parent)\\n(DaimlerChrysler, /location/country, Germany)\\n(Germany, /location/administrative_division/country, None)\\n(Berlin, /location/city, None)\\n(Chrysler, /business/person/company, Its parent)\\n(Its parent, /business/location/located_in, Berlin)\\nTherefore, the relations extracted from the sentence are: parent_company, country, located_in.',\n",
              "   'predicted_relations': 'None',\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': 'Its portfolio is concentrated in some of the best neighborhoods in Washington , Southern California , New York , the San Francisco Bay area , Boston and Seattle .',\n",
              "  'output': 'None',\n",
              "  'base_model': {'response': \" Based on the given sentence, there seems to be no explicit mention of companies or specific people. However, we can infer that we're dealing with some entities related to locations. The sentence mentions several cities and regions in the United States.\\n\\nRelation: '/location/located_in'\\n\\nTriple 1: ('Washington', '/location/located_in', SomeCompanyOrRegion)\\nTriple 2: ('Southern California', '/location/located_in', SomeCompanyOrRegion)\\nTriple 3: ('New York', '/location/located_in', SomeCompanyOrRegion)\\nTriple 4: ('San Francisco Bay area', '/location/located_in', SomeCompanyOrRegion)\\nTriple 5: ('Boston', '/location/located_in', SomeCompanyOrRegion)\\nTriple 6: ('Seattle', '/location/located_in', SomeCompanyOrRegion)\\n\\nThese triples represent that the portfolio is located in these respective areas.\",\n",
              "   'predicted_relations': [['Washington',\n",
              "     '/location/located_in',\n",
              "     'SomeCompanyOrRegion'],\n",
              "    ['Southern California', '/location/located_in', 'SomeCompanyOrRegion'],\n",
              "    ['New York', '/location/located_in', 'SomeCompanyOrRegion'],\n",
              "    ['San Francisco Bay area', '/location/located_in', 'SomeCompanyOrRegion'],\n",
              "    ['Boston', '/location/located_in', 'SomeCompanyOrRegion'],\n",
              "    ['Seattle', '/location/located_in', 'SomeCompanyOrRegion']],\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': 'Its properties in Provence , France , start at $ 6,600 to $ 22,000 a week , depending on size and location .',\n",
              "  'output': \"('Provence', '/location/administrative_division/country', 'France')\",\n",
              "  'base_model': {'response': \" Based on the given sentence, the following relation might be present:\\n['/location/located_in', '/location/location_name/provence', '/location/location_name/france']\\nThis relation indicates that the locations 'Provence' and 'France' are located in each other. However, this may not be the intended meaning of the sentence as it mentions 'its properties' which could refer to buildings or establishments rather than locations per se. Therefore, this relation should be considered with caution and further context would be needed for accurate extraction.\",\n",
              "   'predicted_relations': [],\n",
              "   'precision': 0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': \"Jane Hobson New Orleans It seems curiously selective to discuss Pierre Vidal-Naquet 's writings on anti-Semitism at such length without mentioning the courageous positions he took on Israel and the Middle East -LRB- '' Denying the Deniers , '' Paul Berman -RRB- .\",\n",
              "  'output': \"('Israel', '/location/located_in', 'Middle East')\",\n",
              "  'base_model': {'response': \" None.\\nIn this sentence, there are no explicit mentions of companies, locations, or people with their relationships as per the given list. The sentence primarily focuses on discussing Pierre Vidal-Naquet's writings and his courageous positions on Israel and the Middle East.\",\n",
              "   'predicted_relations': 'None',\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': \"Jessica Lopez She is 43 , with a sociology degree from Sweet Briar , a women 's college in Virginia .\",\n",
              "  'output': \"('Sweet Briar', '/location/located_in', 'Virginia')\",\n",
              "  'base_model': {'response': \" Based on the given sentence, there isn't any clear relation that can be extracted using the provided list. The sentence mentions Jessica Lopez, her age, and the location of her alma mater, Sweet Briar, which is in Virginia. However, no explicit relation between these entities is stated in the sentence. Therefore, none.\",\n",
              "   'predicted_relations': 'None',\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': 'Jets \\\\* James Farrior , LB -LRB- Virginia -RRB- WHAT HAPPENED : After five years with the Jets , he has flourished with the Steelers , starting for the 2005 Super Bowl champions .',\n",
              "  'output': \"('James Farrior', '/people/person/place_lived', 'Virginia')\",\n",
              "  'base_model': {'response': \" Based on the given sentence, there is one possible relation that can be extracted:\\n(head entity: 'Jets', relation: '/business/person/company', tail entity: '[James Farrier]')\\nThis relation signifies that James Farrior was a person who was part of the company 'Jets'. However, no other relations from the given list appear explicitly in the sentence.\",\n",
              "   'predicted_relations': [[\"head entity: 'Jets\",\n",
              "     \"relation: '/business/person/company\",\n",
              "     \"tail entity: '[James Farrier]\"]],\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': 'Kuhn and his wife Luisa relocated to Ponte Vedra Beach , Florida in 1990 , where he continued his many charitable and philanthropic activities .',\n",
              "  'output': \"('Ponte Vedra Beach', '/location/located_in', 'Florida')\",\n",
              "  'base_model': {'response': ' Based on the given sentence, the following relation triple can be extracted:\\n(Kuhn, /people/person/place_lived, Ponte Vedra Beach)\\n(Ponte Vedra Beach, /location/located_in, Florida)',\n",
              "   'predicted_relations': [['Kuhn',\n",
              "     '/people/person/place_lived',\n",
              "     'Ponte Vedra Beach'],\n",
              "    ['Ponte Vedra Beach', '/location/located_in', 'Florida']],\n",
              "   'precision': 0.5,\n",
              "   'recall': 1.0,\n",
              "   'f1': 0.6666666666666666}},\n",
              " {'input': 'Lamar , Tex. , Independent School District , $ 150 million of debt securities for Fort Bend County , Tex. .',\n",
              "  'output': 'None',\n",
              "  'base_model': {'response': \" Based on the given sentence, the following relation triple can be extracted: ('Fort Bend County, Tex.', '/business/location/located_in', 'Fort Bend County School District, Lamar, Tex.'). This indicates that Fort Bend County is located in Fort Bend County School District, which is further specified as being in Lamar, Tex. However, no other relations from the given list appear explicitly in the sentence.\",\n",
              "   'predicted_relations': [['Fort Bend County',\n",
              "     'Tex.',\n",
              "     \"/business/location/located_in', 'Fort Bend County School District, Lamar, Tex.\"]],\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': \"Laure Manaudou of France won her latest gold medal in the women 's 400 freestyle , looking less than elated after she realized that she had failed to break her own world record .\",\n",
              "  'output': \"('Laure Manaudou', '/people/person/nationality', 'France'), ('Laure Manaudou', '/people/person/place_lived', 'France')\",\n",
              "  'base_model': {'response': \" None.\\nIn this sentence, we have mentioned 'Laure Manaudou of France' which can be considered as a person entity. However, no explicit location or company entities or their relationships are mentioned in the sentence.\",\n",
              "   'predicted_relations': 'None',\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': \"MIRAZUR At the Côte d'Azur 's most-talked-about new restaurant , the chef Mauro Colagreco -- from Alain Passard 's L'Arp ège in Paris -- trains his monklike reverence for fresh ingredients on local markets .\",\n",
              "  'output': \"('Alain Passard', '/people/person/place_lived', 'Paris')\",\n",
              "  'base_model': {'response': \" Based on the given sentence, the following relation triple can be extracted:\\n(MIRAZUR, /business/restaurant/type, most-talked-about new restaurant)\\n(chef Mauro Colagreco, /people/person/nationality, French) - This information is not explicitly stated in the sentence but assumed based on the context that he is from Paris, France.\\n(Mauro Colagreco, /business/person/occupation, chef)\\n(MIRAZUR, /location/region, Côte d'Azur)\\nTherefore, the final answer would look like this:\\n[(MIRAZUR, /business/restaurant/type, most-talked-about new restaurant),\\n (chef Mauro Colagreco, /people/person/nationality, French),\\n (Mauro Colagreco, /business/person/occupation, chef),\\n (MIRAZUR, /location/region, Côte d'Azur)]\",\n",
              "   'predicted_relations': [['MIRAZUR',\n",
              "     '/business/restaurant/type',\n",
              "     'most-talked-about new restaurant'],\n",
              "    ['chef Mauro Colagreco', '/people/person/nationality', 'French'],\n",
              "    ['Mauro Colagreco', '/business/person/occupation', 'chef'],\n",
              "    ['MIRAZUR', '/location/region', \"Côte d'Azur\"],\n",
              "    ['MIRAZUR',\n",
              "     '/business/restaurant/type',\n",
              "     'most-talked-about new restaurant'],\n",
              "    ['chef Mauro Colagreco', '/people/person/nationality', 'French'],\n",
              "    ['Mauro Colagreco', '/business/person/occupation', 'chef'],\n",
              "    ['MIRAZUR', '/location/region', \"Côte d'Azur\"]],\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': 'MORE than 60 years ago , as she awaited the final horrors of the Holocaust in the Bedzin ghetto of Poland , a 14-year-old Jewish girl named Rutka Laskier committed her thoughts to a diary .',\n",
              "  'output': \"('Rutka Laskier', '/people/person/place_lived', 'Poland')\",\n",
              "  'base_model': {'response': ' None.\\nThe sentence mentions a Jewish girl named Rutka Laskier who wrote a diary during the Holocaust in the Bedzin ghetto of Poland. However, no explicit business or location entities or their relationships are mentioned in the sentence.',\n",
              "   'predicted_relations': 'None',\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': 'Marie in 1991 and found a savior in Ted Nolan , also a member of the Ojibwa tribe .',\n",
              "  'output': \"('Ted Nolan', '/people/person/place_lived', 'Ojibwa')\",\n",
              "  'base_model': {'response': \" Based on the given sentence, there isn't enough information to extract any specific relation from the list provided. The sentence mentions Marie, Ted Nolan, and the fact that they were both members of the Ojibwa tribe at some point in time. However, no business entities or locations are mentioned, so we cannot extract any relations related to those concepts. Therefore, the answer would be: None.\",\n",
              "   'predicted_relations': 'None',\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': \"Martina McBride Waking Up Laughing -LRB- RCA\\\\/Sony BMG Nashville -RRB- '' I got pitched every social issue song on the planet . ''\",\n",
              "  'output': 'None',\n",
              "  'base_model': {'response': \" Based on the given sentence, there doesn't seem to be any explicit mention of entities or their relationships according to the provided list. Therefore, no relation triples can be extracted directly from this sentence.\\n\\nNone.\",\n",
              "   'predicted_relations': 'None',\n",
              "   'precision': 1.0,\n",
              "   'recall': 1.0,\n",
              "   'f1': 1.0}},\n",
              " {'input': 'Mr. Edwards tried to joke it off while campaigning in Adel , Iowa .',\n",
              "  'output': \"('Adel', '/location/located_in', 'Iowa')\",\n",
              "  'base_model': {'response': ' Based on the given sentence, there seems to be no explicit mention of any company or person advisor, location administrative division or country, deceased person, or place of birth or death. Therefore, none of the relations in the given list appear to be directly applicable to this sentence.',\n",
              "   'predicted_relations': 'None',\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': \"Nelly Furtado 's Weekend The pop singer Nelly Furtado was the big winner -LRB- and the host -RRB- when the Junos , Canada 's equivalent of the Grammys , were awarded in Toronto on Sunday , Reuters reported .\",\n",
              "  'output': \"('Canada', '/location/country/administrative_divisions', 'Toronto'), ('Toronto', '/location/located_in', 'Canada')\",\n",
              "  'base_model': {'response': ' Based on the given sentence, there are no explicit relations mentioned between entities that can be extracted using the provided relation types. Therefore, the answer would be: None.',\n",
              "   'predicted_relations': 'None',\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': 'Now that may not be necessary , with Israel and the West embracing the idea of a non-Hamas government , even if its powers are limited to the West Bank .',\n",
              "  'output': 'None',\n",
              "  'base_model': {'response': ' None.\\nIn this sentence, there are no explicit mentions of companies, locations, or people with their relationships as per the provided list. The sentence discusses the ideas and actions related to Israel and the West, but it does not provide sufficient information for extracting any specific entities or relations using the given list.',\n",
              "   'predicted_relations': 'None',\n",
              "   'precision': 1.0,\n",
              "   'recall': 1.0,\n",
              "   'f1': 1.0}},\n",
              " {'input': 'One by Loring Brinckerhoff , director of disability policy at the Educational Testing Service , highlights colleges with good comprehensive programs , including the University of Arizona in Tucson , Curry College in Massachusetts , Stanford and the University of North Carolina , Chapel Hill .',\n",
              "  'output': \"('University of Arizona', '/location/located_in', 'Tucson')\",\n",
              "  'base_model': {'response': ' Based on the given sentence, the following relation triples can be extracted:\\n(Educational Testing Service, /business/company/employee/has_employee, Loring Brinckerhoff)\\n(Loring Brinckerhoff, /people/person/occupation/is_occupation_of, director of disability policy)\\n(University of Arizona, /location/located_in, Tucson)\\n(Curry College, /location/located_in, Massachusetts)\\n(Stanford, None) % This entity doesn\\'t have any explicit relation mentioned in the text\\n(University of North Carolina, Chapel Hill, /location/located_in)\\n(University of North Carolina, Chapel Hill, /business/educational_institution/has_campus)\\nNote that for entities like \"Stanford\" which don\\'t have any explicit relation mentioned in the text but still need to be recognized as entities, we assign them a relation of type \\'None\\'.',\n",
              "   'predicted_relations': 'None',\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': 'Paul Secon , who in 1949 loaded the family station wagon with discontinued and slightly damaged ceramics from an upstate New York factory , drove to Manhattan and opened the first Pottery Barn store , died Feb. 24 at his home in Rochester .',\n",
              "  'output': \"('Paul Secon', '/people/deceasedperson/place_of_death', 'Rochester'), ('Paul Secon', '/people/person/place_lived', 'Rochester')\",\n",
              "  'base_model': {'response': ' Based on the given sentence, the following relation triples can be extracted:\\n(Paul Secon, /people/person/place_lived, Upstate New York)\\n(Paul Secon, /business/person/company, Pottery Barn)\\n(Pottery Barn, /location/located_in, Manhattan)\\n(Paul Secon, /people/person/place_of_death, Rochester)',\n",
              "   'predicted_relations': [['Paul Secon',\n",
              "     '/people/person/place_lived',\n",
              "     'Upstate New York'],\n",
              "    ['Paul Secon', '/business/person/company', 'Pottery Barn'],\n",
              "    ['Pottery Barn', '/location/located_in', 'Manhattan'],\n",
              "    ['Paul Secon', '/people/person/place_of_death', 'Rochester']],\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': 'Paul Touvier , the chief of the wartime paramilitary militia in Lyon , was sentenced to life in prison in 1994 after being convicted of ordering the execution of seven Jews .',\n",
              "  'output': \"('Paul Touvier', '/people/person/place_lived', 'Lyon')\",\n",
              "  'base_model': {'response': \" Based on the given sentence, the following relation triples can be extracted:\\n(Paul Touvier, /people/person/place_of_birth, Unknown) - Paul Touvier is a person, but no specific place of birth is mentioned in the sentence.\\n(Paul Touvier, /business/company/roles/chief, Wartime paramilitary militia in Lyon) - Paul Touvier is the chief of the wartime paramilitary militia in Lyon.\\n(Wartime paramilitary militia in Lyon, /location/located_in, Lyon) - The wartime paramilitary militia in Lyon is located in Lyon.\\n(Paul Touvier, /people/person/place_lived, Lyon) - Paul Touvier lived in Lyon.\\n(Paul Touvier, /people/deceasedperson/place_of_death, Unknown) - No information about Paul Touvier's place of death is mentioned in the sentence.\\n(Paul Touvier, /business/person/convicted_for, Execution of seven Jews) - Paul Touvier\",\n",
              "   'predicted_relations': [['Paul Touvier',\n",
              "     '/people/person/place_of_birth',\n",
              "     'Unknown'],\n",
              "    ['Paul Touvier',\n",
              "     '/business/company/roles/chief',\n",
              "     'Wartime paramilitary militia in Lyon'],\n",
              "    ['Wartime paramilitary militia in Lyon', '/location/located_in', 'Lyon'],\n",
              "    ['Paul Touvier', '/people/person/place_lived', 'Lyon'],\n",
              "    ['Paul Touvier', '/people/deceasedperson/place_of_death', 'Unknown'],\n",
              "    ['Paul Touvier',\n",
              "     '/business/person/convicted_for',\n",
              "     'Execution of seven Jews']],\n",
              "   'precision': 0.16666666666666666,\n",
              "   'recall': 1.0,\n",
              "   'f1': 0.2857142857142857}},\n",
              " {'input': 'Peter Munk , founder and chairman of Barrick Gold in Toronto , has warned that an exodus of head offices to other countries will cause , among other things , lower levels of charitable donations and fewer opportunities for skilled workers .',\n",
              "  'output': \"('Peter Munk', '/people/person/place_lived', 'Toronto'), ('Barrick Gold', '/business/location', 'Toronto'), ('Barrick Gold', '/people/person/place_lived', 'Toronto'), ('Peter Munk', '/business/person/company', 'Barrick Gold'), ('Barrick Gold', '/business/company/advisors', 'Peter Munk'), ('Barrick Gold', '/business/person/company', 'Peter Munk')\",\n",
              "  'base_model': {'response': ' Based on the given sentence, the following relation triples can be extracted:\\n(Peter Munk, /people/person/place_lived, Toronto)\\n(Barrick Gold, /business/company/headquarter_location, Toronto)\\n(/business/city/Toronto, /location/country/administrative_divisions, Canada)\\n(Peter Munk, /business/person/company, Barrick Gold)\\n(Peter Munk, /people/person/occupation, founder)\\n(Peter Munk, /people/person/occupation, chairman)\\nNote: The relation \"/business/company/advisors\" is not applicable as there is no mention of any advisor in the sentence. Also, the relation \"/location/located_in\" could potentially apply between \"Toronto\" and \"Canada\", but since we already have a triple stating that Toronto is in Canada, we do not need another one.',\n",
              "   'predicted_relations': [['Peter Munk',\n",
              "     '/people/person/place_lived',\n",
              "     'Toronto'],\n",
              "    ['Barrick Gold', '/business/company/headquarter_location', 'Toronto'],\n",
              "    ['/business/city/Toronto',\n",
              "     '/location/country/administrative_divisions',\n",
              "     'Canada'],\n",
              "    ['Peter Munk', '/business/person/company', 'Barrick Gold'],\n",
              "    ['Peter Munk', '/people/person/occupation', 'founder'],\n",
              "    ['Peter Munk', '/people/person/occupation', 'chairman']],\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': \"Philip Rylands , director of the Peggy Guggenheim Collection in Venice , said that the terms of the competition had been altered during the process , '' so the vision for the Punta della Dogana changed from a dynamic center of contemporary art to a static museum of modern art . ''\",\n",
              "  'output': 'None',\n",
              "  'base_model': {'response': ' Based on the given sentence, the following relation triple can be extracted:\\n(Philip Rylands, /people/person/occupation, director)\\n(Peggy Guggenheim Collection, /business/company, company)\\n(Peggy Guggenheim Collection, /location/located_in, Venice)\\n(vision for the Punta della Dogana, /people/person/concept, dynamic center of contemporary art)\\n(punta della Dogana, /business/company, company)\\n(punta della Dogana, /people/person/concept, static museum of modern art)\\n\\nThese relations represent that Philip Rylands is a person who is the director of the Peggy Guggenheim Collection, which is a company located in Venice. The vision for the Punta della Dogana was initially conceptualized as a dynamic center of contemporary art but later changed to a static museum of modern art.',\n",
              "   'predicted_relations': [['Philip Rylands',\n",
              "     '/people/person/occupation',\n",
              "     'director'],\n",
              "    ['Peggy Guggenheim Collection', '/business/company', 'company'],\n",
              "    ['Peggy Guggenheim Collection', '/location/located_in', 'Venice'],\n",
              "    ['vision for the Punta della Dogana',\n",
              "     '/people/person/concept',\n",
              "     'dynamic center of contemporary art'],\n",
              "    ['punta della Dogana', '/business/company', 'company'],\n",
              "    ['punta della Dogana',\n",
              "     '/people/person/concept',\n",
              "     'static museum of modern art']],\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': \"Second and third place went to Fritz Strobl of Austria (1:14.62) and Bruno Kernen of Switzerland (1:14.92) , a pair of 34-year-olds , each the last to qualify for his nation 's four-man race quota .\",\n",
              "  'output': \"('Bruno Kernen', '/people/person/nationality', 'Switzerland')\",\n",
              "  'base_model': {'response': ' Based on the given sentence, the following relation triple can be extracted:\\n(person \"Fritz Strobl\", /people/person/nationality, country \"Austria\")\\n(person \"Bruno Kernen\", /people/person/nationality, country \"Switzerland\")',\n",
              "   'predicted_relations': [['person \"Fritz Strobl',\n",
              "     '/people/person/nationality',\n",
              "     'country \"Austria'],\n",
              "    ['person \"Bruno Kernen',\n",
              "     '/people/person/nationality',\n",
              "     'country \"Switzerland']],\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': \"Senator Jim DeMint of South Carolina , a critic of the measure , said he had heard from people who were upset not only with the legislation , but also with his Republican colleague from the state , Senator Lindsey Graham , one of the measure 's architects . ''\",\n",
              "  'output': 'None',\n",
              "  'base_model': {'response': ' Based on the given sentence, there aren\\'t any explicit relations mentioned between entities that can be directly extracted using the provided relation types. However, we can infer some implicit relationships based on the context:\\n\\n1. (Person/Jim DeMint, Person/place_of_birth, Location/South_Carolina) - This can be inferred as Jim DeMint is described as being \"from South Carolina\".\\n2. (Person/Lindsey_Graham, Person/person, Person/Jim_DeMint) - They are both persons and mentioned in the same sentence as colleagues.\\n3. (Location/South_Carolina, location/located_in, Country/) - South Carolina is located in a country, although this isn\\'t explicitly stated in the sentence.\\n4. (Person/Jim_DeMint, /business/person/politician, Organization/Republican_Party) - Jim DeMint is identified as a senator and a Republican, implying membership in the Republican Party.\\n5. (Person/Jim_DeMint, /business/person/critic, Legislation/) - He is described as a critic',\n",
              "   'predicted_relations': [['Person/Jim DeMint',\n",
              "     'Person/place_of_birth',\n",
              "     'Location/South_Carolina'],\n",
              "    ['Person/Lindsey_Graham', 'Person/person', 'Person/Jim_DeMint'],\n",
              "    ['Location/South_Carolina', 'location/located_in', 'Country/'],\n",
              "    ['Person/Jim_DeMint',\n",
              "     '/business/person/politician',\n",
              "     'Organization/Republican_Party'],\n",
              "    ['Person/Jim_DeMint', '/business/person/critic', 'Legislation/']],\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': \"Several Italian politicians have criticized Pirelli 's plan to sell most of Olimpia to the two North American companies , and the chief executive of one of Italy 's largest banks made a thinly veiled call for a group of domestic companies to band together to buy control of Telecom Italia .\",\n",
              "  'output': 'None',\n",
              "  'base_model': {'response': \" Based on the given sentence, the following relation triple may be extracted:\\n(head entity: 'Pirelli', relation: '/business/company/plan', tail entity: 'to sell most of Olimpia')\\n(head entity: 'Italian politicians', relation: '/people/person/nationality', tail entity: 'Italy')\\n(head entity: 'one of Italy ’s largest banks', relation: '/business/bank/CEO', tail entity: 'chief executive')\\n(head entity: 'North American companies', relation: '/business/company/type', tail entity: 'North American')\\n(head entity: 'group of domestic companies', relation: '/business/person/company', tail entity: 'domestic companies')\\n(head entity: 'Telecom Italia ', relation: '/business/company/target', tail entity: 'control of')\\nHowever, there isn't any direct relation mentioned between entities 'Pirelli' and 'domestic companies'. The sentence implies that they are involved in some sort of competition or conflict over ownership of 'Telecom Italia', but it does not explicitly state that 'domestic companies' aim to buy 'Pirelli's shares\",\n",
              "   'predicted_relations': [[\"head entity: 'Pirelli\",\n",
              "     \"relation: '/business/company/plan\",\n",
              "     \"tail entity: 'to sell most of Olimpia\"],\n",
              "    [\"head entity: 'Italian politicians\",\n",
              "     \"relation: '/people/person/nationality\",\n",
              "     \"tail entity: 'Italy\"],\n",
              "    [\"head entity: 'one of Italy ’s largest banks\",\n",
              "     \"relation: '/business/bank/CEO\",\n",
              "     \"tail entity: 'chief executive\"],\n",
              "    [\"head entity: 'North American companies\",\n",
              "     \"relation: '/business/company/type\",\n",
              "     \"tail entity: 'North American\"],\n",
              "    [\"head entity: 'group of domestic companies\",\n",
              "     \"relation: '/business/person/company\",\n",
              "     \"tail entity: 'domestic companies\"],\n",
              "    [\"head entity: 'Telecom Italia \",\n",
              "     \"relation: '/business/company/target\",\n",
              "     \"tail entity: 'control of\"]],\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': 'She is survived by her brother Stanley H. Rumbough and her sisters Nina Rumbough of Greenwich , Connecticut and Stephanie Saunders of Charlesston , South Carolina .',\n",
              "  'output': \"('Greenwich', '/location/located_in', 'Connecticut')\",\n",
              "  'base_model': {'response': ' Based on the given sentence, the following relation triples can be extracted:\\n(persons/she, relations/people/person/survived_by, persons/stanley_h_rumbough)\\n(persons/she, relations/people/person/sister_of, persons/nina_rumbough)\\n(persons/she, relations/people/person/sister_of, persons/stephanie_saunders)\\n(locations/greenwich,_connecticut, relations/location/located_in, persons/nina_rumbaugh)\\n(locations/charlesston,_south_carolina, relations/location/located_in, persons/stephanie_saunders)',\n",
              "   'predicted_relations': [['persons/she',\n",
              "     'relations/people/person/survived_by',\n",
              "     'persons/stanley_h_rumbough'],\n",
              "    ['persons/she',\n",
              "     'relations/people/person/sister_of',\n",
              "     'persons/nina_rumbough'],\n",
              "    ['persons/she',\n",
              "     'relations/people/person/sister_of',\n",
              "     'persons/stephanie_saunders']],\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': \"Shortly after he won the Nobel , the Bogotá daily newspaper El Tiempo sent a reporter here , and he described Aracataca as '' a ruined , backward town , without the tiniest attraction . ''\",\n",
              "  'output': 'None',\n",
              "  'base_model': {'response': ' Based on the given sentence, there doesn\\'t seem to be any explicit mention of companies or locations being related to each other or to people. Therefore, no relations from the given list would directly apply to this sentence. However, we can infer that \"here\" refers to Colombia based on context, so we could potentially have the following relation for the person mentioned: (\\'Aracataca\\', /location/country/\\'Colombia\\', /people/person/\\'him\\') for representing the fact that \\'he\\' is from Colombia. But keep in mind that this is not explicitly stated in the sentence and is an inference made based on context. So, the final answer would be: None.',\n",
              "   'predicted_relations': 'None',\n",
              "   'precision': 1.0,\n",
              "   'recall': 1.0,\n",
              "   'f1': 1.0}},\n",
              " {'input': \"Some of the biggest creative names in Canada are choosing to introduce their new works in Calgary . ''\",\n",
              "  'output': \"('Calgary', '/location/located_in', 'Canada')\",\n",
              "  'base_model': {'response': \" Based on the given sentence, the following relation might be extracted:\\n('/people/person': head entity 1, '/location/located_in': relation 1, 'Calgary' : tail entity 1)\",\n",
              "   'predicted_relations': [[\"/people/person': head entity 1\",\n",
              "     \"/location/located_in': relation 1\",\n",
              "     \"Calgary' : tail entity 1\"]],\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': \"Songs From ` Here Lies Love ' '' offered 20 selections from his forthcoming multimedia production about Imelda Marcos , the former first lady of the Philippines and an enduring symbol of despotic extravagance and shoe love .\",\n",
              "  'output': \"('Imelda Marcos', '/people/person/place_lived', 'Philippines'), ('Imelda Marcos', '/people/person/nationality', 'Philippines')\",\n",
              "  'base_model': {'response': \" None.\\nIn this sentence, there are no explicit mentions of specific entities or locations that can be related using the provided relation types. The sentence primarily talks about 'Songs From Here Lies Love', which is a multimedia production by an unspecified 'he'. There is also a reference to Imelda Marcos as the former first lady of the Philippines, but no location or company is explicitly mentioned in relation to her. Therefore, no relation triples can be extracted from this sentence based on the given list.\",\n",
              "   'predicted_relations': 'None',\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': 'Stallone Fined for Hormone Imports Sylvester Stallone , right , officially became a convict in Australia yesterday .',\n",
              "  'output': \"('Sylvester Stallone', '/people/person/place_lived', 'Australia')\",\n",
              "  'base_model': {'response': \" Based on the given sentence, there doesn't seem to be any explicit mention of companies or locations involved. Therefore, none of the relations from the given list would directly apply to this sentence. However, if we make some assumptions based on context, we could potentially infer that 'Australia' is a location where an event occurred ('/location/country/location'), and 'Sylvester Stallone' is a person who was in a specific country ('/people/person/place_lived'). But these inferences would require additional context or background knowledge not provided in the sentence itself. So, the answer remains: None.\",\n",
              "   'predicted_relations': 'None',\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': 'That changed in 1994 , when voters in North Carolina and South Carolina elected Republican majorities in their Houses , and Florida elected a Republican majority in its Senate , according to the National Conference of State Legislatures .',\n",
              "  'output': 'None',\n",
              "  'base_model': {'response': ' Based on the given sentence, the following relation triple may be extracted:\\n(National_Conference_of_State_Legislatures, /business/organization/reports, That)\\n(North_Carolina, /location/country/administrative_divisions/state, United_States)\\n(South_Carolina, /location/country/administrative_divisions/state, United_States)\\n(Florida, /location/country/administrative_divisions/state, United_States)\\n(North_Carolina, /location/located_in, Eastern_United_States)\\n(South_Carolina, /location/located_in, Southeastern_United_States)\\n(Florida, /location/located_in, Southeastern_United_States)\\n(Republican_majorities, /business/company/political_party, Republicans)\\n(Voters_in_North_Carolina_and_South_Carolina, /people/group, Voters)\\n(Voters_in_Florida, /people/group,',\n",
              "   'predicted_relations': [['National_Conference_of_State_Legislatures',\n",
              "     '/business/organization/reports',\n",
              "     'That'],\n",
              "    ['North_Carolina',\n",
              "     '/location/country/administrative_divisions/state',\n",
              "     'United_States'],\n",
              "    ['South_Carolina',\n",
              "     '/location/country/administrative_divisions/state',\n",
              "     'United_States'],\n",
              "    ['Florida',\n",
              "     '/location/country/administrative_divisions/state',\n",
              "     'United_States'],\n",
              "    ['North_Carolina', '/location/located_in', 'Eastern_United_States'],\n",
              "    ['South_Carolina', '/location/located_in', 'Southeastern_United_States'],\n",
              "    ['Florida', '/location/located_in', 'Southeastern_United_States'],\n",
              "    ['Republican_majorities',\n",
              "     '/business/company/political_party',\n",
              "     'Republicans'],\n",
              "    ['Voters_in_North_Carolina_and_South_Carolina',\n",
              "     '/people/group',\n",
              "     'Voters']],\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': 'That was underscored when 10 Consol miners traveled to California to shoot the commercial at Zoic Studios , bringing along their equipment and gear .',\n",
              "  'output': \"('Zoic Studios', '/business/location', 'California')\",\n",
              "  'base_model': {'response': \" Based on the given sentence, there do not seem to be any explicit entities or relationships that can be extracted using the provided list. The sentence mentions '10 Consol miners' and 'California' as locations, but no clear business or person entities or their relationships are mentioned. Therefore, the answer would be: None.\",\n",
              "   'predicted_relations': 'None',\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': \"The Faculty Senate at Southern Methodist University in Dallas rejected a proposal yesterday for a faculty referendum on plans for an independent policy institute on campus that would accompany President Bush 's future library and museum .\",\n",
              "  'output': 'None',\n",
              "  'base_model': {'response': \" Based on the given sentence, the following relation triple may be extracted:\\n(Entity: 'Faculty Senate at Southern Methodist University', Relation: '/business/organization/meeting', Tail Entity: 'rejected a proposal')\\n(Entity: 'Southern Methodist University in Dallas', Relation: '/location/city', Tail Entity: None)\\n(Entity: 'Southern Methodist University in Dallas', Relation: '/business/educational_institution/campus', Tail Entity: None)\\n(Entity: 'President Bush ', Relation: '/people/person/politician', Tail Entity: None)\\nThere isn't any relation directly mentioned in the sentence between entities related to companies or locations and entities related to countries, deceased persons, or places of birth/living. Therefore, no triples involving those relation types can be derived from this sentence.\",\n",
              "   'predicted_relations': 'None',\n",
              "   'precision': 1.0,\n",
              "   'recall': 1.0,\n",
              "   'f1': 1.0}},\n",
              " {'input': 'The United Nations mediator Martti Ahtisaari presented his proposals for the final status of Kosovo on Friday , most likely setting the tiny war-torn territory on its way toward independence .',\n",
              "  'output': \"('Martti Ahtisaari', '/business/person/company', 'United Nations')\",\n",
              "  'base_model': {'response': ' None.\\nIn this sentence, there are no explicit mentions of companies, locations, or people having specific relationships as defined by the provided relation types. The sentence primarily discusses the role of Martti Ahtisaari as the UN mediator and the proposed path towards independence for Kosovo.',\n",
              "   'predicted_relations': 'None',\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': 'The craft that is to replace the space shuttle could be delayed because of recent budget reductions , pushing its first missions into 2015 instead of 2014 , the NASA administrator , Michael D. Griffin , told a Senate committee on Wednesday .',\n",
              "  'output': \"('Michael D. Griffin', '/business/person/company', 'NASA')\",\n",
              "  'base_model': {'response': ' None.\\nIn this sentence, there are no explicit mentions of companies, locations, or people with specific relationships as defined by the provided relation types. The sentence primarily discusses events related to the NASA administrator and the spacecraft replacement project, but it does not establish any direct relationships between entities using the specified relation types.',\n",
              "   'predicted_relations': 'None',\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': \"The crew chief Tony Eury Jr. was fined $ 100,000 and suspended until July 4 after Earnhardt Jr. 's car was found to have been altered before a race at Darlington Raceway in South Carolina .\",\n",
              "  'output': 'None',\n",
              "  'base_model': {'response': ' Based on the given sentence, the following relation triple can be extracted:\\n(Tony Eury Jr., /business/person/company, Earnhardt Jr.\\'s car)\\n(Earnhardt Jr.\\'s car, /location/country/administrative_divisions, South Carolina)\\nNote that these relations are based on the assumption that \"Earnhardt Jr.\\'s car\" can be considered as an entity representing a vehicle involved in a business context. Additionally, \"South Carolina\" is assumed to represent a location within a country context.',\n",
              "   'predicted_relations': [['Tony Eury Jr.',\n",
              "     '/business/person/company',\n",
              "     \"Earnhardt Jr.'s car\"],\n",
              "    [\"Earnhardt Jr.'s car\",\n",
              "     '/location/country/administrative_divisions',\n",
              "     'South Carolina']],\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': 'The explosives stored in his basement were similar to those that have been used to destabilize Lebanon since the assassination of the former prime minister Rafik Hariri in February 2005 .',\n",
              "  'output': \"('Rafik Hariri', '/people/person/nationality', 'Lebanon'), ('Rafik Hariri', '/people/person/place_lived', 'Lebanon')\",\n",
              "  'base_model': {'response': ' Based on the given sentence, there do not seem to be any explicit entities or relationships mentioned that can be extracted using the provided relation types. Therefore, the answer would be: None.',\n",
              "   'predicted_relations': 'None',\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': 'The hours each day of the pilgrimage will be 10 a.m. to 5 p.m. Admission for each day of the tour , $ 25 , at any of the sites and pilgrimage headquarters , 1105-A Providence Road , behind the Maryland Presbyterian Church in Towson .',\n",
              "  'output': 'None',\n",
              "  'base_model': {'response': \" Based on the given sentence, the following relation triple can be extracted:\\n(head entity: 'Maryland Presbyterian Church in Towson', relation: '/location/address/street_address', tail entity: '1105-A Providence Road')\",\n",
              "   'predicted_relations': [[\"head entity: 'Maryland Presbyterian Church in Towson\",\n",
              "     \"relation: '/location/address/street_address\",\n",
              "     \"tail entity: '1105-A Providence Road\"]],\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': 'The list of the top 10 companies requesting H-1B visas in fiscal 2006 , the most recent government data available , was dominated by Indian-based technology outsourcing companies like Infosys Technologies , Wipro Technologies and Tata Consultancy Services , and a few other companies that offer outsourced services and have sizable operations in India like Cognizant Technology Solutions , Accenture and Deloitte & Touche , according to a paper last month by Mr. Hira , which was published by the Economic Policy Institute , a liberal research group .',\n",
              "  'output': \"('Wipro Technologies', '/business/location', 'India')\",\n",
              "  'base_model': {'response': ' Based on the given sentence, the following relation triples can be extracted:\\n(Economic Policy Institute, /business/organization/publisher, Paper)\\n(Paper, /relation/has_author, Mr. Hira)\\n(/business/company/Indian_technology_outsourcing_companies/{Infosys_Technologies, Wipro_Technologies, Tata_Consultancy_Services}, /business/company/requested_H1B_visas, Fiscal_2006)\\n(/business/company/Indian_technology_outsourcing_companies/{Cognizant_Technology_Solutions, Accenture, Deloitte_&_Touche}, /business/company/offered_outsourced_services, NA)\\n(/business/company/Indian_technology_outsourcing_companies/{Infosys_Technologies, Wipro_Technologies, Tata_Consultancy_Services, Cognizant_Technology_Solutions, Accenture, Deloitte_&_Touche}, /location/',\n",
              "   'predicted_relations': [['Economic Policy Institute',\n",
              "     '/business/organization/publisher',\n",
              "     'Paper'],\n",
              "    ['Paper', '/relation/has_author', 'Mr. Hira'],\n",
              "    ['/business/company/Indian_technology_outsourcing_companies/{Infosys_Technologies',\n",
              "     'Wipro_Technologies',\n",
              "     'Tata_Consultancy_Services}, /business/company/requested_H1B_visas, Fiscal_2006'],\n",
              "    ['/business/company/Indian_technology_outsourcing_companies/{Cognizant_Technology_Solutions',\n",
              "     'Accenture',\n",
              "     'Deloitte_&_Touche}, /business/company/offered_outsourced_services, NA']],\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': 'The move came less than a week after it hired the independent producer Ben Silverman as a co-chairman , with Marc Graboff , of the television group , with authority over both the entertainment division of the NBC network and the television studio .',\n",
              "  'output': \"('Ben Silverman', '/business/person/company', 'NBC')\",\n",
              "  'base_model': {'response': ' Based on the given sentence, the following relation triple can be extracted:\\n(Marc Graboff, /business/person/company, NBC network)\\n(Marc Graboff, /business/person/company, Television studio)\\n(Ben Silverman, /business/person/company, NBC network and Television studio)\\n(NBC network, /location/located_in, Location unspecified in the sentence)\\nNote that no country or specific administrative divisions were mentioned in the sentence, so no relations related to those entities were identified.',\n",
              "   'predicted_relations': [['Marc Graboff',\n",
              "     '/business/person/company',\n",
              "     'NBC network'],\n",
              "    ['Marc Graboff', '/business/person/company', 'Television studio'],\n",
              "    ['Ben Silverman',\n",
              "     '/business/person/company',\n",
              "     'NBC network and Television studio'],\n",
              "    ['NBC network',\n",
              "     '/location/located_in',\n",
              "     'Location unspecified in the sentence']],\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': 'The shooting in Midland occurred hours after a 16-year-old boy in Greenville , Tex. , fatally shot himself shortly after 7 a.m. in the band hall of Greenville High School , according to a statement by the Greenville Independent School District .',\n",
              "  'output': 'None',\n",
              "  'base_model': {'response': \" Based on the given sentence, the following relation triples can be extracted:\\n(Greenville, /location/city, Tex.)\\n(Greenville, /location/located_in, Tex.)\\n(Greenville High School, /business/educational_institution/school, Greenville)\\n(Greenville, /event/crime/shooting, Midland)\\n(Greenville High School, /location/building, band hall)\\n(16-year-old boy, /people/person/age, 16)\\n(16-year-old boy, /people/person, self)\\n(16-year-old boy, /people/deceasedperson, himself)\\n(Greenville, /time/starts_at, 7 a.m.)\\n(Midland, /location/city)\\nNote that there seems to be a missing location for the shooting incident in the sentence, which should be added as a new head entity or modified as an existing one. The current triples assume that 'Midland' is the city where the shooting occurred. If this is not the case, then the relation type for the third triple should be changed accordingly\",\n",
              "   'predicted_relations': [['Greenville', '/location/city', 'Tex.'],\n",
              "    ['Greenville', '/location/located_in', 'Tex.'],\n",
              "    ['Greenville High School',\n",
              "     '/business/educational_institution/school',\n",
              "     'Greenville'],\n",
              "    ['Greenville', '/event/crime/shooting', 'Midland'],\n",
              "    ['Greenville High School', '/location/building', 'band hall'],\n",
              "    ['16-year-old boy', '/people/person/age', '16'],\n",
              "    ['16-year-old boy', '/people/person', 'self'],\n",
              "    ['16-year-old boy', '/people/deceasedperson', 'himself'],\n",
              "    ['Greenville', '/time/starts_at', '7 a.m.']],\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': \"The war was reaching a climax by the time Mr. Papon left Algeria in 1958 , telling superiors in Paris : '' France is on the offensive on all fronts .\",\n",
              "  'output': \"('Paris', '/location/administrative_division/country', 'France')\",\n",
              "  'base_model': {'response': ' Based on the given sentence, the following relation triple may be extracted:\\n(Mr. Papon, /people/person/place_lived, Algeria)\\n(Algeria, /location/country/administrative_divisions, France)\\n(France, /business/company/advisors, superiors)\\nNote that these entities and relations are inferred from the context of the sentence and may not necessarily be explicitly mentioned. The first relation indicates that Mr. Papon lived in Algeria. The second relation indicates that Algeria is a division of France. The third relation indicates that the superiors are advisors of France.',\n",
              "   'predicted_relations': [['Mr. Papon',\n",
              "     '/people/person/place_lived',\n",
              "     'Algeria'],\n",
              "    ['Algeria', '/location/country/administrative_divisions', 'France'],\n",
              "    ['France', '/business/company/advisors', 'superiors']],\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': \"Then Senator Russ Feingold , Democrat of Wisconsin , read a news release issued by the Republican Party in Missouri just after the case was filed , which accused the voter registration group of trying '' to cause chaos and controversy at the polls in order to help Democrats to try to steal next week 's elections . '' ''\",\n",
              "  'output': \"('Russ Feingold', '/people/person/place_lived', 'Wisconsin')\",\n",
              "  'base_model': {'response': ' Based on the given sentence, there aren\\'t any direct relationships that can be extracted using the provided relation types. The sentence mentions entities such as \"Senator Russ Feingold\", \"Republican Party in Missouri\", and \"voter registration group\" but does not explicitly state any location or nationality information for these entities, nor does it mention any advisory roles or administrative divisions. Therefore, no relationship triples can be derived from this sentence using the given relation types.\\n\\nNone.',\n",
              "   'predicted_relations': 'None',\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': \"This is the most important labor issue facing New York City and it must be resolved , '' Police Commissioner Raymond W. Kelly said at a City Council hearing on Monday .\",\n",
              "  'output': \"('Raymond W. Kelly', '/people/person/place_lived', 'New York City')\",\n",
              "  'base_model': {'response': ' None.\\nIn this sentence, there are no explicit mentions of companies, locations, or people with specified relationships according to the provided list. The mention of \"New York City\" could potentially be related to the \\'/location/\\' type, but without further context or entities involved in a relation to it, no valid triples can be extracted from this sentence.',\n",
              "   'predicted_relations': 'None',\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': 'This time in Yonkers , where eight million gallons from a broken pipe spewed into the Hudson River last weekend in what officials called the worst such incident in the history of Westchester County .',\n",
              "  'output': 'None',\n",
              "  'base_model': {'response': \" Based on the given sentence, the following relation might be applicable:\\n['/location/located_in', '/location/location', 'Yonkers']\\n(Yonkers, located_in, location)\\nThis relation indicates that Yonkers is a location that contains or is the location of another location or entity. In this case, it is the location where the incident occurred.\",\n",
              "   'predicted_relations': [['Yonkers', 'located_in', 'location']],\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': 'This week , Senator Chuck Hagel , Republican of Nebraska , said Mr. Gonzales should leave .',\n",
              "  'output': \"('Chuck Hagel', '/people/person/place_lived', 'Nebraska')\",\n",
              "  'base_model': {'response': \" None.\\nIn this sentence, we have mention of two persons ('Senator Chuck Hagel' and 'Mr. Gonzales') but no explicit mentions of businesses or locations. Therefore, there are no relations that can be extracted from this sentence based on the provided list.\",\n",
              "   'predicted_relations': 'None',\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': 'Thorpe , a Sac and Fox Indian reared in Oklahoma , was a remarkably versatile athlete in the early 20th century .',\n",
              "  'output': \"('Oklahoma', '/people/person/place_lived', 'Thorpe')\",\n",
              "  'base_model': {'response': ' Based on the given sentence, the following relation might be extracted:\\n(person \"Thorpe\", person/place_of_birth \"Oklahoma\")',\n",
              "   'predicted_relations': [],\n",
              "   'precision': 0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': 'Those visitors can pass a barbershop on 181st Street and see a customer who happens to be the nephew of Joaquín Balaguer , a former president of the Dominican Republic .',\n",
              "  'output': \"('Joaquín Balaguer', '/people/person/place_lived', 'Dominican Republic'), ('Joaquín Balaguer', '/people/person/nationality', 'Dominican Republic')\",\n",
              "  'base_model': {'response': \" Based on the given sentence, the following relation triple could be extracted: ('barbershop', '/location/address/street', '181st Street')\\n('customer', '/people/person/relatives/nephew', 'Joaquín Balaguer')\\n('Joaquín Balaguer', '/business/person/jobtitle/former_president', 'Dominican Republic')\\n\\nThese relations are derived as follows:\\n- The first relation identifies the location of the barbershop.\\n- The second relation establishes that the customer is the nephew of Joaquín Balaguer.\\n- The third relation indicates that Joaquín Balaguer was a former president of the Dominican Republic.\",\n",
              "   'predicted_relations': [['barbershop',\n",
              "     '/location/address/street',\n",
              "     '181st Street'],\n",
              "    ['customer', '/people/person/relatives/nephew', 'Joaquín Balaguer'],\n",
              "    ['Joaquín Balaguer',\n",
              "     '/business/person/jobtitle/former_president',\n",
              "     'Dominican Republic']],\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': 'To illustrate , he walked me through some of the dizzying complexities of the pay for Peter R. Dolan , the former chief executive of Bristol-Myers Squibb , who was fired last September .',\n",
              "  'output': \"('Peter R. Dolan', '/business/person/company', 'Bristol-Myers Squibb'), ('Bristol-Myers Squibb', '/business/person/company', 'Peter R. Dolan')\",\n",
              "  'base_model': {'response': ' Based on the given sentence, there do not seem to be any explicit relations mentioned that can be directly extracted using the provided list. The sentence primarily focuses on the identity of Peter R. Dolan as the former CEO of Bristol-Myers Squibb and the fact that he was fired last September. Therefore, no relation triples can be derived from this sentence based on the given list.\\n\\nNone.',\n",
              "   'predicted_relations': 'None',\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': \"To the Editor : Re '' Documents From Vast Nazi Archive to Be Made Available to Scholars '' -LRB- news article , May 16 -RRB- : The 11-nation board governing the International Tracing Service archives at Bad Arolsen , Germany , announced an agreement allowing the transfer of digitized documents to archives around the world while the formal treaty ratification process continues .\",\n",
              "  'output': \"('Bad Arolsen', '/location/located_in', 'Germany')\",\n",
              "  'base_model': {'response': ' Based on the given sentence, the following relation might be extracted:\\n(International Tracing Service archives at Bad Arolsen, /location/country/located_in, Germany)',\n",
              "   'predicted_relations': [['International Tracing Service archives at Bad Arolsen',\n",
              "     '/location/country/located_in',\n",
              "     'Germany']],\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': 'Two Democratic Senators , Ben Nelson of Nebraska and Mark Pryor of Arkansas , crossed party lines to oppose the withdrawal plan .',\n",
              "  'output': \"('Mark Pryor', '/people/person/place_lived', 'Arkansas'), ('Ben Nelson', '/business/person/company', 'Nebraska'), ('Ben Nelson', '/people/person/place_lived', 'Nebraska')\",\n",
              "  'base_model': {'response': ' None.\\nIn this sentence, we have mention of two Democratic Senators, Ben Nelson and Mark Pryor, but there is no explicit information about their companies, locations, or nationalities mentioned. Therefore, no relation from the given list can be extracted from this sentence.',\n",
              "   'predicted_relations': 'None',\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': \"Two independent experts -- William K. Reilly , who represented the first President Bush in the 1992 negotiations , and David G. Victor , a Stanford University law professor whose writings helped provide the underpinnings for Thursday 's speech -- said that Mr. Bush 's plan had merit .\",\n",
              "  'output': 'None',\n",
              "  'base_model': {'response': ' Based on the given sentence, the following relation triple can be extracted:\\n(William_K_Reilly, /business/person/company/employer, First_President_Bush)\\n(David_G_Victor, /location/country/nationality, United_States)\\n(William_K_Reilly, /business/person/company, Stanford_University)\\n(William_K_Reilly, /people/person/occupation, independent_experts)\\n(David_G_Victor, /people/person/occupation, Stanford_University_law_professor)\\n(First_President_Bush, /business/company/advisors, William_K_Reilly)\\n(First_President_Bush, /business/company/advisors, David_G_Victor)\\nNote: The exact names or entities mentioned in the sentence may vary slightly depending on how they are named or referred to in real-world sources. These mappings are based on the information given in the sentence itself.',\n",
              "   'predicted_relations': [['William_K_Reilly',\n",
              "     '/business/person/company/employer',\n",
              "     'First_President_Bush'],\n",
              "    ['David_G_Victor', '/location/country/nationality', 'United_States'],\n",
              "    ['William_K_Reilly', '/business/person/company', 'Stanford_University'],\n",
              "    ['William_K_Reilly', '/people/person/occupation', 'independent_experts'],\n",
              "    ['David_G_Victor',\n",
              "     '/people/person/occupation',\n",
              "     'Stanford_University_law_professor'],\n",
              "    ['First_President_Bush', '/business/company/advisors', 'William_K_Reilly'],\n",
              "    ['First_President_Bush', '/business/company/advisors', 'David_G_Victor']],\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': 'Under its empire-building director , Thomas Krens , the Solomon R. Guggenheim Foundation in New York led the way , first by adding the Guggenheim Bilbao in northern Spain to its traditional outpost in Venice , where it houses the Peggy Guggenheim Collection .',\n",
              "  'output': 'None',\n",
              "  'base_model': {'response': ' Based on the given sentence, the following relation triples can be extracted:\\n(Solomon R. Guggenheim Foundation, /business/person/company/employee, Thomas Krens)\\n(Solomon R. Guggenheim Foundation, /business/location/located_in, New York)\\n(Solomon R. Guggenheim Foundation, /business/location/located_or_established_in, Venice)\\n(Solomon R. Guggenheim Foundation, /business/location/located_or_established_in, Bilbao)\\nThese relations represent that Thomas Krens is an employee of the Solomon R. Guggenheim Foundation, the foundation is located in New York, and it has established or located outposts in both Venice and Bilbao.',\n",
              "   'predicted_relations': [['Solomon R. Guggenheim Foundation',\n",
              "     '/business/person/company/employee',\n",
              "     'Thomas Krens'],\n",
              "    ['Solomon R. Guggenheim Foundation',\n",
              "     '/business/location/located_in',\n",
              "     'New York'],\n",
              "    ['Solomon R. Guggenheim Foundation',\n",
              "     '/business/location/located_or_established_in',\n",
              "     'Venice'],\n",
              "    ['Solomon R. Guggenheim Foundation',\n",
              "     '/business/location/located_or_established_in',\n",
              "     'Bilbao']],\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': 'WITH : Abhishek Bachchan -LRB- Rikki Thukral -RRB- , Preity Zinta -LRB- Alvira Khan -RRB- , Lara Dutta -LRB- Anaida -RRB- , Bobby Deol -LRB- Steve -RRB- and in a special appearance , Amitabh Bachchan .',\n",
              "  'output': 'None, None',\n",
              "  'base_model': {'response': ' Based on the given sentence, there do not seem to be any explicit relations mentioned that can be directly extracted using the provided list. The sentence mentions names of people and their possible associates or co-stars, but it does not provide enough context for determining business affiliations, locations, nationalities, or places of birth/lived for these entities. Therefore, no relationship triples can be derived from this sentence based on the given list.',\n",
              "   'predicted_relations': [],\n",
              "   'precision': 0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': 'When James Dimon took over at Bank One in March 2000 , he signed a contract that gave him a guaranteed $ 9.5 million bonus in cash and stock for at least his first five years at the helm .',\n",
              "  'output': \"('James Dimon', '/business/person/company', 'Bank')\",\n",
              "  'base_model': {'response': ' Based on the given sentence, the following relation might be extracted:\\n(James Dimon, /business/person/company, Bank One)\\nThis relation indicates that James Dimon is a person who has been associated with the company Bank One. However, no other relations from the given list appear explicitly in the sentence. Therefore, the answer is:\\n[(James Dimon, /business/person/company, Bank One)]',\n",
              "   'predicted_relations': [['James Dimon',\n",
              "     '/business/person/company',\n",
              "     'Bank One'],\n",
              "    ['James Dimon', '/business/person/company', 'Bank One']],\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': \"When Kyle was 5 , his mother organized a local prayer vigil for Amadou Diallo , the African immigrant shot to death by the police in New York City . ''\",\n",
              "  'output': \"('Amadou Diallo', '/people/deceasedperson/place_of_death', 'New York City'), ('Amadou Diallo', '/people/person/place_lived', 'New York City')\",\n",
              "  'base_model': {'response': \" Based on the given sentence, the following relation might be present:\\n['/people/person/place_lived' : (Kyle, relation, New York City)]\\n['/people/person/nationality' : (Amadou Diallo, relation, Africa)]\\n['/location/located_in' : (New York City, relation, United States)]\\n\\nTherefore, the relation triples would look like this:\\n(Kyle, /people/person/place_lived, New York City)\\n(Amadio Diallo, /people/person/nationality, Africa)\\n(New York City, /location/located_in, United States)\",\n",
              "   'predicted_relations': [['Kyle', 'relation', 'New York City'],\n",
              "    ['Amadou Diallo', 'relation', 'Africa'],\n",
              "    ['New York City', 'relation', 'United States'],\n",
              "    ['Kyle', '/people/person/place_lived', 'New York City'],\n",
              "    ['Amadio Diallo', '/people/person/nationality', 'Africa'],\n",
              "    ['New York City', '/location/located_in', 'United States']],\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': \"Yun Zhao , 31 , a bright woman who works in a large insurance company here , was drawn back here after studying in Toronto and becoming a legal resident of Canada , something that has long been close to an irresistible dream for many Chinese . ''\",\n",
              "  'output': \"('Canada', '/location/country/administrative_divisions', 'Toronto'), ('Toronto', '/location/administrative_division/country', 'Canada'), ('Toronto', '/location/located_in', 'Canada')\",\n",
              "  'base_model': {'response': ' Based on the given sentence, the following relation triple can be extracted:\\n(Yun Zhao, /business/person/company, large insurance company here)',\n",
              "   'predicted_relations': [['Yun Zhao',\n",
              "     '/business/person/company',\n",
              "     'large insurance company here']],\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}}]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('drive/My Drive/mistral-finetune/')"
      ],
      "metadata": {
        "id": "wv-r2jqE967P"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import formatting_func, get_tuples, get_relations, get_scores"
      ],
      "metadata": {
        "id": "YGTVx5KqXhlT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "progress_bar = tqdm(total=len(data), desc='Progress')\n",
        "\n",
        "for idx, example in zip(list(range(len(data))), data):\n",
        "\n",
        "    eval_prompt = formatting_func(example)\n",
        "\n",
        "    model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "    ft_model.eval()\n",
        "    with torch.no_grad():\n",
        "        response  = eval_tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=256,\n",
        "                                                         repetition_penalty=1.15,\n",
        "                                                         pad_token_id=eval_tokenizer.eos_token_id)[0],\n",
        "                                          skip_special_tokens=True)\n",
        "        response = response.replace(eval_prompt, \"\")\n",
        "\n",
        "    predicted_relations = get_tuples(response)\n",
        "\n",
        "    expected_relations = get_relations(example)\n",
        "\n",
        "    precision, recall,f1 = get_scores(expected_relations, predicted_relations)\n",
        "\n",
        "    data[idx].update({'ft_model':\n",
        "                        {'response': response,\n",
        "                         'predicted_relations':predicted_relations,\n",
        "                        'precision': precision,\n",
        "                        'recall': recall,\n",
        "                        'f1': f1}\n",
        "                    })\n",
        "    progress_bar.update(1)\n",
        "\n",
        "progress_bar.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6wlakd_zHLx",
        "outputId": "4aac1f4d-287a-486f-a4d4-fdd3a464a782"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Progress: 100%|██████████| 100/100 [01:01<00:00,  1.63it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YD4Fh0pM9Da",
        "outputId": "1497db67-675a-4321-f33a-3916ebc91443"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'input': '-LRB- AP -RRB- WEST VIRGINIA 67 , VILLANOVA 56 -- Frank Young scored a career-high 25 points , including eight 3-pointers , for No. 25 West Virginia -LRB- 12-1 , 2-0 -RRB- in a Big East game .',\n",
              "  'output': \"('Frank Young', '/people/person/place_lived', 'West Virginia')\",\n",
              "  'base_model': {'response': \" Based on the given sentence, there do not seem to be any explicit relations mentioned that can be directly extracted using the provided list. The sentence primarily describes an event (a basketball game) involving entities 'West Virginia' and 'Villanova'. However, no specific relations between these entities or other mentioned entities ('Frank Young') are explicitly stated in the sentence. Therefore, the answer would be: None.\",\n",
              "   'predicted_relations': 'None',\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0},\n",
              "  'ft_model': {'response': ' None.',\n",
              "   'predicted_relations': ['None'],\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': \"9:30 P.M. (13) THE WILD PARROTS OF TELEGRAPH HILL -- '' Independent Lens '' follows Mark Bittner , a homeless street musician in San Francisco , as he literally goes to the birds -- and finds meaning in his life -- by taking up with a flock of wild red and green parrots .\",\n",
              "  'output': \"('Mark Bittner', '/people/person/place_lived', 'San Francisco')\",\n",
              "  'base_model': {'response': \" Based on the given sentence, there don't seem to be any explicit relations mentioned that can be directly extracted using the provided list. The sentence describes Mark Bittner being a homeless street musician in San Francisco who connects with a flock of wild parrots, but it does not explicitly state any location or company relationships between these entities. Therefore, none.\",\n",
              "   'predicted_relations': 'None',\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0},\n",
              "  'ft_model': {'response': ' None.',\n",
              "   'predicted_relations': ['None'],\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}},\n",
              " {'input': 'A1 OBITUARIES A15 Mstislav Rostropovich A cellist and conductor who was renowned as one of the great instrumentalists of the 20th century and an outspoken champion of artistic freedom in the Soviet Union during the last decades of the cold war , he was 80 and lived in Paris .',\n",
              "  'output': \"('Mstislav Rostropovich', '/people/person/place_lived', 'Paris')\",\n",
              "  'base_model': {'response': ' Based on the given sentence, the following relation triple can be extracted:\\n(Mstislav Rostropovich, /people/person/place_lived, Paris)',\n",
              "   'predicted_relations': [['Mstislav Rostropovich',\n",
              "     '/people/person/place_lived',\n",
              "     'Paris']],\n",
              "   'precision': 1.0,\n",
              "   'recall': 1.0,\n",
              "   'f1': 1.0},\n",
              "  'ft_model': {'response': ' None.',\n",
              "   'predicted_relations': ['None'],\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'f1': 0}}]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! tail \"drive/MyDrive/mistral-finetune/mistral-finetuning-data-nonegative.json\""
      ],
      "metadata": {
        "id": "q9-ws3sp9VTj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9rS-EkED9Wv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the file path\n",
        "file_path = \"drive/MyDrive/mistral-finetune/mistral-finetuning-data-r128alpha64batch8.json\"\n",
        "\n",
        "# Save the data to a JSON file\n",
        "with open(file_path, \"w\") as json_file:\n",
        "    json.dump(data, json_file)\n",
        "\n",
        "print(f\"Data saved to {file_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXgRdI3p5QSb",
        "outputId": "0edd2447-037b-417f-c7b4-00edc8393b7b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data saved to drive/MyDrive/mistral-finetune/mistral-finetuning-data-r128alpha64batch8.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the file path\n",
        "import json\n",
        "file_path = \"drive/MyDrive/mistral-finetune/mistral-finetuning-data-balanced.json\"\n",
        "\n",
        "# Save the data to a JSON file\n",
        "with open(file_path, \"r\") as json_file:\n",
        "    data = json.load(json_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "S6zCRjFH9FN-",
        "outputId": "e18485f6-7308-4c83-d055-c8de49d85870"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "JSONDecodeError",
          "evalue": "Expecting value: line 1 column 1 (char 0)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-15cbd5f3873b>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Save the data to a JSON file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.10/json/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0mkwarg\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0motherwise\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mJSONDecoder\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \"\"\"\n\u001b[0;32m--> 293\u001b[0;31m     return loads(fp.read(),\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mparse_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_int\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_int\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, entry in enumerate(data):\n",
        "    if entry['output']==\"None\":\n",
        "        print(idx)\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfvLZvwGZnpM",
        "outputId": "24e92b6d-fcee-4a68-f343-50cdc09d50a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_precision = 0.0\n",
        "total_recall = 0.0\n",
        "total_f1 = 0.0\n",
        "total_samples = len(data)\n",
        "\n",
        "for item in data:\n",
        "    total_precision += item['ft_model']['precision']\n",
        "    total_recall += item['ft_model']['recall']\n",
        "    total_f1 += item['ft_model']['f1']"
      ],
      "metadata": {
        "id": "XhPI2OtdaXBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_f1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEHXr953uOTY",
        "outputId": "c8032dcd-ad3d-4eec-c48a-cecbb8eeb792"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23.0"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, item in enumerate(data):\n",
        "    if item['ft_model']['precision']==1:\n",
        "        print(item['ft_model']['response'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KT33b1ZvaZjy",
        "outputId": "fd5bf7fe-aff2-4577-d0da-c8f519b1ab8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " None.\n",
            "In the given sentence, there is no triple that can be formed using relations from the list provided.\n",
            " None.\n",
            " None.\n",
            " None.\n",
            " None.\n",
            " None.\n",
            " None.\n",
            " None.\n",
            " None.\n",
            " None.\n",
            " None.\n",
            " None.\n",
            " None.\n",
            " None.\n",
            " None.\n",
            " None.\n",
            " None.\n",
            " None.\n",
            " None.\n",
            " None.\n",
            " None.\n",
            " None.\n",
            " None.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[x for x in data if (x['output'] == \"None\" and x['base_model']['predicted_relations'] == \"None\")]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVd0gLM4cM87",
        "outputId": "28381953-6ee3-404a-dd06-49a74a23657f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'input': 'As the new face of the L.P.G.A. Tour , and as a star in Mexico and elsewhere , Ochoa seems to have taken to the job of being a role model .',\n",
              "  'output': 'None',\n",
              "  'base_model': {'response': ' Based on the given sentence, there do not seem to be any explicit relations mentioned that can be extracted using the provided list. Therefore, the answer would be: None.',\n",
              "   'predicted_relations': 'None',\n",
              "   'precision': 1.0,\n",
              "   'recall': 1.0,\n",
              "   'f1': 1.0},\n",
              "  'ft_model': {'response': ' None.',\n",
              "   'predicted_relations': ['None'],\n",
              "   'precision': 1.0,\n",
              "   'recall': 1.0,\n",
              "   'f1': 1.0}},\n",
              " {'input': \"Coincidentally , the movie Mr. Starkweather inspired , Terrence Malick 's '' Badlands , '' involves a flight to Saskatchewan .\",\n",
              "  'output': 'None',\n",
              "  'base_model': {'response': \" Based on the given sentence, there doesn't seem to be any clear-cut relation that can be extracted using the entities and relation types provided in the list. Therefore, the answer would be: None.\",\n",
              "   'predicted_relations': 'None',\n",
              "   'precision': 1.0,\n",
              "   'recall': 1.0,\n",
              "   'f1': 1.0},\n",
              "  'ft_model': {'response': ' None.',\n",
              "   'predicted_relations': ['None'],\n",
              "   'precision': 1.0,\n",
              "   'recall': 1.0,\n",
              "   'f1': 1.0}},\n",
              " {'input': \"Correction : June 9 , 2007 , Saturday An article in Business Day on May 29 about Russia 's strategy to gain a monopoly in natural gas exports to Asia through Gazprom misstated the percentage of ownership in the Kovykta gas field by TNK-BP , which is being accused by the Kremlin of having failed to meet license requirements .\",\n",
              "  'output': 'None',\n",
              "  'base_model': {'response': \" None.\\nThe given sentence does not provide sufficient information for any relation from the list to be extracted. It mentions entities such as 'Business Day', 'Russia', 'Gazprom', 'Kovykta gas field', 'TNK-BP', and 'May 29'. However, no explicit relationships between these entities are stated in the sentence.\",\n",
              "   'predicted_relations': 'None',\n",
              "   'precision': 1.0,\n",
              "   'recall': 1.0,\n",
              "   'f1': 1.0},\n",
              "  'ft_model': {'response': ' None.',\n",
              "   'predicted_relations': ['None'],\n",
              "   'precision': 1.0,\n",
              "   'recall': 1.0,\n",
              "   'f1': 1.0}},\n",
              " {'input': \"In a telephone interview from Khartoum on Tuesday , as she and a three-member camera crew prepared for a two-hour flight on a small plane into Darfur , Ms. Curry was asked why she had felt compelled to return to Sudan twice since her first visit . ''\",\n",
              "  'output': 'None',\n",
              "  'base_model': {'response': \" Based on the given sentence, there do not seem to be any explicit entities or relationships that can be extracted using the provided relation types. The sentence mentions 'Ms. Curry' who is a person, 'Khartoum' which is a location, and 'Darfur' which is also a location. However, the relation types provided do not include simple 'person-location' or 'location-location' relationships like 'person/place_lived' or 'location/located_in'. Therefore, no relationship triples can be extracted directly from this sentence using the given relation types.\\n\\nNone.\",\n",
              "   'predicted_relations': 'None',\n",
              "   'precision': 1.0,\n",
              "   'recall': 1.0,\n",
              "   'f1': 1.0},\n",
              "  'ft_model': {'response': ' None.',\n",
              "   'predicted_relations': ['None'],\n",
              "   'precision': 1.0,\n",
              "   'recall': 1.0,\n",
              "   'f1': 1.0}},\n",
              " {'input': \"Martina McBride Waking Up Laughing -LRB- RCA\\\\/Sony BMG Nashville -RRB- '' I got pitched every social issue song on the planet . ''\",\n",
              "  'output': 'None',\n",
              "  'base_model': {'response': \" Based on the given sentence, there doesn't seem to be any explicit mention of entities or their relationships according to the provided list. Therefore, no relation triples can be extracted directly from this sentence.\\n\\nNone.\",\n",
              "   'predicted_relations': 'None',\n",
              "   'precision': 1.0,\n",
              "   'recall': 1.0,\n",
              "   'f1': 1.0},\n",
              "  'ft_model': {'response': ' None.',\n",
              "   'predicted_relations': ['None'],\n",
              "   'precision': 1.0,\n",
              "   'recall': 1.0,\n",
              "   'f1': 1.0}},\n",
              " {'input': 'Now that may not be necessary , with Israel and the West embracing the idea of a non-Hamas government , even if its powers are limited to the West Bank .',\n",
              "  'output': 'None',\n",
              "  'base_model': {'response': ' None.\\nIn this sentence, there are no explicit mentions of companies, locations, or people with their relationships as per the provided list. The sentence discusses the ideas and actions related to Israel and the West, but it does not provide sufficient information for extracting any specific entities or relations using the given list.',\n",
              "   'predicted_relations': 'None',\n",
              "   'precision': 1.0,\n",
              "   'recall': 1.0,\n",
              "   'f1': 1.0},\n",
              "  'ft_model': {'response': ' None.',\n",
              "   'predicted_relations': ['None'],\n",
              "   'precision': 1.0,\n",
              "   'recall': 1.0,\n",
              "   'f1': 1.0}},\n",
              " {'input': \"Shortly after he won the Nobel , the Bogotá daily newspaper El Tiempo sent a reporter here , and he described Aracataca as '' a ruined , backward town , without the tiniest attraction . ''\",\n",
              "  'output': 'None',\n",
              "  'base_model': {'response': ' Based on the given sentence, there doesn\\'t seem to be any explicit mention of companies or locations being related to each other or to people. Therefore, no relations from the given list would directly apply to this sentence. However, we can infer that \"here\" refers to Colombia based on context, so we could potentially have the following relation for the person mentioned: (\\'Aracataca\\', /location/country/\\'Colombia\\', /people/person/\\'him\\') for representing the fact that \\'he\\' is from Colombia. But keep in mind that this is not explicitly stated in the sentence and is an inference made based on context. So, the final answer would be: None.',\n",
              "   'predicted_relations': 'None',\n",
              "   'precision': 1.0,\n",
              "   'recall': 1.0,\n",
              "   'f1': 1.0},\n",
              "  'ft_model': {'response': ' None.',\n",
              "   'predicted_relations': ['None'],\n",
              "   'precision': 1.0,\n",
              "   'recall': 1.0,\n",
              "   'f1': 1.0}},\n",
              " {'input': \"The Faculty Senate at Southern Methodist University in Dallas rejected a proposal yesterday for a faculty referendum on plans for an independent policy institute on campus that would accompany President Bush 's future library and museum .\",\n",
              "  'output': 'None',\n",
              "  'base_model': {'response': \" Based on the given sentence, the following relation triple may be extracted:\\n(Entity: 'Faculty Senate at Southern Methodist University', Relation: '/business/organization/meeting', Tail Entity: 'rejected a proposal')\\n(Entity: 'Southern Methodist University in Dallas', Relation: '/location/city', Tail Entity: None)\\n(Entity: 'Southern Methodist University in Dallas', Relation: '/business/educational_institution/campus', Tail Entity: None)\\n(Entity: 'President Bush ', Relation: '/people/person/politician', Tail Entity: None)\\nThere isn't any relation directly mentioned in the sentence between entities related to companies or locations and entities related to countries, deceased persons, or places of birth/living. Therefore, no triples involving those relation types can be derived from this sentence.\",\n",
              "   'predicted_relations': 'None',\n",
              "   'precision': 1.0,\n",
              "   'recall': 1.0,\n",
              "   'f1': 1.0},\n",
              "  'ft_model': {'response': ' None.',\n",
              "   'predicted_relations': ['None'],\n",
              "   'precision': 1.0,\n",
              "   'recall': 1.0,\n",
              "   'f1': 1.0}}]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[item['ft_model']['response'] for item in data if item['ft_model']['f1']!=0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mub3QSIrayYH",
        "outputId": "5f54006c-a888-425f-e404-dcba34269239"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' None.\\nIn the given sentence, there is no triple that can be formed using relations from the list provided.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_average_metrics2(data):\n",
        "    total_precision = 0.0\n",
        "    total_recall = 0.0\n",
        "    total_f1 = 0.0\n",
        "    total_samples = len(data)\n",
        "\n",
        "    for item in data:\n",
        "        total_precision += item['ft_model']['precision']\n",
        "        total_recall += item['ft_model']['recall']\n",
        "        total_f1 += item['ft_model']['f1']\n",
        "\n",
        "    average_precision = total_precision / total_samples\n",
        "    average_recall = total_recall / total_samples\n",
        "    average_f1 = total_f1 / total_samples\n",
        "\n",
        "    return average_precision, average_recall, average_f1\n",
        "\n",
        "# Calculate average metrics\n",
        "avg_precision, avg_recall, avg_f1 = calculate_average_metrics2(data)\n",
        "\n",
        "print(\"Average Precision:\", avg_precision)\n",
        "print(\"Average Recall:\", avg_recall)\n",
        "print(\"Average F1-score:\", avg_f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q05XVcYD5Q_D",
        "outputId": "47cab0ae-171a-491d-85dd-41a93bc7a618"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Precision: 0.23\n",
            "Average Recall: 0.23\n",
            "Average F1-score: 0.23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[24]['base_model']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7v21z-SCG3t",
        "outputId": "21034882-0411-4116-b2fb-9923219899c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'response': ' None.\\nIn this sentence, there are no explicit mentions of companies, locations, or people with specified relationships using the provided relation types. The sentence primarily discusses monetary amounts, political actions, and geographical references without specifying entities in a relational context according to the given relation types.',\n",
              " 'predicted_relations': 'None',\n",
              " 'precision': 0.0,\n",
              " 'recall': 0.0,\n",
              " 'f1': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[24]['ft_model']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cyVchLICNsN",
        "outputId": "92b5118c-6286-4335-8309-0836ea809939"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'response': ' None.',\n",
              " 'predicted_relations': ['None'],\n",
              " 'precision': 0.0,\n",
              " 'recall': 0.0,\n",
              " 'f1': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hf7AlxAtCm-e",
        "outputId": "4396021d-8ad7-45a2-9aaf-452c13ccf665"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': '-LRB- AP -RRB- WEST VIRGINIA 67 , VILLANOVA 56 -- Frank Young scored a career-high 25 points , including eight 3-pointers , for No. 25 West Virginia -LRB- 12-1 , 2-0 -RRB- in a Big East game .',\n",
              " 'output': \"('Frank Young', '/people/person/place_lived', 'West Virginia')\",\n",
              " 'base_model': {'response': \" Based on the given sentence, there do not seem to be any explicit relations mentioned that can be directly extracted using the provided list. The sentence primarily describes an event (a basketball game) involving entities 'West Virginia' and 'Villanova'. However, no specific relations between these entities or other mentioned entities ('Frank Young') are explicitly stated in the sentence. Therefore, the answer would be: None.\",\n",
              "  'predicted_relations': 'None',\n",
              "  'precision': 0.0,\n",
              "  'recall': 0.0,\n",
              "  'f1': 0},\n",
              " 'ft_model': {'response': \" Based on the given sentence, there do not seem to be any explicit relations mentioned that can be directly extracted using the provided list. The sentence primarily describes an event (a basketball game) involving entities 'West Virginia' and 'Villanova'. However, no specific relations between these entities or other mentioned entities ('Frank Young') are explicitly stated in the sentence. Therefore, the answer would be: None.\",\n",
              "  'predicted_relations': 'None',\n",
              "  'precision': 0.0,\n",
              "  'recall': 0.0,\n",
              "  'f1': 0}}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://huggingface.co/docs/transformers/en/llm_tutorial\n",
        "\n",
        "### common pitfalls\n",
        "\n",
        "Wrong padding side\n",
        "\n",
        "LLMs are decoder-only architectures, meaning they continue to iterate on your input prompt. If your inputs do not have the same length, they need to be padded. Since LLMs are not trained to continue from pad tokens, your input needs to be left-padded. Make sure you also don’t forget to pass the attention mask to generate!\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NbZl2xq8icRZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "32^0.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "HNT1EgfUIRCV",
        "outputId": "444d1493-d6bc-4ad8-f5a9-08b1597a5467"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "unsupported operand type(s) for ^: 'int' and 'float'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-73f535772828>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;36m32\u001b[0m\u001b[0;34m^\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for ^: 'int' and 'float'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "[ x['ft_model']['response'] for x in data]"
      ],
      "metadata": {
        "id": "zlVbVqe7C_BN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98f35d12-343f-4bf8-8575-20e87b2c2161"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.\\n\\nIn the given sentence, there is no relation from the list that might be included. The relations in the list require entities or involve locations that are not explicitly mentioned in the sentence.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.\\n\\nIn the given sentence, there are no relations from the list provided that can be extracted. The relations mentioned in the sentence are /business/company/advisors but this relation type is not in the list provided.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.',\n",
              " ' None.']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fKt1A-ODa_nh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}